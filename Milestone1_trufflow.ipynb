{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29401ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HEADER / TOP-LEVEL KEYS ===\n",
      "['tenant/id', 'transaction/consumer/id', 'transaction/consumer/name', 'transaction/cost', 'transaction/data', 'transaction/id', 'transaction/response', 'transaction/supplier/id', 'transaction/supplier/name', 'transaction/time']\n",
      "\n",
      "=== EXPECTED FIELD CHECK ===\n",
      "Present: []\n",
      "Missing: ['ts', 'timestamp', 'service_id', 'peer_id', 'req_count', 'error_count', 'p50_latency_ms', 'p95_latency_ms', 'bytes_in', 'bytes_out']\n",
      "\n",
      "=== FIRST 5 ROWS ===\n",
      "\n",
      "--- Row 1 ---\n",
      "{'tenant/id': 'DEMO', 'transaction/consumer/id': 'SELENE', 'transaction/consumer/name': 'Selene Customer Warehouse', 'transaction/cost': 41.5, 'transaction/data': 0.3, 'transaction/id': 't0x78b44bd3-GWVR7-O9HZF', 'transaction/response': 'success', 'transaction/supplier/id': 'AWS', 'transaction/supplier/name': 'Amazon Web Services', 'transaction/time': '2024-06-01 00:00:00'}\n",
      "\n",
      "--- Row 2 ---\n",
      "{'tenant/id': 'DEMO', 'transaction/consumer/id': 'SELENE', 'transaction/consumer/name': 'Selene Customer Warehouse', 'transaction/cost': 49.8, 'transaction/data': 0.45, 'transaction/id': 't0x78b44bd3-GWVR7-O9HZF', 'transaction/response': 'success', 'transaction/supplier/id': 'DBRCKS', 'transaction/supplier/name': 'Databricks', 'transaction/time': '2024-06-01 00:00:00'}\n",
      "\n",
      "--- Row 3 ---\n",
      "{'tenant/id': 'DEMO', 'transaction/consumer/id': 'SELENE', 'transaction/consumer/name': 'Selene Customer Warehouse', 'transaction/cost': 24.9, 'transaction/data': 0.9, 'transaction/id': 't0x78b44bd3-GWVR7-O9HZF', 'transaction/response': 'success', 'transaction/supplier/id': 'SNWFLK', 'transaction/supplier/name': 'Snowflake', 'transaction/time': '2024-06-01 00:00:00'}\n",
      "\n",
      "--- Row 4 ---\n",
      "{'tenant/id': 'DEMO', 'transaction/consumer/id': 'FRDETCT', 'transaction/consumer/name': 'Fraud Detection System', 'transaction/cost': 116.2, 'transaction/data': 1.65, 'transaction/id': 't0x78b44bd3-GWVR7-O9HZF', 'transaction/response': 'success', 'transaction/supplier/id': 'SELENE', 'transaction/supplier/name': 'Selene Customer Warehouse', 'transaction/time': '2024-06-01 00:00:00'}\n",
      "\n",
      "--- Row 5 ---\n",
      "{'tenant/id': 'DEMO', 'transaction/consumer/id': 'HMFRP', 'transaction/consumer/name': 'Hermes Fast Release Platform', 'transaction/cost': 16.6, 'transaction/data': 0.15, 'transaction/id': 't0x78b44bd3-GWVR7-O9HZF', 'transaction/response': 'success', 'transaction/supplier/id': 'AZURE', 'transaction/supplier/name': 'Microsoft Azure', 'transaction/time': '2024-06-01 00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect transactions.jsonl (single cell)\n",
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "EXPECTED = [\n",
    "    \"ts\",\"timestamp\",\"service_id\",\"peer_id\",\n",
    "    \"req_count\",\"error_count\",\"p50_latency_ms\",\"p95_latency_ms\",\n",
    "    \"bytes_in\",\"bytes_out\"\n",
    "]\n",
    "\n",
    "def inspect_jsonl(path: str, n: int = 5):\n",
    "    keys_union, samples = set(), []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in islice(f, n):\n",
    "            if not line.strip(): \n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            samples.append(obj)\n",
    "            keys_union.update(obj.keys())\n",
    "    keys_union = sorted(keys_union)\n",
    "    print(\"=== HEADER / TOP-LEVEL KEYS ===\")\n",
    "    print(keys_union)\n",
    "    print(\"\\n=== EXPECTED FIELD CHECK ===\")\n",
    "    present = [k for k in EXPECTED if k in keys_union]\n",
    "    missing = [k for k in EXPECTED if k not in keys_union]\n",
    "    print(\"Present:\", present)\n",
    "    print(\"Missing:\", missing)\n",
    "    print(f\"\\n=== FIRST {len(samples)} ROWS ===\")\n",
    "    for i, obj in enumerate(samples, 1):\n",
    "        print(f\"\\n--- Row {i} ---\")\n",
    "        print({k: obj.get(k) for k in keys_union})\n",
    "\n",
    "inspect_jsonl(\"transactions.jsonl\", n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efa0ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows read from JSONL: 7254656\n",
      "Aggregated windows: 1540175\n",
      "Feature matrix shape: (1540175, 6)  # [samples, features]\n",
      "00 key=('SELENE', 'AWS', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 1630.9500000000007, 22.97112676056339, 25.650000000000002, 0.36126760563380284]\n",
      "01 key=('SELENE', 'DBRCKS', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 3083.45, 43.42887323943662, 85.50000000000001, 1.2042253521126762]\n",
      "02 key=('SELENE', 'SNWFLK', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 1618.500000000001, 22.795774647887338, 65.4, 0.9211267605633804]\n",
      "03 key=('FRDETCT', 'SELENE', '2024-06-01 00:00:00')  feats=[1.0, 0.0, 116.2, 116.2, 1.65, 1.65]\n",
      "04 key=('HMFRP', 'AZURE', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 1361.2, 19.171830985915495, 8.250000000000002, 0.11619718309859157]\n"
     ]
    }
   ],
   "source": [
    "# Build hourly features from transactions.jsonl (single cell)\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# --- helpers ---\n",
    "def floor_to_hour(ts: str):\n",
    "    \"\"\"Parse timestamp and floor to the hour, return 'YYYY-MM-DD HH:00:00' or None.\"\"\"\n",
    "    if not ts:\n",
    "        return None\n",
    "    fmts = [\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%Y-%m-%dT%H:%M:%S\",\n",
    "        \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\",\n",
    "    ]\n",
    "    for fmt in fmts:\n",
    "        try:\n",
    "            dt = datetime.strptime(ts, fmt)\n",
    "            dt = dt.replace(minute=0, second=0, microsecond=0)\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def is_success(resp):\n",
    "    \"\"\"Return True if response indicates success.\"\"\"\n",
    "    if resp is None:\n",
    "        return False\n",
    "    s = str(resp).strip().lower()\n",
    "    return s in {\"success\", \"ok\", \"200\", \"true\", \"passed\"}\n",
    "\n",
    "# --- aggregate per (consumer_id, supplier_id, hour) ---\n",
    "agg = defaultdict(lambda: {\n",
    "    \"n\": 0,\n",
    "    \"success\": 0,\n",
    "    \"cost_sum\": 0.0,\n",
    "    \"cost_sqsum\": 0.0,   # optional variance later\n",
    "    \"data_sum\": 0.0,\n",
    "    \"data_sqsum\": 0.0,   # optional variance later\n",
    "})\n",
    "\n",
    "path = \"transactions.jsonl\"  # adjust if needed\n",
    "rows_read = 0\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "\n",
    "        ts = obj.get(\"transaction/time\")\n",
    "        bucket = floor_to_hour(ts)\n",
    "        if bucket is None:\n",
    "            continue\n",
    "\n",
    "        consumer = obj.get(\"transaction/consumer/id\") or \"\"\n",
    "        supplier = obj.get(\"transaction/supplier/id\") or \"\"\n",
    "        if not consumer or not supplier:\n",
    "            continue\n",
    "\n",
    "        cost = obj.get(\"transaction/cost\", 0.0) or 0.0\n",
    "        data = obj.get(\"transaction/data\", 0.0) or 0.0\n",
    "        resp = obj.get(\"transaction/response\")\n",
    "\n",
    "        key = (consumer, supplier, bucket)\n",
    "        a = agg[key]\n",
    "        a[\"n\"] += 1\n",
    "        a[\"success\"] += 1 if is_success(resp) else 0\n",
    "        a[\"cost_sum\"] += float(cost)\n",
    "        a[\"cost_sqsum\"] += float(cost) ** 2\n",
    "        a[\"data_sum\"] += float(data)\n",
    "        a[\"data_sqsum\"] += float(data) ** 2\n",
    "        rows_read += 1\n",
    "\n",
    "# --- build feature matrix ---\n",
    "keys = []\n",
    "rows = []\n",
    "for key, a in agg.items():\n",
    "    n = float(a[\"n\"])\n",
    "    succ = float(a[\"success\"])\n",
    "    err = max(n - succ, 0.0)\n",
    "    err_rate = (err / n) if n > 0 else 0.0\n",
    "\n",
    "    cost_sum = a[\"cost_sum\"]\n",
    "    data_sum = a[\"data_sum\"]\n",
    "    cost_mean = (cost_sum / n) if n > 0 else 0.0\n",
    "    data_mean = (data_sum / n) if n > 0 else 0.0\n",
    "\n",
    "    # features: [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "    feat = [n, err_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "    rows.append(feat)\n",
    "    keys.append(key)\n",
    "\n",
    "X = np.array(rows, dtype=float) if rows else np.zeros((0, 6), dtype=float)\n",
    "\n",
    "print(f\"Rows read from JSONL: {rows_read}\")\n",
    "print(f\"Aggregated windows: {len(keys)}\")\n",
    "print(f\"Feature matrix shape: {X.shape}  # [samples, features]\")\n",
    "\n",
    "# show a small preview\n",
    "for i in range(min(5, len(keys))):\n",
    "    (consumer, supplier, bucket) = keys[i]\n",
    "    print(f\"{i:02d} key={keys[i]}  feats={X[i].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e969cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid_size': 308035, 'pos_rate_valid': 0.0848767185547097, 'PR_AUC': 0.9774733165108653, 'F1': 0.9235196292766784, 'Precision': 0.9028533849694933, 'Recall': 0.9451902849493211, 'Acc_pos': 0.9451902849493211, 'Acc_mean': 0.9867125488986641, 'threshold': 0.9806067807015026}\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Naive Bayes baseline (weak labels + metrics)\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, f1_score, accuracy_score\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the feature cell first.\"\n",
    "\n",
    "# Features: [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "er = X[:, 1]\n",
    "cmean = X[:, 3]\n",
    "dmean = X[:, 5]\n",
    "\n",
    "def robust_z(x):\n",
    "    med = np.median(x)\n",
    "    mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "\n",
    "z_c = robust_z(cmean)\n",
    "z_d = robust_z(dmean)\n",
    "\n",
    "# Weak labels: anomaly if high error_rate OR cost/data mean outlier\n",
    "y = ((er > 0.10) | (z_c > 3.0) | (z_d > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split (80/20) by hour bucket string\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx) * 0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:] if cut > 0 else (idx, idx)\n",
    "\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"nb\", GaussianNB())\n",
    "]).fit(Xtr, ytr)\n",
    "\n",
    "if len(Xva) and len(np.unique(yva)) > 1:\n",
    "    proba = model.predict_proba(Xva)[:, 1]\n",
    "    pr_auc = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi > 0 and (bi-1) < len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    acc_pos = accuracy_score(yva[yva == 1], yhat[yva == 1]) if np.any(yva == 1) else 0.0\n",
    "    acc_mean = accuracy_score(yva, yhat)\n",
    "    print({\n",
    "        \"valid_size\": int(len(yva)),\n",
    "        \"pos_rate_valid\": float(yva.mean()),\n",
    "        \"PR_AUC\": float(pr_auc),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"Acc_pos\": float(acc_pos),\n",
    "        \"Acc_mean\": float(acc_mean),\n",
    "        \"threshold\": float(best_thr)\n",
    "    })\n",
    "else:\n",
    "    print({\"note\": \"Validation split has only one class; try adjusting weak labels or split.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be3260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task1_results.csv and task1_results.json\n",
      "{'Feature Set / Variant': 'All features (NB)', 'Precision': 0.9028533849694933, 'Recall': 0.9451902849493211, 'F1': 0.9235196292766784, 'PR-AUC': 0.9774733165108653, 'Accuracy (+ve)': 0.9451902849493211, 'Accuracy (mean)': 0.9867125488986641, 'Threshold': 0.9806067807015026, 'Valid size': 308035, 'Pos rate (valid)': 0.0848767185547097}\n"
     ]
    }
   ],
   "source": [
    "# Save Task 1 metrics to CSV + JSON (one-row table)\n",
    "import csv, json\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run feature cell first.\"\n",
    "\n",
    "# Rebuild weak labels (same as before)\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "z_c = robust_z(cmean); z_d = robust_z(dmean)\n",
    "y = ((er > 0.10) | (z_c > 3.0) | (z_d > 3.0)).astype(int)\n",
    "\n",
    "# Time split\n",
    "idx = np.arange(len(keys)); idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "# Train NB\n",
    "model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "\n",
    "# Metrics\n",
    "proba = model.predict_proba(Xva)[:,1]\n",
    "pr_auc = average_precision_score(yva, proba)\n",
    "prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "bi = int(np.argmax(f1s))\n",
    "best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "yhat = (proba >= best_thr).astype(int)\n",
    "acc_pos = accuracy_score(yva[yva==1], yhat[yva==1]) if np.any(yva==1) else 0.0\n",
    "acc_mean = accuracy_score(yva, yhat)\n",
    "row = {\n",
    "    \"Feature Set / Variant\": \"All features (NB)\",\n",
    "    \"Precision\": float(prec[bi]),\n",
    "    \"Recall\": float(rec[bi]),\n",
    "    \"F1\": float(f1_score(yva, yhat)),\n",
    "    \"PR-AUC\": float(pr_auc),\n",
    "    \"Accuracy (+ve)\": float(acc_pos),\n",
    "    \"Accuracy (mean)\": float(acc_mean),\n",
    "    \"Threshold\": float(best_thr),\n",
    "    \"Valid size\": int(len(yva)),\n",
    "    \"Pos rate (valid)\": float(yva.mean())\n",
    "}\n",
    "\n",
    "# Write CSV\n",
    "csv_path = \"task1_results.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=list(row.keys()))\n",
    "    w.writeheader(); w.writerow(row)\n",
    "\n",
    "# Write JSON\n",
    "json_path = \"task1_results.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"results\": [row]}, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", csv_path, \"and\", json_path)\n",
    "print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c77986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Services: 87 Vector shape: (87, 8)\n",
      "ABTEST -> [('NOTIFY', 0.9999999999809024), ('MKTDB', 0.9999999999349333), ('DYNPRC', 0.9999999998786389), ('XCHATTR', 0.9999999997867001), ('TAXCALC', 0.9999999996770227)]\n",
      "AIRFLW -> [('HMFRP', 0.999999998609385), ('YELLOWS', 0.9999999953721767), ('KAFKA', 0.9999999888122127), ('DDSD', 0.9999999793005887), ('ELASTIC', 0.9999996950612356)]\n",
      "ANALAPI -> [('AUTOML', 0.9999992614814076), ('RISKMG', 0.9999991143549807), ('BILLING', 0.9999989627174771), ('GLOBCMP', 0.9999989224119094), ('SUPCHN', 0.9999988448202543)]\n",
      "APIGWY -> [('SNAPINT', 0.9999999992863867), ('MULTILNG', 0.9999999971777137), ('SLSDB', 0.9999999962098263), ('TAXCALC', 0.9999999958172383), ('XCHATTR', 0.9999999955270946)]\n",
      "ATLAS -> [('DATAHUB', 0.9999896440875172), ('MDLREG', 0.9999718818442569), ('JPNXPP', 0.999951212040954), ('SPARK', 0.9999474668239722), ('PANDRA', 0.9999318254451391)]\n",
      "Saved task2_neighbors.json\n"
     ]
    }
   ],
   "source": [
    "# Task 2 — Service similarity (cosine over consumer/supplier profiles)\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the feature cell first.\"\n",
    "\n",
    "k = 5  # top-k neighbors\n",
    "\n",
    "# Accumulate per service, separately for consumer and supplier roles.\n",
    "# For each service we keep:\n",
    "# [n_cons, err_wsum_cons, cost_wsum_cons, data_wsum_cons,\n",
    "#  n_sup,  err_wsum_sup,  cost_wsum_sup,  data_wsum_sup]\n",
    "acc = defaultdict(lambda: np.zeros(8, dtype=float))\n",
    "\n",
    "for (cons, supp, _), row in zip(keys, X):\n",
    "    n, err_rate, _cost_sum, cost_mean, _data_sum, data_mean = row\n",
    "\n",
    "    # consumer role\n",
    "    a = acc[cons]\n",
    "    a[0] += n\n",
    "    a[1] += err_rate * n\n",
    "    a[2] += cost_mean * n\n",
    "    a[3] += data_mean * n\n",
    "\n",
    "    # supplier role\n",
    "    b = acc[supp]\n",
    "    b[4] += n\n",
    "    b[5] += err_rate * n\n",
    "    b[6] += cost_mean * n\n",
    "    b[7] += data_mean * n\n",
    "\n",
    "services = sorted(acc.keys())\n",
    "mat = np.zeros((len(services), 8), dtype=float)\n",
    "\n",
    "# Convert weighted sums to means where appropriate\n",
    "for i, s in enumerate(services):\n",
    "    v = acc[s].copy()\n",
    "    # consumer means\n",
    "    v[1] = v[1] / (v[0] + 1e-9)\n",
    "    v[2] = v[2] / (v[0] + 1e-9)\n",
    "    v[3] = v[3] / (v[0] + 1e-9)\n",
    "    # supplier means\n",
    "    v[5] = v[5] / (v[4] + 1e-9)\n",
    "    v[6] = v[6] / (v[4] + 1e-9)\n",
    "    v[7] = v[7] / (v[4] + 1e-9)\n",
    "    mat[i] = v\n",
    "\n",
    "# Cosine similarity on normalized vectors\n",
    "Xn = normalize(mat)\n",
    "S = cosine_similarity(Xn)\n",
    "\n",
    "neighbors = {}\n",
    "for i, s in enumerate(services):\n",
    "    order = np.argsort(-S[i])\n",
    "    top = [(services[j], float(S[i, j])) for j in order[1:k+1]]  # skip self\n",
    "    neighbors[s] = top\n",
    "\n",
    "print(\"Services:\", len(services), \"Vector shape:\", mat.shape)\n",
    "for i in range(min(5, len(services))):\n",
    "    print(services[i], \"->\", neighbors[services[i]][:k])\n",
    "\n",
    "with open(\"task2_neighbors.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"k\": k, \"neighbors\": neighbors}, f, indent=2)\n",
    "print(\"Saved task2_neighbors.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d121fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task2_neighbors.csv\n",
      "Saved: task2_clustering_results.csv\n",
      "Best k: 8  Silhouette(cosine): 0.9835  -> task2_clusters_k8.csv\n"
     ]
    }
   ],
   "source": [
    "# Task 2 tables: neighbors CSV + KMeans clustering (silhouette) summary\n",
    "import json, csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "assert 'services' in globals() and 'mat' in globals(), \"Run the Task 2 cell first.\"\n",
    "\n",
    "# 1) Neighbors CSV (top-5)\n",
    "Xn = normalize(mat)\n",
    "S = cosine_similarity(Xn)\n",
    "\n",
    "k = 5\n",
    "rows = []\n",
    "for i, s in enumerate(services):\n",
    "    order = np.argsort(-S[i])\n",
    "    nbrs = [(services[j], float(S[i,j])) for j in order[1:k+1]]\n",
    "    rows.append({\n",
    "        \"service\": s,\n",
    "        \"n1\": nbrs[0][0], \"s1\": nbrs[0][1],\n",
    "        \"n2\": nbrs[1][0], \"s2\": nbrs[1][1],\n",
    "        \"n3\": nbrs[2][0], \"s3\": nbrs[2][1],\n",
    "        \"n4\": nbrs[3][0], \"s4\": nbrs[3][1],\n",
    "        \"n5\": nbrs[4][0], \"s5\": nbrs[4][1],\n",
    "    })\n",
    "\n",
    "with open(\"task2_neighbors.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fieldnames = [\"service\",\"n1\",\"s1\",\"n2\",\"s2\",\"n3\",\"s3\",\"n4\",\"s4\",\"n5\",\"s5\"]\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    for r in rows: w.writerow(r)\n",
    "\n",
    "# 2) Clustering summary (silhouette across k)\n",
    "ks = [3,4,5,6,7,8,9,10]\n",
    "summary = []\n",
    "best = (None, -1.0, None)  # (k, score, labels)\n",
    "\n",
    "for k_ in ks:\n",
    "    km = KMeans(n_clusters=k_, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(Xn)\n",
    "    sil = silhouette_score(Xn, labels, metric=\"cosine\")\n",
    "    summary.append({\"Representation\":\"Role means (8-dim)\", \"Method\":\"KMeans\", \"k\":k_, \"Silhouette\":float(sil)})\n",
    "    if sil > best[1]:\n",
    "        best = (k_, sil, labels)\n",
    "\n",
    "with open(\"task2_clustering_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fieldnames = [\"Representation\",\"Method\",\"k\",\"Silhouette\"]\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    for r in summary: w.writerow(r)\n",
    "\n",
    "# Save best-k cluster assignments\n",
    "best_k, best_sil, best_labels = best\n",
    "with open(f\"task2_clusters_k{best_k}.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"service\",\"cluster\"])\n",
    "    for s, lbl in zip(services, best_labels):\n",
    "        w.writerow([s, int(lbl)])\n",
    "\n",
    "print(\"Saved: task2_neighbors.csv\")\n",
    "print(\"Saved: task2_clustering_results.csv\")\n",
    "print(f\"Best k: {best_k}  Silhouette(cosine): {best_sil:.4f}  -> task2_clusters_k{best_k}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aabf2259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task2_neighbors.csv\n",
      "Saved: task2_clustering_results.csv\n",
      "Best k: 8  Silhouette(cosine): 0.9835  -> task2_clusters_k8.csv\n"
     ]
    }
   ],
   "source": [
    "# Task 2 tables: neighbors CSV + KMeans clustering (silhouette) summary\n",
    "import json, csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "assert 'services' in globals() and 'mat' in globals(), \"Run the Task 2 cell first.\"\n",
    "\n",
    "# 1) Neighbors CSV (top-5)\n",
    "Xn = normalize(mat)\n",
    "S = cosine_similarity(Xn)\n",
    "\n",
    "k = 5\n",
    "rows = []\n",
    "for i, s in enumerate(services):\n",
    "    order = np.argsort(-S[i])\n",
    "    nbrs = [(services[j], float(S[i,j])) for j in order[1:k+1]]\n",
    "    rows.append({\n",
    "        \"service\": s,\n",
    "        \"n1\": nbrs[0][0], \"s1\": nbrs[0][1],\n",
    "        \"n2\": nbrs[1][0], \"s2\": nbrs[1][1],\n",
    "        \"n3\": nbrs[2][0], \"s3\": nbrs[2][1],\n",
    "        \"n4\": nbrs[3][0], \"s4\": nbrs[3][1],\n",
    "        \"n5\": nbrs[4][0], \"s5\": nbrs[4][1],\n",
    "    })\n",
    "\n",
    "with open(\"task2_neighbors.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fieldnames = [\"service\",\"n1\",\"s1\",\"n2\",\"s2\",\"n3\",\"s3\",\"n4\",\"s4\",\"n5\",\"s5\"]\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    for r in rows: w.writerow(r)\n",
    "\n",
    "# 2) Clustering summary (silhouette across k)\n",
    "ks = [3,4,5,6,7,8,9,10]\n",
    "summary = []\n",
    "best = (None, -1.0, None)  # (k, score, labels)\n",
    "\n",
    "for k_ in ks:\n",
    "    km = KMeans(n_clusters=k_, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(Xn)\n",
    "    sil = silhouette_score(Xn, labels, metric=\"cosine\")\n",
    "    summary.append({\"Representation\":\"Role means (8-dim)\", \"Method\":\"KMeans\", \"k\":k_, \"Silhouette\":float(sil)})\n",
    "    if sil > best[1]:\n",
    "        best = (k_, sil, labels)\n",
    "\n",
    "with open(\"task2_clustering_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fieldnames = [\"Representation\",\"Method\",\"k\",\"Silhouette\"]\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    for r in summary: w.writerow(r)\n",
    "\n",
    "# Save best-k cluster assignments\n",
    "best_k, best_sil, best_labels = best\n",
    "with open(f\"task2_clusters_k{best_k}.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"service\",\"cluster\"])\n",
    "    for s, lbl in zip(services, best_labels):\n",
    "        w.writerow([s, int(lbl)])\n",
    "\n",
    "print(\"Saved: task2_neighbors.csv\")\n",
    "print(\"Saved: task2_clustering_results.csv\")\n",
    "print(f\"Best k: {best_k}  Silhouette(cosine): {best_sil:.4f}  -> task2_clusters_k{best_k}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f831aa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tables_for_report.md\n",
      "# Results Tables\n",
      "\n",
      "## Task 1 — Insight Detection (Naive Bayes Baseline)\n",
      "\n",
      "| Feature Set / Variant | Precision | Recall | F1 | PR-AUC | Accuracy (+ve) | Accuracy (mean) | Threshold | Valid size | Pos rate (valid) |\n",
      "|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|\n",
      "| All features (NB) | 0.9028533849694933 | 0.9451902849493211 | 0.9235196292766784 | 0.9774733165108653 | 0.9451902849493211 | 0.9867125488986641 | 0.9806067807015026 | 308035 | 0.0848767185547097 |\n",
      "\n",
      "## Task 2 — Service Similarity (Top-5 Neighbors, sample)\n",
      "| service | n1 | s1 | n2 | s2 | n3 | s3 | n4 | s4 | n5 | s5 |\n",
      "|---|---|---:|---|---:|---|---:|---|---:|---|---:|\n",
      "| ABTEST | NOTIFY | 0.9999999999809024 | MKTDB | 0.9999999999349333 | DYNPRC | 0.9999999998786389 | XCHATTR | 0.9999999997867001 | TAXCALC | 0.9999999996770227 |\n",
      "| AIRFLW | HMFRP | 0.999999998609385 | YELLOWS | 0.9999999953721767 | KAFKA | 0.9999999888122127 | DDSD | 0.9999999793005887 | ELASTIC | 0.9999996950612356 |\n",
      "| ANALAPI | AUTOML | 0.9999992614814076 | RISKMG | 0.9999991143549807 | BILLING | 0.9999989627174771 | GLOBCMP | 0.9999989224119094 | SUPCHN | 0.9999988448202543 |\n",
      "| APIGWY | SNAPINT | 0.9999999992863867 | MULTILNG | 0.9999999971777137 | SLSDB | 0.9999999962098263 | TAXCALC | 0.9999999958172383 | XCHATTR | 0.9999999955270946 |\n",
      "| ATLAS | DATAHUB | 0.9999896440875172 | MDLREG | 0.9999718818442569 | JPNXPP | 0.999951212040954 | SPARK | 0.9999474668239722 | PANDRA | 0.9999318254451391 |\n",
      "| AUTOML | RISKMG | 0.9999999930268135 | BILLING | 0.9999999744404572 | GLOBCMP | 0.9999999675906348 | SUPCHN | 0.9999999532220397 | PAYPROC | 0.9999998582373713 |\n",
      "| AWS | AZURE | 0.9999999999941895 | SNWFLK | 0.9999999999270122 | DBRCKS | 0.9999999998043644 | HMFRP | 0.7071067811150845 | AIRFLW | 0.7071067796016148 |\n",
      "| AZURE | AWS | 0.9999999999941895 | SNWFLK | 0.9999999999622053 | DBRCKS | 0.9999999998659184 | HMFRP | 0.7071067811452451 | AIRFLW | 0.7071067797588978 |\n",
      "| BILLING | GLOBCMP | 0.999999999573766 | SUPCHN | 0.9999999968161862 | RISKMG | 0.9999999940065972 | AUTOML | 0.9999999744404572 | PAYPROC | 0.9999999528774104 |\n",
      "| CHURNP | FINPLAN | 0.9999999791190787 | INVOPT | 0.9999998271869271 | RTDASH | 0.9999997446540816 | GEOANL | 0.9999995496414685 | TRNPIPE | 0.9999972450839603 |\n",
      "\n",
      "## Task 2 — Clustering Summary (Silhouette, cosine)\n",
      "| Representation | Method | k | Silhouette |\n",
      "|---|---|---:|---:|\n",
      "| Role means (8-dim) | KMeans | 3 | 0.851158675092405 |\n",
      "| Role means (8-dim) | KMeans | 4 | 0.8687091680037328 |\n",
      "| Role means (8-dim) | KMeans | 5 | 0.933113627229332 |\n",
      "| Role means (8-dim) | KMeans | 6 | 0.9661969420545483 |\n",
      "| Role means (8-dim) | KMeans | 7 | 0.9631850236343544 |\n",
      "| Role means (8-dim) | KMeans | 8 | 0.9834557457986388 |\n",
      "| Role means (8-dim) | KMeans | 9 | 0.9743887732550746 |\n",
      "| Role means (8-dim) | KMeans | 10 | 0.9673060323981396 |\n"
     ]
    }
   ],
   "source": [
    "# Build a report-ready Markdown with Task 1 & Task 2 tables\n",
    "import csv, os, json\n",
    "\n",
    "task1_csv = \"task1_results.csv\"\n",
    "task2_neighbors_csv = \"task2_neighbors.csv\"\n",
    "task2_cluster_csv = \"task2_clustering_results.csv\"\n",
    "out_md = \"tables_for_report.md\"\n",
    "\n",
    "# --- load Task 1 (one row) ---\n",
    "with open(task1_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "    r = list(csv.DictReader(f))\n",
    "t1 = r[0] if r else {}\n",
    "\n",
    "# --- load Task 2 neighbors (limit to 10 services for the doc) ---\n",
    "rows_nbr = []\n",
    "if os.path.exists(task2_neighbors_csv):\n",
    "    with open(task2_neighbors_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        rows_nbr = list(csv.DictReader(f))\n",
    "rows_nbr = rows_nbr[:10]\n",
    "\n",
    "# --- load Task 2 clustering summary ---\n",
    "rows_clu = []\n",
    "if os.path.exists(task2_cluster_csv):\n",
    "    with open(task2_cluster_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        rows_clu = list(csv.DictReader(f))\n",
    "\n",
    "md = []\n",
    "\n",
    "md.append(\"# Results Tables\\n\")\n",
    "\n",
    "# Task 1 table\n",
    "md.append(\"## Task 1 — Insight Detection (Naive Bayes Baseline)\\n\")\n",
    "md.append(\"| Feature Set / Variant | Precision | Recall | F1 | PR-AUC | Accuracy (+ve) | Accuracy (mean) | Threshold | Valid size | Pos rate (valid) |\")\n",
    "md.append(\"|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|\")\n",
    "md.append(f\"| {t1.get('Feature Set / Variant','')} | {t1.get('Precision','')} | {t1.get('Recall','')} | {t1.get('F1','')} | {t1.get('PR-AUC','')} | {t1.get('Accuracy (+ve)','')} | {t1.get('Accuracy (mean)','')} | {t1.get('Threshold','')} | {t1.get('Valid size','')} | {t1.get('Pos rate (valid)','')} |\")\n",
    "md.append(\"\")\n",
    "\n",
    "# Task 2 neighbors table (sample)\n",
    "md.append(\"## Task 2 — Service Similarity (Top-5 Neighbors, sample)\")\n",
    "md.append(\"| service | n1 | s1 | n2 | s2 | n3 | s3 | n4 | s4 | n5 | s5 |\")\n",
    "md.append(\"|---|---|---:|---|---:|---|---:|---|---:|---|---:|\")\n",
    "for r in rows_nbr:\n",
    "    md.append(f\"| {r['service']} | {r['n1']} | {r['s1']} | {r['n2']} | {r['s2']} | {r['n3']} | {r['s3']} | {r['n4']} | {r['s4']} | {r['n5']} | {r['s5']} |\")\n",
    "md.append(\"\")\n",
    "\n",
    "# Task 2 clustering summary\n",
    "md.append(\"## Task 2 — Clustering Summary (Silhouette, cosine)\")\n",
    "if rows_clu:\n",
    "    md.append(\"| Representation | Method | k | Silhouette |\")\n",
    "    md.append(\"|---|---|---:|---:|\")\n",
    "    for r in rows_clu:\n",
    "        md.append(f\"| {r['Representation']} | {r['Method']} | {r['k']} | {r['Silhouette']} |\")\n",
    "else:\n",
    "    md.append(\"_No clustering summary file found._\")\n",
    "\n",
    "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(md))\n",
    "\n",
    "print(\"Saved:\", out_md)\n",
    "# preview first ~40 lines\n",
    "with open(out_md, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in zip(range(40), f):\n",
    "        print(line.rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "713e53ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task1_top_incidents.csv\n",
      "Top 3 preview:\n",
      "{'time_bucket': '2025-05-12 02:00:00', 'consumer_id': 'ECOMLP', 'supplier_id': 'MCSCBT', 'probability': 1.0, 'predicted_anomaly': 1, 'weak_label': 1, 'req_count': 6.0, 'error_rate': 0.0, 'cost_sum': 3539.9500000000007, 'cost_mean': 589.9916666666668, 'data_sum': 70.8, 'data_mean': 11.799999999999999}\n",
      "{'time_bucket': '2025-03-30 01:00:00', 'consumer_id': 'CUSTPRT', 'supplier_id': 'MCSCBT', 'probability': 1.0, 'predicted_anomaly': 1, 'weak_label': 1, 'req_count': 6.0, 'error_rate': 0.0, 'cost_sum': 3465.25, 'cost_mean': 577.5416666666666, 'data_sum': 73.05000000000001, 'data_mean': 12.175000000000002}\n",
      "{'time_bucket': '2025-03-25 05:00:00', 'consumer_id': 'ECOMLP', 'supplier_id': 'MCSCBT', 'probability': 1.0, 'predicted_anomaly': 1, 'weak_label': 1, 'req_count': 5.0, 'error_rate': 0.0, 'cost_sum': 2921.6, 'cost_mean': 584.3199999999999, 'data_sum': 59.25, 'data_mean': 11.85}\n"
     ]
    }
   ],
   "source": [
    "# Task 1 — Top-20 incidents (ranked by proba * cost_sum)\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the feature cell first.\"\n",
    "\n",
    "# Rebuild weak labels (same as earlier)\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "z_c = robust_z(cmean); z_d = robust_z(dmean)\n",
    "y = ((er > 0.10) | (z_c > 3.0) | (z_d > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split (80/20)\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "\n",
    "proba = model.predict_proba(Xva)[:,1]\n",
    "prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "bi = int(np.argmax(f1s))\n",
    "best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "pred = (proba >= best_thr).astype(int)\n",
    "\n",
    "# Rank by probability * cost_sum (impact proxy)\n",
    "cost_sum = Xva[:,2]\n",
    "score = proba * (cost_sum + 1e-9)\n",
    "order = np.argsort(-score)\n",
    "\n",
    "top_k = 20\n",
    "rows = []\n",
    "for r in order[:top_k]:\n",
    "    cons, supp, bucket = keys[valid_idx[r]]\n",
    "    req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean = Xva[r].tolist()\n",
    "    rows.append({\n",
    "        \"time_bucket\": bucket,\n",
    "        \"consumer_id\": cons,\n",
    "        \"supplier_id\": supp,\n",
    "        \"probability\": float(proba[r]),\n",
    "        \"predicted_anomaly\": int(pred[r]),\n",
    "        \"weak_label\": int(yva[r]),\n",
    "        \"req_count\": float(req_count),\n",
    "        \"error_rate\": float(error_rate),\n",
    "        \"cost_sum\": float(cost_sum),\n",
    "        \"cost_mean\": float(cost_mean),\n",
    "        \"data_sum\": float(data_sum),\n",
    "        \"data_mean\": float(data_mean)\n",
    "    })\n",
    "\n",
    "out_path = \"task1_top_incidents.csv\"\n",
    "with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    w.writeheader()\n",
    "    for rr in rows: w.writerow(rr)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"Top 3 preview:\")\n",
    "for rr in rows[:3]:\n",
    "    print(rr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9be0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task1_incident_summaries.md\n",
      "\n",
      "Preview:\n",
      "\n",
      "# Top Incidents — Brief Summaries\n",
      "\n",
      "## 2025-05-12 02:00:00 — ECOMLP → MCSCBT\n",
      "- **Anomaly score**: p=1.000 (confidence: high), predicted=1, weak_label=1\n",
      "- **Impact**: req=6, cost_sum=$3,539.95, cost/tx=589.99, data_sum=70.80, data/tx=11.80\n",
      "- **Signals**: cost/tx high (z=14.7), data/tx high (z=8.2)\n",
      "- **Next checks**: verify recent deployments/config for `MCSCBT`, inspect capacity/quotas, correlate with upstream `ECOMLP` traffic and provider billing.\n",
      "\n",
      "## 2025-03-30 01:00:00 — CUSTPRT → MCSCBT\n",
      "- **Anomaly score**: p=1.000 (confidence: high), predicted=1, weak_label=1\n",
      "- **Impact**: req=6, cost_sum=$3,465.25, cost/tx=577.54, data_sum=73.05, data/tx=12.18\n",
      "- **Signals**: cost/tx high (z=14.4), data/tx high (z=8.4)\n",
      "- **Next checks**: verify recent deployments/config for `MCSCBT`, inspect capacity/quotas, correlate with upstream `CUSTPRT` traffic and provider billing.\n",
      "\n",
      "## 2025-03-25 05:00:00 — ECOMLP → MCSCBT\n",
      "- **Anomaly score**: p=1.000 (confidence: high), predicted=1, weak_label=1\n",
      "- **Impact**: req=5, cost_sum=$2,921.60, cost/tx=584.32, data_sum=59.25, data/tx=11.85\n",
      "- **Signals**: cost/tx high (z=14.6), data/tx high (z=8.2)\n",
      "- **Next checks**: verify recent deployments/config for `MCSCBT`, inspect capacity/quotas, correlate with upstream `ECOMLP` traffic and provider billing.\n"
     ]
    }
   ],
   "source": [
    "# Build concise LLM-style summaries (template) for Top-20 incidents\n",
    "import csv, math\n",
    "import numpy as np\n",
    "\n",
    "assert 'X' in globals(), \"Run the feature cell first.\"\n",
    "\n",
    "# Globals from X to compute robust baselines\n",
    "# Features: [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "cmean_all = X[:,3]; dmean_all = X[:,5]; er_all = X[:,1]\n",
    "\n",
    "def robust_stats(x):\n",
    "    med = float(np.median(x))\n",
    "    mad = float(np.median(np.abs(x - med))) + 1e-9\n",
    "    return med, mad\n",
    "\n",
    "c_med, c_mad = robust_stats(cmean_all)\n",
    "d_med, d_mad = robust_stats(dmean_all)\n",
    "e_med, e_mad = robust_stats(er_all)\n",
    "\n",
    "def rz(val, med, mad):\n",
    "    return (abs(val - med) / (1.4826 * mad)) if mad > 0 else 0.0\n",
    "\n",
    "def conf_str(p):\n",
    "    return \"high\" if p >= 0.9 else (\"medium\" if p >= 0.7 else \"low\")\n",
    "\n",
    "rows = []\n",
    "with open(\"task1_top_incidents.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rows = list(csv.DictReader(f))\n",
    "\n",
    "lines = [\"# Top Incidents — Brief Summaries\\n\"]\n",
    "for r in rows:\n",
    "    tb   = r[\"time_bucket\"]\n",
    "    cons = r[\"consumer_id\"]\n",
    "    supp = r[\"supplier_id\"]\n",
    "    proba = float(r[\"probability\"])\n",
    "    pred  = int(r[\"predicted_anomaly\"])\n",
    "    lab   = int(r[\"weak_label\"])\n",
    "    req   = float(r[\"req_count\"])\n",
    "    er    = float(r[\"error_rate\"])\n",
    "    csum  = float(r[\"cost_sum\"])\n",
    "    cmean = float(r[\"cost_mean\"])\n",
    "    dsum  = float(r[\"data_sum\"])\n",
    "    dmean = float(r[\"data_mean\"])\n",
    "\n",
    "    z_c = rz(cmean, c_med, c_mad)\n",
    "    z_d = rz(dmean, d_med, d_mad)\n",
    "    z_e = rz(er,    e_med, e_mad)\n",
    "\n",
    "    reasons = []\n",
    "    if er > max(0.10, e_med + 2*1.4826*e_mad): reasons.append(f\"error rate spike ({er:.1%})\")\n",
    "    if z_c > 3: reasons.append(f\"cost/tx high (z={z_c:.1f})\")\n",
    "    if z_d > 3: reasons.append(f\"data/tx high (z={z_d:.1f})\")\n",
    "    if not reasons:\n",
    "        reasons.append(\"unusual pattern vs baseline\")\n",
    "\n",
    "    lines.append(f\"## {tb} — {cons} → {supp}\")\n",
    "    lines.append(f\"- **Anomaly score**: p={proba:.3f} (confidence: {conf_str(proba)}), predicted={pred}, weak_label={lab}\")\n",
    "    lines.append(f\"- **Impact**: req={req:.0f}, cost_sum=${csum:,.2f}, cost/tx={cmean:.2f}, data_sum={dsum:.2f}, data/tx={dmean:.2f}\")\n",
    "    lines.append(f\"- **Signals**: {', '.join(reasons)}\")\n",
    "    lines.append(f\"- **Next checks**: verify recent deployments/config for `{supp}`, inspect capacity/quotas, correlate with upstream `{cons}` traffic and provider billing.\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "out_md = \"task1_incident_summaries.md\"\n",
    "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Saved:\", out_md)\n",
    "print(\"\\nPreview:\\n\")\n",
    "print(\"\\n\".join(lines[:18]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8caec9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task1_results_variants.csv\n",
      "{'Feature Set / Variant': 'Counts only (NB)', 'Precision': 0.10568402532383772, 'Recall': 0.8179001721170396, 'F1': 0.1830056388612474, 'PR-AUC': 0.1021308496893949, 'Accuracy (+ve)': 0.9179575444635686, 'Accuracy (mean)': 0.3043420390540036, 'Threshold': 0.3514217132994965, 'Valid size': 308035, 'Pos rate (valid)': 0.0848767185547097}\n",
      "{'Feature Set / Variant': 'All features (NB)', 'Precision': 0.9028533849694933, 'Recall': 0.9451902849493211, 'F1': 0.9235196292766784, 'PR-AUC': 0.9774733165108653, 'Accuracy (+ve)': 0.9451902849493211, 'Accuracy (mean)': 0.9867125488986641, 'Threshold': 0.9806067807015026, 'Valid size': 308035, 'Pos rate (valid)': 0.0848767185547097}\n",
      "{'Feature Set / Variant': 'PCA(3) + NB', 'Precision': 0.6810904129423886, 'Recall': 0.9355517307324537, 'F1': 0.7882821186290465, 'PR-AUC': 0.6950759672884285, 'Accuracy (+ve)': 0.9355517307324537, 'Accuracy (mean)': 0.9573457561640722, 'Threshold': 0.154903618666408, 'Valid size': 308035, 'Pos rate (valid)': 0.0848767185547097}\n"
     ]
    }
   ],
   "source": [
    "# Task 1 variants: Counts-only (NB), All features (NB), PCA(3)+NB)\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, f1_score, accuracy_score\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the feature cell first.\"\n",
    "\n",
    "# --- weak labels (same as before) ---\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "z_c = robust_z(cmean); z_d = robust_z(dmean)\n",
    "y = ((er > 0.10) | (z_c > 3.0) | (z_d > 3.0)).astype(int)\n",
    "\n",
    "# time-based split\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr_all, ytr = X[train_idx], y[train_idx]\n",
    "Xva_all, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "def eval_model(model, Xtr, ytr, Xva, yva, label):\n",
    "    model.fit(Xtr, ytr)\n",
    "    proba = model.predict_proba(Xva)[:,1]\n",
    "    pr_auc = average_precision_score(yva, proba) if len(np.unique(yva))>1 else 0.0\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    acc_pos = accuracy_score(yva[yva==1], yhat[yva==1]) if np.any(yva==1) else 0.0\n",
    "    acc_mean = accuracy_score(yva, yhat)\n",
    "    return {\n",
    "        \"Feature Set / Variant\": label,\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"PR-AUC\": float(pr_auc),\n",
    "        \"Accuracy (+ve)\": float(acc_pos),\n",
    "        \"Accuracy (mean)\": float(acc_mean),\n",
    "        \"Threshold\": float(best_thr),\n",
    "        \"Valid size\": int(len(yva)),\n",
    "        \"Pos rate (valid)\": float(yva.mean())\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Variant 1: Counts only (req_count, error_rate) + NB\n",
    "rows.append(\n",
    "    eval_model(\n",
    "        Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]),\n",
    "        Xtr_all[:, [0,1]], ytr,\n",
    "        Xva_all[:, [0,1]], yva,\n",
    "        \"Counts only (NB)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Variant 2: All features (NB)\n",
    "rows.append(\n",
    "    eval_model(\n",
    "        Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]),\n",
    "        Xtr_all, ytr, Xva_all, yva,\n",
    "        \"All features (NB)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Variant 3: PCA(3) + NB\n",
    "rows.append(\n",
    "    eval_model(\n",
    "        Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=3, random_state=42)), (\"nb\", GaussianNB())]),\n",
    "        Xtr_all, ytr, Xva_all, yva,\n",
    "        \"PCA(3) + NB\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save multi-row CSV\n",
    "out_csv = \"task1_results_variants.csv\"\n",
    "with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    w.writeheader()\n",
    "    for r in rows: w.writerow(r)\n",
    "\n",
    "print(\"Saved:\", out_csv)\n",
    "for r in rows: print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77a9935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tables_for_report_full.md\n"
     ]
    }
   ],
   "source": [
    "# Build FINAL report tables (includes Task 1 variants + Task 2)\n",
    "import csv, os\n",
    "\n",
    "t1_var_csv = \"task1_results_variants.csv\"\n",
    "t2_nbr_csv = \"task2_neighbors.csv\"\n",
    "t2_clu_csv = \"task2_clustering_results.csv\"\n",
    "out_md = \"tables_for_report_full.md\"\n",
    "\n",
    "# --- load Task 1 variants ---\n",
    "with open(t1_var_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "    t1_rows = list(csv.DictReader(f))\n",
    "\n",
    "# --- load Task 2 neighbors (sample 10) ---\n",
    "rows_nbr = []\n",
    "if os.path.exists(t2_nbr_csv):\n",
    "    with open(t2_nbr_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        rows_nbr = list(csv.DictReader(f))[:10]\n",
    "\n",
    "# --- load Task 2 clustering summary ---\n",
    "rows_clu = []\n",
    "if os.path.exists(t2_clu_csv):\n",
    "    with open(t2_clu_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        rows_clu = list(csv.DictReader(f))\n",
    "\n",
    "lines = []\n",
    "lines.append(\"# Results Tables (Final)\\n\")\n",
    "\n",
    "# ---- Task 1 variants table ----\n",
    "hdr = [\"Feature Set / Variant\",\"Precision\",\"Recall\",\"F1\",\"PR-AUC\",\"Accuracy (+ve)\",\"Accuracy (mean)\",\"Threshold\",\"Valid size\",\"Pos rate (valid)\"]\n",
    "lines.append(\"## Task 1 — Insight Detection (Naive Bayes Variants)\\n\")\n",
    "lines.append(\"| \" + \" | \".join(hdr) + \" |\")\n",
    "lines.append(\"|\" + \"|\".join([\"---\"] + [\":---:\" for _ in hdr[1:]]) + \"|\")\n",
    "for r in t1_rows:\n",
    "    lines.append(\"| \" + \" | \".join(str(r[h]) for h in hdr) + \" |\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# ---- Task 2 neighbors (sample) ----\n",
    "lines.append(\"## Task 2 — Service Similarity (Top-5 Neighbors, sample)\")\n",
    "nbr_hdr = [\"service\",\"n1\",\"s1\",\"n2\",\"s2\",\"n3\",\"s3\",\"n4\",\"s4\",\"n5\",\"s5\"]\n",
    "lines.append(\"| \" + \" | \".join(nbr_hdr) + \" |\")\n",
    "lines.append(\"|\" + \"|\".join([\"---\",\"---\",\":---:\",\"---\",\":---:\",\"---\",\":---:\",\"---\",\":---:\",\"---\",\":---:\"]) + \"|\")\n",
    "for r in rows_nbr:\n",
    "    lines.append(\"| \" + \" | \".join(r[h] for h in nbr_hdr) + \" |\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# ---- Task 2 clustering summary ----\n",
    "lines.append(\"## Task 2 — Clustering Summary (Silhouette, cosine)\")\n",
    "if rows_clu:\n",
    "    lines.append(\"| Representation | Method | k | Silhouette |\")\n",
    "    lines.append(\"|---|---|---:|---:|\")\n",
    "    for r in rows_clu:\n",
    "        lines.append(f\"| {r['Representation']} | {r['Method']} | {r['k']} | {r['Silhouette']} |\")\n",
    "else:\n",
    "    lines.append(\"_No clustering summary file found._\")\n",
    "\n",
    "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Saved:\", out_md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a54699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KEYS ===\n",
      "['app/id', 'app/name', 'daily/label', 'daily/metric', 'daily/time', 'daily/value', 'tenant/id']\n",
      "\n",
      "=== FIRST 5 ROWS ===\n",
      "\n",
      "--- Row 1 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'daily/label': 'Cost', 'daily/metric': 'cost', 'daily/time': '2024-06-01T00:00:00', 'daily/value': 158758.2500000005, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 2 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'daily/label': 'Value', 'daily/metric': 'value', 'daily/time': '2024-06-01T00:00:00', 'daily/value': 4646.0999999999985, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 3 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'daily/label': 'Data Used', 'daily/metric': 'data_used', 'daily/time': '2024-06-01T00:00:00', 'daily/value': 4646.100000000008, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 4 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'daily/label': 'Data Sent', 'daily/metric': 'data_sent', 'daily/time': '2024-06-01T00:00:00', 'daily/value': 4646.0999999999985, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 5 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'daily/label': 'Requests Made', 'daily/metric': 'requests_made', 'daily/time': '2024-06-01T00:00:00', 'daily/value': 5490, 'tenant/id': 'DEMO'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect daily_metrics.jsonl (schema + first rows)\n",
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "def inspect_jsonl(path: str, n: int = 5):\n",
    "    keys_union, samples = set(), []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in islice(f, n):\n",
    "            if not line.strip(): \n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            samples.append(obj)\n",
    "            keys_union.update(obj.keys())\n",
    "    keys = sorted(keys_union)\n",
    "    print(\"=== KEYS ===\")\n",
    "    print(keys)\n",
    "    print(f\"\\n=== FIRST {len(samples)} ROWS ===\")\n",
    "    for i, obj in enumerate(samples, 1):\n",
    "        print(f\"\\n--- Row {i} ---\")\n",
    "        print({k: obj.get(k) for k in keys})\n",
    "\n",
    "inspect_jsonl(\"daily_metrics.jsonl\", n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740b3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows read: 444570\n",
      "Apps: 87\n",
      "Days (unique): 365\n",
      "Metrics included: ['cost', 'value', 'data_used', 'data_sent', 'requests_made', 'cost_per_request_made', 'cost_per_request_received', 'data_per_request', 'data_sent_per_received', 'data_used_per_received', 'requests_per_business_hour', 'requests_per_hour', 'requests_received', 'value_per_cost']\n",
      "Saved: daily_features.csv\n",
      "\n",
      "Preview:\n",
      "{'app_id': 'SELENE', 'day': '2024-06-01', 'cost': 158758.2500000005, 'value': 4646.0999999999985, 'data_used': 4646.100000000008, 'data_sent': 4646.0999999999985, 'requests_made': 5490.0, 'cost_per_request_made': 28.917714025501002, 'cost_per_request_received': 86.753142076503, 'data_per_request': 0.8462841530054659, 'data_sent_per_received': 2.538852459016393, 'data_used_per_received': 2.5388524590163977, 'requests_per_business_hour': 296.8, 'requests_per_hour': 228.75, 'requests_received': 1830.0, 'value_per_cost': 0.02926525078224271, 'cost_per_request': 28.917714025501002}\n",
      "{'app_id': 'AWS', 'day': '2024-06-01', 'cost': 0.0, 'value': 1342.6499999999983, 'data_used': 0.0, 'data_sent': 1342.6499999999983, 'requests_made': 0.0, 'cost_per_request_made': 0.0, 'cost_per_request_received': 0.0, 'data_per_request': 0.0, 'data_sent_per_received': 0.2919439008480101, 'data_used_per_received': 0.0, 'requests_per_business_hour': 185.5, 'requests_per_hour': 0.0, 'requests_received': 4599.0, 'value_per_cost': 1342649999999.9983, 'cost_per_request': 0.0}\n",
      "{'app_id': 'DBRCKS', 'day': '2024-06-01', 'cost': 0.0, 'value': 3673.200000000003, 'data_used': 0.0, 'data_sent': 3673.200000000003, 'requests_made': 0.0, 'cost_per_request_made': 0.0, 'cost_per_request_received': 0.0, 'data_per_request': 0.0, 'data_sent_per_received': 1.0727803738317765, 'data_used_per_received': 0.0, 'requests_per_business_hour': 138.5, 'requests_per_hour': 0.0, 'requests_received': 3424.0, 'value_per_cost': 3673200000000.003, 'cost_per_request': 0.0}\n",
      "{'app_id': 'SNWFLK', 'day': '2024-06-01', 'cost': 0.0, 'value': 2185.6499999999983, 'data_used': 0.0, 'data_sent': 2185.6499999999983, 'requests_made': 0.0, 'cost_per_request_made': 0.0, 'cost_per_request_received': 0.0, 'data_per_request': 0.0, 'data_sent_per_received': 0.9675298804780869, 'data_used_per_received': 0.0, 'requests_per_business_hour': 90.6, 'requests_per_hour': 0.0, 'requests_received': 2259.0, 'value_per_cost': 2185649999999.998, 'cost_per_request': 0.0}\n",
      "{'app_id': 'FRDETCT', 'day': '2024-06-01', 'cost': 11736.2, 'value': 176.24999999999997, 'data_used': 268.05, 'data_sent': 176.24999999999997, 'requests_made': 192.0, 'cost_per_request_made': 61.12604166666667, 'cost_per_request_received': 286.2487804878049, 'data_per_request': 1.3960937500000001, 'data_sent_per_received': 4.298780487804877, 'data_used_per_received': 6.537804878048781, 'requests_per_business_hour': 11.6, 'requests_per_hour': 8.0, 'requests_received': 41.0, 'value_per_cost': 0.015017637736234895, 'cost_per_request': 61.12604166666667}\n"
     ]
    }
   ],
   "source": [
    "# Pivot daily_metrics.jsonl -> daily_features.csv (per-app per-day)\n",
    "import json, csv\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "path = \"daily_metrics.jsonl\"\n",
    "\n",
    "def to_day(s: str):\n",
    "    for fmt in (\"%Y-%m-%dT%H:%M:%S\", \"%Y-%m-%d %H:%M:%S\"):\n",
    "        try:\n",
    "            return datetime.strptime(s, fmt).strftime(\"%Y-%m-%d\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# Accumulate values per (app_id, day, metric)\n",
    "agg = defaultdict(lambda: defaultdict(float))\n",
    "apps = set()\n",
    "metrics_seen = set()\n",
    "rows_read = 0\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        app = obj.get(\"app/id\")\n",
    "        day = to_day(obj.get(\"daily/time\", \"\"))\n",
    "        metric = obj.get(\"daily/metric\")\n",
    "        val = obj.get(\"daily/value\", 0.0) or 0.0\n",
    "        if not app or not day or not metric:\n",
    "            continue\n",
    "        agg[(app, day)][metric] += float(val)\n",
    "        apps.add(app)\n",
    "        metrics_seen.add(metric)\n",
    "        rows_read += 1\n",
    "\n",
    "metrics_base = [\"cost\", \"value\", \"data_used\", \"data_sent\", \"requests_made\"]\n",
    "ordered_metrics = [m for m in metrics_base if m in metrics_seen] + \\\n",
    "                  sorted([m for m in metrics_seen if m not in metrics_base])\n",
    "\n",
    "# Build rows + simple derived features\n",
    "out_rows = []\n",
    "for (app, day), mvals in agg.items():\n",
    "    row = {\"app_id\": app, \"day\": day}\n",
    "    for m in ordered_metrics:\n",
    "        row[m] = mvals.get(m, 0.0)\n",
    "\n",
    "    req  = row.get(\"requests_made\", 0.0)\n",
    "    cost = row.get(\"cost\", 0.0)\n",
    "    val  = row.get(\"value\", 0.0)\n",
    "    data_u = row.get(\"data_used\", 0.0)\n",
    "\n",
    "    row[\"cost_per_request\"] = (cost / max(req, 1.0)) if \"cost\" in ordered_metrics else 0.0\n",
    "    row[\"value_per_cost\"]   = (val / max(cost, 1e-9)) if (\"value\" in ordered_metrics and \"cost\" in ordered_metrics) else 0.0\n",
    "    row[\"data_per_request\"] = (data_u / max(req, 1.0)) if \"data_used\" in ordered_metrics else 0.0\n",
    "\n",
    "    out_rows.append(row)\n",
    "\n",
    "fieldnames = [\"app_id\", \"day\"] + ordered_metrics + [\"cost_per_request\", \"value_per_cost\", \"data_per_request\"]\n",
    "csv_path = \"daily_features.csv\"\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    for r in out_rows:\n",
    "        w.writerow(r)\n",
    "\n",
    "print(\"Rows read:\", rows_read)\n",
    "print(\"Apps:\", len(apps))\n",
    "print(\"Days (unique):\", len({d for _, d in agg.keys()}))\n",
    "print(\"Metrics included:\", ordered_metrics)\n",
    "print(\"Saved:\", csv_path)\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "for r in out_rows[:5]:\n",
    "    print({k: r.get(k) for k in fieldnames})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8485e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KEYS ===\n",
      "['app/id', 'app/name', 'monthly/created', 'monthly/label', 'monthly/metric', 'monthly/value', 'tenant/id']\n",
      "\n",
      "=== FIRST 5 ROWS ===\n",
      "\n",
      "--- Row 1 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'monthly/created': '2024-08-01T00:00:00', 'monthly/label': 'Cost', 'monthly/metric': 'cost', 'monthly/value': 1219070.7999999553, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 2 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'monthly/created': '2024-08-01T00:00:00', 'monthly/label': 'Value', 'monthly/metric': 'value', 'monthly/value': 35701.04999999981, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 3 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'monthly/created': '2024-08-01T00:00:00', 'monthly/label': 'Data Used', 'monthly/metric': 'data_used', 'monthly/value': 35701.049999999675, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 4 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'monthly/created': '2024-08-01T00:00:00', 'monthly/label': 'Data Sent', 'monthly/metric': 'data_sent', 'monthly/value': 35701.04999999981, 'tenant/id': 'DEMO'}\n",
      "\n",
      "--- Row 5 ---\n",
      "{'app/id': 'SELENE', 'app/name': 'Selene Customer Warehouse', 'monthly/created': '2024-08-01T00:00:00', 'monthly/label': 'Requests Made', 'monthly/metric': 'requests_made', 'monthly/value': 41964, 'tenant/id': 'DEMO'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect monthly_metrics.jsonl (schema + first rows)\n",
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "def inspect_jsonl(path: str, n: int = 5):\n",
    "    keys_union, samples = set(), []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in islice(f, n):\n",
    "            if not line.strip(): \n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            samples.append(obj)\n",
    "            keys_union.update(obj.keys())\n",
    "    keys = sorted(keys_union)\n",
    "    print(\"=== KEYS ===\")\n",
    "    print(keys)\n",
    "    print(f\"\\n=== FIRST {len(samples)} ROWS ===\")\n",
    "    for i, obj in enumerate(samples, 1):\n",
    "        print(f\"\\n--- Row {i} ---\")\n",
    "        print({k: obj.get(k) for k in keys})\n",
    "\n",
    "inspect_jsonl(\"monthly_metrics.jsonl\", n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3c9fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows read: 18270\n",
      "Apps: 87\n",
      "Months (unique): 10\n",
      "Metrics included: ['cost', 'value', 'data_used', 'data_sent', 'requests_made', 'requests_received', 'cost_per_request_made', 'cost_per_request_received', 'data_per_request', 'data_sent_per_received', 'data_used_per_received', 'outage_cost', 'outage_count', 'outage_duration', 'outage_efficiency', 'outage_frequency', 'outage_impact', 'outage_severity', 'rate_of_return', 'requests_per_business_hour', 'requests_per_hour']\n",
      "Saved: monthly_features.csv\n",
      "\n",
      "Preview:\n",
      "{'app_id': 'SELENE', 'month': '2024-08', 'cost': 1219070.7999999553, 'value': 35701.04999999981, 'data_used': 35701.049999999675, 'data_sent': 35701.04999999981, 'requests_made': 41964.0, 'requests_received': 13988.0, 'cost_per_request_made': 29.050395577160312, 'cost_per_request_received': 87.15118673148093, 'data_per_request': 0.8507542179010503, 'data_sent_per_received': 2.5522626537031603, 'data_used_per_received': 2.552262653703151, 'outage_cost': 0.0, 'outage_count': 2.0, 'outage_duration': 205.0, 'outage_efficiency': 0.0, 'outage_frequency': 1.0, 'outage_impact': 0.0, 'outage_severity': 102.5, 'rate_of_return': 0.029285460696787353, 'requests_per_business_hour': 264.6666666666667, 'requests_per_hour': 194.27777777777777, 'cost_per_request': 29.050395577160312, 'value_per_cost': 0.029285460696787353}\n",
      "{'app_id': 'AWS', 'month': '2024-08', 'cost': 0.0, 'value': 10423.349999999726, 'data_used': 0.0, 'data_sent': 10423.349999999726, 'requests_made': 0.0, 'requests_received': 35749.0, 'cost_per_request_made': 0.0, 'cost_per_request_received': 0.0, 'data_per_request': 0.0, 'data_sent_per_received': 0.291570393577435, 'data_used_per_received': 0.0, 'outage_cost': 0.0, 'outage_count': 0.0, 'outage_duration': 0.0, 'outage_efficiency': 0.0, 'outage_frequency': 0.0, 'outage_impact': 0.0, 'outage_severity': 0.0, 'rate_of_return': 0.0, 'requests_per_business_hour': 167.36666666666667, 'requests_per_hour': 0.0, 'cost_per_request': 0.0, 'value_per_cost': 10423349999999.725}\n",
      "{'app_id': 'DBRCKS', 'month': '2024-08', 'cost': 0.0, 'value': 27726.45000000023, 'data_used': 0.0, 'data_sent': 27726.45000000023, 'requests_made': 0.0, 'requests_received': 25793.0, 'cost_per_request_made': 0.0, 'cost_per_request_received': 0.0, 'data_per_request': 0.0, 'data_sent_per_received': 1.0749602605358133, 'data_used_per_received': 0.0, 'outage_cost': 0.0, 'outage_count': 0.0, 'outage_duration': 0.0, 'outage_efficiency': 0.0, 'outage_frequency': 0.0, 'outage_impact': 0.0, 'outage_severity': 0.0, 'rate_of_return': 0.0, 'requests_per_business_hour': 121.88888888888889, 'requests_per_hour': 0.0, 'cost_per_request': 0.0, 'value_per_cost': 27726450000000.227}\n",
      "{'app_id': 'SNWFLK', 'month': '2024-08', 'cost': 0.0, 'value': 17358.6, 'data_used': 0.0, 'data_sent': 17358.6, 'requests_made': 0.0, 'requests_received': 17780.0, 'cost_per_request_made': 0.0, 'cost_per_request_received': 0.0, 'data_per_request': 0.0, 'data_sent_per_received': 0.9762992125984251, 'data_used_per_received': 0.0, 'outage_cost': 0.0, 'outage_count': 0.0, 'outage_duration': 0.0, 'outage_efficiency': 0.0, 'outage_frequency': 0.0, 'outage_impact': 0.0, 'outage_severity': 0.0, 'rate_of_return': 0.0, 'requests_per_business_hour': 84.47777777777777, 'requests_per_hour': 0.0, 'cost_per_request': 0.0, 'value_per_cost': 17358599999999.998}\n",
      "{'app_id': 'RISKMG', 'month': '2024-08', 'cost': 67964.55000000002, 'value': 0.0, 'data_used': 1541.5499999999988, 'data_sent': 0.0, 'requests_made': 606.0, 'requests_received': 0.0, 'cost_per_request_made': 112.15272277227726, 'cost_per_request_received': 0.0, 'data_per_request': 2.543811881188117, 'data_sent_per_received': 0.0, 'data_used_per_received': 0.0, 'outage_cost': 0.0, 'outage_count': 0.0, 'outage_duration': 0.0, 'outage_efficiency': 0.0, 'outage_frequency': 0.0, 'outage_impact': 0.0, 'outage_severity': 0.0, 'rate_of_return': 0.0, 'requests_per_business_hour': 2.7, 'requests_per_hour': 2.8055555555555554, 'cost_per_request': 112.15272277227726, 'value_per_cost': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Pivot monthly_metrics.jsonl -> monthly_features.csv (per-app per-month)\n",
    "import json, csv\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "path = \"monthly_metrics.jsonl\"\n",
    "\n",
    "def to_month(s: str):\n",
    "    for fmt in (\"%Y-%m-%dT%H:%M:%S\", \"%Y-%m-%d %H:%M:%S\"):\n",
    "        try:\n",
    "            return datetime.strptime(s, fmt).strftime(\"%Y-%m\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# Accumulate values per (app_id, month, metric)\n",
    "agg = defaultdict(lambda: defaultdict(float))\n",
    "apps = set()\n",
    "metrics_seen = set()\n",
    "rows_read = 0\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        app = obj.get(\"app/id\")\n",
    "        month = to_month(obj.get(\"monthly/created\", \"\"))  # timestamp field\n",
    "        metric = obj.get(\"monthly/metric\")\n",
    "        val = obj.get(\"monthly/value\", 0.0) or 0.0\n",
    "        if not app or not month or not metric:\n",
    "            continue\n",
    "        agg[(app, month)][metric] += float(val)\n",
    "        apps.add(app)\n",
    "        metrics_seen.add(metric)\n",
    "        rows_read += 1\n",
    "\n",
    "metrics_base = [\"cost\",\"value\",\"data_used\",\"data_sent\",\"requests_made\",\"requests_received\"]\n",
    "ordered_metrics = [m for m in metrics_base if m in metrics_seen] + \\\n",
    "                  sorted([m for m in metrics_seen if m not in metrics_base])\n",
    "\n",
    "# Build rows + simple derived features\n",
    "out_rows = []\n",
    "for (app, month), mvals in agg.items():\n",
    "    row = {\"app_id\": app, \"month\": month}\n",
    "    for m in ordered_metrics:\n",
    "        row[m] = mvals.get(m, 0.0)\n",
    "\n",
    "    req  = row.get(\"requests_made\", 0.0)\n",
    "    cost = row.get(\"cost\", 0.0)\n",
    "    val  = row.get(\"value\", 0.0)\n",
    "    data_u = row.get(\"data_used\", 0.0)\n",
    "\n",
    "    row[\"cost_per_request\"] = (cost / max(req, 1.0)) if \"cost\" in ordered_metrics else 0.0\n",
    "    row[\"value_per_cost\"]   = (val / max(cost, 1e-9)) if (\"value\" in ordered_metrics and \"cost\" in ordered_metrics) else 0.0\n",
    "    row[\"data_per_request\"] = (data_u / max(req, 1.0)) if \"data_used\" in ordered_metrics else 0.0\n",
    "\n",
    "    out_rows.append(row)\n",
    "\n",
    "fieldnames = [\"app_id\",\"month\"] + ordered_metrics + [\"cost_per_request\",\"value_per_cost\",\"data_per_request\"]\n",
    "csv_path = \"monthly_features.csv\"\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    for r in out_rows:\n",
    "        w.writerow(r)\n",
    "\n",
    "print(\"Rows read:\", rows_read)\n",
    "print(\"Apps:\", len(apps))\n",
    "print(\"Months (unique):\", len({m for _, m in agg.keys()}))\n",
    "print(\"Metrics included:\", ordered_metrics)\n",
    "print(\"Saved:\", csv_path)\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "for r in out_rows[:5]:\n",
    "    print({k: r.get(k) for k in fieldnames})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f30ea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: watchlist_apps.csv\n",
      "Top 10 preview:\n",
      "{'app_id': 'MCSCBT', 'anomalies_consumer': 3010, 'score_consumer': 2247204.864172169, 'anomalies_supplier': 3069, 'score_supplier': 2627282.000003058, 'anomalies_total': 6079, 'score_total': 4874486.864175227, 'latest_month': '2025-05', 'cost_latest': 1522083.049999968, 'cost_mom_pct': 0.07695582850548877, 'value_per_cost_latest': 0.015829359639738805, 'outage_count_latest': 83.0, 'outage_duration_latest': 13955.0}\n",
      "{'app_id': 'CLVMDL', 'anomalies_consumer': 0, 'score_consumer': 4555.476827580488, 'anomalies_supplier': 6695, 'score_supplier': 2512970.4724194533, 'anomalies_total': 6695, 'score_total': 2517525.949247034, 'latest_month': '2025-05', 'cost_latest': 1249448.799999955, 'cost_mom_pct': 0.06576045593726959, 'value_per_cost_latest': 0.01809545937376611, 'outage_count_latest': 287.0, 'outage_duration_latest': 85770.0}\n",
      "{'app_id': 'CSTSEG', 'anomalies_consumer': 0, 'score_consumer': 10762.728691977702, 'anomalies_supplier': 3332, 'score_supplier': 1569913.3446396294, 'anomalies_total': 3332, 'score_total': 1580676.073331607, 'latest_month': '2025-05', 'cost_latest': 849081.7000000023, 'cost_mom_pct': 0.06634769737528308, 'value_per_cost_latest': 0.014266824971024585, 'outage_count_latest': 1571.0, 'outage_duration_latest': 239785.0}\n",
      "{'app_id': 'SELENE', 'anomalies_consumer': 0, 'score_consumer': 2.0304696855699883e-134, 'anomalies_supplier': 0, 'score_supplier': 1402166.6285491423, 'anomalies_total': 0, 'score_total': 1402166.6285491423, 'latest_month': '2025-05', 'cost_latest': 4452273.550000766, 'cost_mom_pct': 0.04600896213907379, 'value_per_cost_latest': 0.029246720476098772, 'outage_count_latest': 2.0, 'outage_duration_latest': 205.0}\n",
      "{'app_id': 'CUSTPRT', 'anomalies_consumer': 2398, 'score_consumer': 1370124.0668129628, 'anomalies_supplier': 0, 'score_supplier': 0.0, 'anomalies_total': 2398, 'score_total': 1370124.0668129628, 'latest_month': '2025-05', 'cost_latest': 708209.9499999983, 'cost_mom_pct': 0.10269449470147067, 'value_per_cost_latest': 0.0, 'outage_count_latest': 16.0, 'outage_duration_latest': 1505.0}\n",
      "{'app_id': 'MOBAPP', 'anomalies_consumer': 2332, 'score_consumer': 1359245.272597053, 'anomalies_supplier': 0, 'score_supplier': 0.0, 'anomalies_total': 2332, 'score_total': 1359245.272597053, 'latest_month': '2025-05', 'cost_latest': 839258.6499999962, 'cost_mom_pct': 0.1474099290780082, 'value_per_cost_latest': 0.0, 'outage_count_latest': 94.0, 'outage_duration_latest': 7320.0}\n",
      "{'app_id': 'NXPCR', 'anomalies_consumer': 0, 'score_consumer': 39375.629084546905, 'anomalies_supplier': 1662, 'score_supplier': 1264470.6331996147, 'anomalies_total': 1662, 'score_total': 1303846.2622841615, 'latest_month': '2025-05', 'cost_latest': 709015.0499999976, 'cost_mom_pct': 0.09823546427537842, 'value_per_cost_latest': 0.017724800058898628, 'outage_count_latest': 68.0, 'outage_duration_latest': 9765.0}\n",
      "{'app_id': 'ECOMLP', 'anomalies_consumer': 1525, 'score_consumer': 1188310.9207149453, 'anomalies_supplier': 0, 'score_supplier': 0.0, 'anomalies_total': 1525, 'score_total': 1188310.9207149453, 'latest_month': '2025-05', 'cost_latest': 760425.2499999962, 'cost_mom_pct': 0.0675479634819133, 'value_per_cost_latest': 0.0, 'outage_count_latest': 3.0, 'outage_duration_latest': 395.0}\n",
      "{'app_id': 'MLOPS', 'anomalies_consumer': 2792, 'score_consumer': 1061194.7956829409, 'anomalies_supplier': 0, 'score_supplier': 0.0, 'anomalies_total': 2792, 'score_total': 1061194.7956829409, 'latest_month': '2025-05', 'cost_latest': 456126.49999999924, 'cost_mom_pct': 0.08050451725798735, 'value_per_cost_latest': 0.0, 'outage_count_latest': 0.0, 'outage_duration_latest': 0.0}\n",
      "{'app_id': 'FEATSTR', 'anomalies_consumer': 0, 'score_consumer': 54346.14585472198, 'anomalies_supplier': 3021, 'score_supplier': 889759.6047474698, 'anomalies_total': 3021, 'score_total': 944105.7506021918, 'latest_month': '2025-05', 'cost_latest': 374757.45000000106, 'cost_mom_pct': 0.028273741744478362, 'value_per_cost_latest': 0.01912917274893397, 'outage_count_latest': 0.0, 'outage_duration_latest': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Build a ranked WATCHLIST of apps (combine Task 1 anomalies + monthly trends)\n",
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the transactions feature cell first.\"\n",
    "\n",
    "# ---------- Re-train Task 1 model on same split ----------\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "proba = model.predict_proba(Xva)[:,1]\n",
    "prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "bi = int(np.argmax(f1s))\n",
    "best_thr = thr[bi-1] if bi>0 and (bi-1) < len(thr) else 0.5\n",
    "pred = (proba >= best_thr).astype(int)\n",
    "\n",
    "# ---------- Aggregate anomalies per app (consumer & supplier roles) ----------\n",
    "cons_stats = defaultdict(lambda: {\"count\":0, \"score\":0.0})\n",
    "supp_stats = defaultdict(lambda: {\"count\":0, \"score\":0.0})\n",
    "\n",
    "for va_idx, glob_idx in enumerate(valid_idx):\n",
    "    cons, supp, _bucket = keys[glob_idx]\n",
    "    req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean = Xva[va_idx]\n",
    "    p = proba[va_idx]; yhat = pred[va_idx]\n",
    "    impact = p * (cost_sum + 1e-9)\n",
    "    if yhat == 1:\n",
    "        cons_stats[cons][\"count\"] += 1\n",
    "        supp_stats[supp][\"count\"] += 1\n",
    "    cons_stats[cons][\"score\"] += impact\n",
    "    supp_stats[supp][\"score\"] += impact\n",
    "\n",
    "# ---------- Monthly trends (latest + MoM change) ----------\n",
    "monthly_path = \"monthly_features.csv\"\n",
    "monthly = defaultdict(dict)  # monthly[app][month] = metrics dict\n",
    "try:\n",
    "    with open(monthly_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            app = row[\"app_id\"]; month = row[\"month\"]\n",
    "            monthly[app][month] = row\n",
    "except FileNotFoundError:\n",
    "    pass  # if monthly not present, we will just skip trend columns\n",
    "\n",
    "def latest_mom(app):\n",
    "    if app not in monthly or not monthly[app]:\n",
    "        return (\"\", \"\", \"\", \"\", \"\")\n",
    "    months = sorted(monthly[app].keys())  # 'YYYY-MM' sorts lexicographically\n",
    "    latest = months[-1]\n",
    "    prev = months[-2] if len(months) >= 2 else None\n",
    "    r_latest = monthly[app][latest]\n",
    "    def fget(k):\n",
    "        try: return float(r_latest.get(k, \"0\") or 0.0)\n",
    "        except: return 0.0\n",
    "    cost_latest = fget(\"cost\")\n",
    "    vpc_latest = fget(\"value_per_cost\")\n",
    "    oc_latest  = float(r_latest.get(\"outage_count\", 0.0) or 0.0)\n",
    "    od_latest  = float(r_latest.get(\"outage_duration\", 0.0) or 0.0)\n",
    "    if prev:\n",
    "        try:\n",
    "            cost_prev = float((monthly[app][prev].get(\"cost\", \"0\") or 0.0))\n",
    "            mom = (cost_latest - cost_prev) / (cost_prev + 1e-9)\n",
    "        except:\n",
    "            mom = \"\"\n",
    "    else:\n",
    "        mom = \"\"\n",
    "    return (latest, cost_latest, mom, vpc_latest, (oc_latest, od_latest))\n",
    "\n",
    "# ---------- Build watchlist rows ----------\n",
    "apps = set(list(cons_stats.keys()) + list(supp_stats.keys()) + list(monthly.keys()))\n",
    "rows = []\n",
    "for app in apps:\n",
    "    c = cons_stats.get(app, {\"count\":0,\"score\":0.0})\n",
    "    s = supp_stats.get(app, {\"count\":0,\"score\":0.0})\n",
    "    latest, cost_latest, mom, vpc, outages = latest_mom(app)\n",
    "    oc, od = (outages if outages else (0.0, 0.0))\n",
    "    rows.append({\n",
    "        \"app_id\": app,\n",
    "        \"anomalies_consumer\": int(c[\"count\"]),\n",
    "        \"score_consumer\": float(c[\"score\"]),\n",
    "        \"anomalies_supplier\": int(s[\"count\"]),\n",
    "        \"score_supplier\": float(s[\"score\"]),\n",
    "        \"anomalies_total\": int(c[\"count\"] + s[\"count\"]),\n",
    "        \"score_total\": float(c[\"score\"] + s[\"score\"]),\n",
    "        \"latest_month\": latest,\n",
    "        \"cost_latest\": float(cost_latest) if cost_latest != \"\" else \"\",\n",
    "        \"cost_mom_pct\": float(mom) if mom != \"\" else \"\",\n",
    "        \"value_per_cost_latest\": float(vpc) if vpc != \"\" else \"\",\n",
    "        \"outage_count_latest\": float(oc),\n",
    "        \"outage_duration_latest\": float(od)\n",
    "    })\n",
    "\n",
    "# Rank by score_total desc\n",
    "rows.sort(key=lambda r: r[\"score_total\"], reverse=True)\n",
    "\n",
    "# Save CSV + preview\n",
    "out_csv = \"watchlist_apps.csv\"\n",
    "with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fn = list(rows[0].keys()) if rows else []\n",
    "    w = csv.DictWriter(f, fieldnames=fn)\n",
    "    w.writeheader()\n",
    "    for r in rows: w.writerow(r)\n",
    "\n",
    "print(\"Saved:\", out_csv)\n",
    "print(\"Top 10 preview:\")\n",
    "for r in rows[:10]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eff56c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: report_pack.md\n",
      "# Trufflow 1B — Data Product Insight Recommendation\n",
      "\n",
      "## Summary\n",
      "- **Task 1 (Insight Detection, NB)**: strong PR-AUC and F1 on weak labels; threshold tuned by F1.\n",
      "- **Task 2 (Service Similarity)**: cosine NN and KMeans; high silhouette with compact role vectors.\n",
      "- **Watchlist**: ranked by anomaly impact × cost; includes latest month KPIs.\n",
      "\n",
      "Artifacts: `task1_results_variants.csv`, `task1_top_incidents.csv`, `task2_neighbors.csv`, `task2_clustering_results.csv`, `watchlist_apps.csv`.\n",
      "\n",
      "## Task 1 — Insight Detection (Naive Bayes Variants)\n",
      "\n",
      "| Feature Set / Variant | Precision | Recall | F1 | PR-AUC | Accuracy (+ve) | Accuracy (mean) | Threshold | Valid size | Pos rate (valid) |\n",
      "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "| Counts only (NB) | 0.10568402532383772 | 0.8179001721170396 | 0.1830056388612474 | 0.1021308496893949 | 0.9179575444635686 | 0.3043420390540036 | 0.3514217132994965 | 308035 | 0.0848767185547097 |\n",
      "| All features (NB) | 0.9028533849694933 | 0.9451902849493211 | 0.9235196292766784 | 0.9774733165108653 | 0.9451902849493211 | 0.9867125488986641 | 0.9806067807015026 | 308035 | 0.0848767185547097 |\n",
      "| PCA(3) + NB | 0.6810904129423886 | 0.9355517307324537 | 0.7882821186290465 | 0.6950759672884285 | 0.9355517307324537 | 0.9573457561640722 | 0.154903618666408 | 308035 | 0.0848767185547097 |\n",
      "\n",
      "## Task 2 — Service Similarity (Top-5 Neighbors, sample)\n",
      "\n",
      "| service | n1 | s1 | n2 | s2 | n3 | s3 | n4 | s4 | n5 | s5 |\n",
      "|---|---|---:|---|---:|---|---:|---|---:|---|---:|\n",
      "| ABTEST | NOTIFY | 0.9999999999809024 | MKTDB | 0.9999999999349333 | DYNPRC | 0.9999999998786389 | XCHATTR | 0.9999999997867001 | TAXCALC | 0.9999999996770227 |\n",
      "| AIRFLW | HMFRP | 0.999999998609385 | YELLOWS | 0.9999999953721767 | KAFKA | 0.9999999888122127 | DDSD | 0.9999999793005887 | ELASTIC | 0.9999996950612356 |\n",
      "| ANALAPI | AUTOML | 0.9999992614814076 | RISKMG | 0.9999991143549807 | BILLING | 0.9999989627174771 | GLOBCMP | 0.9999989224119094 | SUPCHN | 0.9999988448202543 |\n",
      "| APIGWY | SNAPINT | 0.9999999992863867 | MULTILNG | 0.9999999971777137 | SLSDB | 0.9999999962098263 | TAXCALC | 0.9999999958172383 | XCHATTR | 0.9999999955270946 |\n",
      "| ATLAS | DATAHUB | 0.9999896440875172 | MDLREG | 0.9999718818442569 | JPNXPP | 0.999951212040954 | SPARK | 0.9999474668239722 | PANDRA | 0.9999318254451391 |\n",
      "| AUTOML | RISKMG | 0.9999999930268135 | BILLING | 0.9999999744404572 | GLOBCMP | 0.9999999675906348 | SUPCHN | 0.9999999532220397 | PAYPROC | 0.9999998582373713 |\n",
      "| AWS | AZURE | 0.9999999999941895 | SNWFLK | 0.9999999999270122 | DBRCKS | 0.9999999998043644 | HMFRP | 0.7071067811150845 | AIRFLW | 0.7071067796016148 |\n",
      "| AZURE | AWS | 0.9999999999941895 | SNWFLK | 0.9999999999622053 | DBRCKS | 0.9999999998659184 | HMFRP | 0.7071067811452451 | AIRFLW | 0.7071067797588978 |\n",
      "| BILLING | GLOBCMP | 0.999999999573766 | SUPCHN | 0.9999999968161862 | RISKMG | 0.9999999940065972 | AUTOML | 0.9999999744404572 | PAYPROC | 0.9999999528774104 |\n"
     ]
    }
   ],
   "source": [
    "# Build a concise, slide-ready report: report_pack.md\n",
    "import csv, os\n",
    "\n",
    "t1_var_csv   = \"task1_results_variants.csv\"\n",
    "t2_nbr_csv   = \"task2_neighbors.csv\"\n",
    "t2_clu_csv   = \"task2_clustering_results.csv\"\n",
    "inc_md       = \"task1_incident_summaries.md\"\n",
    "watch_csv    = \"watchlist_apps.csv\"\n",
    "\n",
    "out_md = \"report_pack.md\"\n",
    "lines = []\n",
    "\n",
    "lines += [\n",
    "    \"# Trufflow 1B — Data Product Insight Recommendation\",\n",
    "    \"\",\n",
    "    \"## Summary\",\n",
    "    \"- **Task 1 (Insight Detection, NB)**: strong PR-AUC and F1 on weak labels; threshold tuned by F1.\",\n",
    "    \"- **Task 2 (Service Similarity)**: cosine NN and KMeans; high silhouette with compact role vectors.\",\n",
    "    \"- **Watchlist**: ranked by anomaly impact × cost; includes latest month KPIs.\",\n",
    "    \"\",\n",
    "    \"Artifacts: `task1_results_variants.csv`, `task1_top_incidents.csv`, `task2_neighbors.csv`, `task2_clustering_results.csv`, `watchlist_apps.csv`.\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "# Task 1 table\n",
    "if os.path.exists(t1_var_csv):\n",
    "    with open(t1_var_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        rows = list(csv.DictReader(f))\n",
    "    hdr = [\"Feature Set / Variant\",\"Precision\",\"Recall\",\"F1\",\"PR-AUC\",\"Accuracy (+ve)\",\"Accuracy (mean)\",\"Threshold\",\"Valid size\",\"Pos rate (valid)\"]\n",
    "    lines += [\"## Task 1 — Insight Detection (Naive Bayes Variants)\", \"\"]\n",
    "    lines += [\"| \" + \" | \".join(hdr) + \" |\"]\n",
    "    lines += [\"|\" + \"|\".join([\"---\"] + [\":---:\" for _ in hdr[1:]]) + \"|\"]\n",
    "    for r in rows:\n",
    "        lines += [\"| \" + \" | \".join(str(r[h]) for h in hdr) + \" |\"]\n",
    "    lines += [\"\"]\n",
    "\n",
    "# Task 2 neighbors (sample)\n",
    "if os.path.exists(t2_nbr_csv):\n",
    "    with open(t2_nbr_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        nbr_rows = list(csv.DictReader(f))[:10]\n",
    "    lines += [\"## Task 2 — Service Similarity (Top-5 Neighbors, sample)\", \"\"]\n",
    "    hdr = [\"service\",\"n1\",\"s1\",\"n2\",\"s2\",\"n3\",\"s3\",\"n4\",\"s4\",\"n5\",\"s5\"]\n",
    "    lines += [\"| \" + \" | \".join(hdr) + \" |\"]\n",
    "    lines += [\"|---|---|---:|---|---:|---|---:|---|---:|---|---:|\"]\n",
    "    for r in nbr_rows:\n",
    "        lines += [\"| \" + \" | \".join(r[h] for h in hdr) + \" |\"]\n",
    "    lines += [\"\"]\n",
    "\n",
    "# Task 2 clustering summary\n",
    "if os.path.exists(t2_clu_csv):\n",
    "    with open(t2_clu_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        clu_rows = list(csv.DictReader(f))\n",
    "    lines += [\"## Task 2 — Clustering Summary (Silhouette, cosine)\", \"\"]\n",
    "    lines += [\"| Representation | Method | k | Silhouette |\"]\n",
    "    lines += [\"|---|---|---:|---:|\"]\n",
    "    for r in clu_rows:\n",
    "        lines += [f\"| {r['Representation']} | {r['Method']} | {r['k']} | {r['Silhouette']} |\"]\n",
    "    lines += [\"\"]\n",
    "\n",
    "# Watchlist Top-20\n",
    "if os.path.exists(watch_csv):\n",
    "    with open(watch_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        wrows = list(csv.DictReader(f))[:20]\n",
    "    lines += [\"## Watchlist — Top 20 Apps (by anomaly impact × cost)\", \"\"]\n",
    "    hdr = [\"app_id\",\"anomalies_total\",\"score_total\",\"latest_month\",\"cost_latest\",\"cost_mom_pct\",\"value_per_cost_latest\",\"outage_count_latest\",\"outage_duration_latest\"]\n",
    "    lines += [\"| \" + \" | \".join(hdr) + \" |\"]\n",
    "    lines += [\"|---|---:|---:|---|---:|---:|---:|---:|---:|\"]\n",
    "    for r in wrows:\n",
    "        lines += [\"| \" + \" | \".join(str(r.get(h, \"\")) for h in hdr) + \" |\"]\n",
    "    lines += [\"\"]\n",
    "\n",
    "# Top incident summaries (sample)\n",
    "if os.path.exists(inc_md):\n",
    "    lines += [\"## Top Incidents — Brief Summaries (sample)\", \"\"]\n",
    "    with open(inc_md, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in zip(range(40), f):  # ~first 40 lines\n",
    "            lines.append(line.rstrip())\n",
    "    lines += [\"\", f\"_See full: `{inc_md}`_\"]\n",
    "\n",
    "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Saved:\", out_md)\n",
    "with open(out_md, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in zip(range(30), f):\n",
    "        print(line.rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8bffcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure: task1_pr_curve.png\n",
      "{'avg_precision': 0.9774733165108653, 'best_F1': 0.9235368856651477, 'best_point': {'precision': 0.9028533849694933, 'recall': 0.9451902849493211}, 'best_threshold': 0.9806067807015026}\n"
     ]
    }
   ],
   "source": [
    "# PR curve for Task 1 (uses X, keys from earlier)\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the feature cell first.\"\n",
    "\n",
    "# Rebuild weak labels\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "# Train NB\n",
    "model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "\n",
    "# PR data\n",
    "proba = model.predict_proba(Xva)[:,1]\n",
    "prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "bi = int(np.argmax(f1s))\n",
    "best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "best_f1 = float(f1s[bi])\n",
    "ap = float(average_precision_score(yva, proba))\n",
    "\n",
    "# Try to plot; if matplotlib unavailable, save CSV instead\n",
    "plotted = False\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec, label=f\"PR curve (AP={ap:.3f})\")\n",
    "    # Mark best F1 point\n",
    "    plt.scatter([rec[bi]], [prec[bi]], s=40)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Task 1 — Precision–Recall\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"task1_pr_curve.png\", dpi=150)\n",
    "    plt.show()\n",
    "    print(\"Saved figure: task1_pr_curve.png\")\n",
    "    plotted = True\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "if not plotted:\n",
    "    import csv\n",
    "    with open(\"task1_pr_curve.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f); w.writerow([\"recall\",\"precision\"])\n",
    "        for r_, p_ in zip(rec, prec): w.writerow([float(r_), float(p_)])\n",
    "    print(\"matplotlib unavailable — saved curve points to task1_pr_curve.csv\")\n",
    "\n",
    "print({\n",
    "    \"avg_precision\": ap,\n",
    "    \"best_F1\": best_f1,\n",
    "    \"best_point\": {\"precision\": float(prec[bi]), \"recall\": float(rec[bi])},\n",
    "    \"best_threshold\": float(best_thr)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8be492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION (labels=[0,1]):\n",
      "[[279230   2660]\n",
      " [  1433  24712]]\n",
      "\n",
      "METRICS:\n",
      "{'threshold': 0.9806067807015026, 'avg_precision': 0.9774733165108653, 'accuracy': 0.9867125488986641, 'precision': 0.9028204004091772, 'recall': 0.9451902849493211, 'f1': 0.9235196292766784, 'pos_rate_valid': 0.0848767185547097, 'pred_pos_rate': 0.08886003213920496, 'TN': 279230, 'FP': 2660, 'FN': 1433, 'TP': 24712}\n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9906    0.9927    281890\n",
      "           1     0.9028    0.9452    0.9235     26145\n",
      "\n",
      "    accuracy                         0.9867    308035\n",
      "   macro avg     0.9489    0.9679    0.9581    308035\n",
      "weighted avg     0.9871    0.9867    0.9869    308035\n",
      "\n",
      "\n",
      "Saved: task1_confusion_matrix.csv, task1_confusion_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix + classification report at best-F1 threshold (Task 1)\n",
    "import numpy as np, csv, json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the feature cell first.\"\n",
    "\n",
    "# Rebuild weak labels (same rule used before)\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "# Train & score\n",
    "model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "proba = model.predict_proba(Xva)[:,1]\n",
    "\n",
    "# Best-F1 threshold (same as PR cell)\n",
    "prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "bi = int(np.argmax(f1s))\n",
    "best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "\n",
    "# Predictions at chosen threshold\n",
    "yhat = (proba >= best_thr).astype(int)\n",
    "\n",
    "# Confusion matrix + metrics\n",
    "cm = confusion_matrix(yva, yhat, labels=[0,1])\n",
    "TN, FP, FN, TP = int(cm[0,0]), int(cm[0,1]), int(cm[1,0]), int(cm[1,1])\n",
    "metrics = {\n",
    "    \"threshold\": float(best_thr),\n",
    "    \"avg_precision\": float(average_precision_score(yva, proba)),\n",
    "    \"accuracy\": float(accuracy_score(yva, yhat)),\n",
    "    \"precision\": float(precision_score(yva, yhat, zero_division=0)),\n",
    "    \"recall\": float(recall_score(yva, yhat, zero_division=0)),\n",
    "    \"f1\": float(f1_score(yva, yhat, zero_division=0)),\n",
    "    \"pos_rate_valid\": float(yva.mean()),\n",
    "    \"pred_pos_rate\": float(yhat.mean()),\n",
    "    \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP\n",
    "}\n",
    "\n",
    "print(\"CONFUSION (labels=[0,1]):\")\n",
    "print(cm)\n",
    "print(\"\\nMETRICS:\")\n",
    "print(metrics)\n",
    "\n",
    "print(\"\\nCLASSIFICATION REPORT:\")\n",
    "print(classification_report(yva, yhat, digits=4))\n",
    "\n",
    "# Save matrix + summary\n",
    "with open(\"task1_confusion_matrix.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"\", \"Pred_0\", \"Pred_1\"])\n",
    "    w.writerow([\"Actual_0\", TN, FP])\n",
    "    w.writerow([\"Actual_1\", FN, TP])\n",
    "\n",
    "with open(\"task1_confusion_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved: task1_confusion_matrix.csv, task1_confusion_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55631658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: milestone1_key_tables.md\n",
      "# Key Results — Milestone 1\n",
      "\n",
      "## Transactions — Coverage\n",
      "| Item | Value |\n",
      "|---|---:|\n",
      "| Transactions rows read | **7,254,656** |\n",
      "| Aggregated hourly windows | **1,540,175** |\n",
      "| Feature matrix shape | **(1,540,175, 6)** |\n",
      "\n",
      "## Data & Feature Engineering (Daily/Monthly)\n",
      "| Item | Value |\n",
      "|---|---:|\n",
      "| Unique services represented | **87** |\n",
      "| Daily metrics rows / days | **666,855 / 365** |\n",
      "| Monthly metrics rows / months | **18,270 / 10** |\n",
      "\n",
      "## Task 1 — Naive Bayes (baseline + variants)\n",
      "| Feature Set / Variant | Precision | Recall | F1 | PR-AUC | Accuracy (mean) | Threshold | Valid size | Pos rate (valid) |\n",
      "|---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
      "| Counts only (NB) | 0.1057 | 0.8179 | 0.183 | 0.1021 | 0.3043 | 0.3514 | 308,035 | 0.0849 |\n",
      "| All features (NB) | 0.9029 | 0.9452 | 0.9235 | 0.9775 | 0.9867 | 0.9806 | 308,035 | 0.0849 |\n",
      "| PCA(3) + NB | 0.6811 | 0.9356 | 0.7883 | 0.6951 | 0.9573 | 0.1549 | 308,035 | 0.0849 |\n",
      "\n",
      "## Task 1 — PR/Threshold & Confusion (at best-F1 threshold)\n",
      "| Metric | Value |\n",
      "|---|---:|\n",
      "| Best threshold (by F1) | **0.9806** |\n",
      "| Average precision (PR-AUC) | **0.9775** |\n",
      "| Accuracy (mean) | **0.9867** |\n",
      "| Precision / Recall | **0.9028 / 0.9452** |\n",
      "| F1 | **0.9235** |\n",
      "| Validation positive rate | **0.0849** |\n",
      "| Predicted positive rate | **0.0889** |\n",
      "| Confusion matrix (valid) | **TN=279,230  FP=2,660  FN=1,433  TP=24,712** |\n",
      "\n",
      "## Task 1 — Top Incidents (from transactions, Top 10)\n",
      "| time_bucket | consumer_id | supplier_id | probability | predicted_anomaly | weak_label | req_count | error_rate | cost_sum | cost_mean | data_sum | data_mean |\n",
      "|---|---|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|\n",
      "| 2025-05-12 02:00:00 | ECOMLP | MCSCBT | 1 | 1 | 1 | 6 | 0 | 3,539.95 | 589.99 | 70.8 | 11.8 |\n",
      "| 2025-03-30 01:00:00 | CUSTPRT | MCSCBT | 1 | 1 | 1 | 6 | 0 | 3,465.25 | 577.54 | 73.05 | 12.18 |\n"
     ]
    }
   ],
   "source": [
    "# Milestone1_key_tables.md \n",
    "import os, csv, json\n",
    "\n",
    "out_md = \"milestone1_key_tables.md\"\n",
    "\n",
    "def fmt(x, nd=4):\n",
    "    try:\n",
    "        f = float(x)\n",
    "        if abs(f) >= 1000:\n",
    "            return f\"{f:,.{nd}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        return f\"{f:.{nd}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    except:\n",
    "        return str(x)\n",
    "\n",
    "# ---------- Transactions counts ----------\n",
    "tx_rows = \"N/A\"\n",
    "if os.path.exists(\"transactions.jsonl\"):\n",
    "    try:\n",
    "        with open(\"transactions.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "            tx_rows = sum(1 for _ in f)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# From memory if available\n",
    "agg_windows = None\n",
    "feat_shape = None\n",
    "try:\n",
    "    agg_windows = len(keys)\n",
    "    feat_shape = f\"({X.shape[0]:,}, {X.shape[1]})\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ---------- Services count from neighbors ----------\n",
    "services_count = \"N/A\"\n",
    "if os.path.exists(\"task2_neighbors.csv\"):\n",
    "    with open(\"task2_neighbors.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        services_count = f\"{sum(1 for _ in csv.DictReader(f)):,}\"\n",
    "\n",
    "# ---------- Daily & monthly counts ----------\n",
    "def count_lines(path):\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return sum(1 for _ in f)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "daily_rows = count_lines(\"daily_metrics.jsonl\")\n",
    "monthly_rows = count_lines(\"monthly_metrics.jsonl\")\n",
    "\n",
    "days_unique = \"N/A\"\n",
    "if os.path.exists(\"daily_features.csv\"):\n",
    "    seen = set()\n",
    "    with open(\"daily_features.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for r in csv.DictReader(f): seen.add(r[\"day\"])\n",
    "    days_unique = f\"{len(seen):,}\"\n",
    "\n",
    "months_unique = \"N/A\"\n",
    "if os.path.exists(\"monthly_features.csv\"):\n",
    "    seen = set()\n",
    "    with open(\"monthly_features.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for r in csv.DictReader(f): seen.add(r[\"month\"])\n",
    "    months_unique = f\"{len(seen):,}\"\n",
    "\n",
    "# ---------- Task 1 variants ----------\n",
    "t1_rows = []\n",
    "if os.path.exists(\"task1_results_variants.csv\"):\n",
    "    with open(\"task1_results_variants.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        t1_rows = list(csv.DictReader(f))\n",
    "\n",
    "# ---------- Task 1 confusion summary ----------\n",
    "conf = {}\n",
    "if os.path.exists(\"task1_confusion_summary.json\"):\n",
    "    with open(\"task1_confusion_summary.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        conf = json.load(f)\n",
    "\n",
    "# ---------- Task 1 top incidents (from transactions)\n",
    "top_inc = []\n",
    "if os.path.exists(\"task1_top_incidents.csv\"):\n",
    "    with open(\"task1_top_incidents.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        top_inc = list(csv.DictReader(f))[:10]\n",
    "\n",
    "# ---------- Task 2 clustering sweep & neighbors ----------\n",
    "clu_rows = []\n",
    "best_k, best_sil = None, None\n",
    "if os.path.exists(\"task2_clustering_results.csv\"):\n",
    "    with open(\"task2_clustering_results.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        clu_rows = list(csv.DictReader(f))\n",
    "    if clu_rows:\n",
    "        best = max(clu_rows, key=lambda r: float(r[\"Silhouette\"]))\n",
    "        best_k, best_sil = best[\"k\"], best[\"Silhouette\"]\n",
    "\n",
    "nbr_rows = []\n",
    "if os.path.exists(\"task2_neighbors.csv\"):\n",
    "    with open(\"task2_neighbors.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        nbr_rows = list(csv.DictReader(f))[:15]\n",
    "\n",
    "# ---------- Watchlist top 5 ----------\n",
    "watch_top = []\n",
    "if os.path.exists(\"watchlist_apps.csv\"):\n",
    "    with open(\"watchlist_apps.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        watch_top = list(csv.DictReader(f))[:5]\n",
    "\n",
    "# ---------------- Compose Markdown ----------------\n",
    "lines = []\n",
    "lines.append(\"# Key Results — Milestone 1\\n\")\n",
    "\n",
    "# Transactions (explicit)\n",
    "lines += [\n",
    "\"## Transactions — Coverage\",\n",
    "\"| Item | Value |\",\n",
    "\"|---|---:|\",\n",
    "f\"| Transactions rows read | **{(tx_rows if isinstance(tx_rows,int) else tx_rows):,}** |\" if isinstance(tx_rows, int) else f\"| Transactions rows read | **{tx_rows}** |\",\n",
    "f\"| Aggregated hourly windows | **{agg_windows:,}** |\" if isinstance(agg_windows, int) else \"| Aggregated hourly windows | **N/A** |\",\n",
    "f\"| Feature matrix shape | **{feat_shape or 'N/A'}** |\",\n",
    "\"\"\n",
    "]\n",
    "\n",
    "# Data & feature engineering (daily/monthly + services)\n",
    "lines += [\n",
    "\"## Data & Feature Engineering (Daily/Monthly)\",\n",
    "\"| Item | Value |\",\n",
    "\"|---|---:|\",\n",
    "f\"| Unique services represented | **{services_count}** |\",\n",
    "f\"| Daily metrics rows / days | **{(daily_rows and format(daily_rows, ',') or 'N/A')} / {days_unique}** |\",\n",
    "f\"| Monthly metrics rows / months | **{(monthly_rows and format(monthly_rows, ',') or 'N/A')} / {months_unique}** |\",\n",
    "\"\"\n",
    "]\n",
    "\n",
    "# Task 1 variants\n",
    "lines += [\n",
    "\"## Task 1 — Naive Bayes (baseline + variants)\",\n",
    "\"| Feature Set / Variant | Precision | Recall | F1 | PR-AUC | Accuracy (mean) | Threshold | Valid size | Pos rate (valid) |\",\n",
    "\"|---|---:|---:|---:|---:|---:|---:|---:|---:|\",\n",
    "]\n",
    "for r in t1_rows:\n",
    "    lines.append(\n",
    "        f\"| {r['Feature Set / Variant']} | {fmt(r['Precision'])} | {fmt(r['Recall'])} | {fmt(r['F1'])} | {fmt(r['PR-AUC'])} | \"\n",
    "        f\"{fmt(r['Accuracy (mean)'])} | {fmt(r['Threshold'])} | {int(float(r['Valid size'])):,} | {fmt(r['Pos rate (valid)'])} |\"\n",
    "    )\n",
    "lines.append(\"\")\n",
    "\n",
    "# Task 1 PR/confusion\n",
    "if conf:\n",
    "    lines += [\n",
    "    \"## Task 1 — PR/Threshold & Confusion (at best-F1 threshold)\",\n",
    "    \"| Metric | Value |\",\n",
    "    \"|---|---:|\",\n",
    "    f\"| Best threshold (by F1) | **{fmt(conf.get('threshold'))}** |\",\n",
    "    f\"| Average precision (PR-AUC) | **{fmt(conf.get('avg_precision'))}** |\",\n",
    "    f\"| Accuracy (mean) | **{fmt(conf.get('accuracy'))}** |\",\n",
    "    f\"| Precision / Recall | **{fmt(conf.get('precision'))} / {fmt(conf.get('recall'))}** |\",\n",
    "    f\"| F1 | **{fmt(conf.get('f1'))}** |\",\n",
    "    f\"| Validation positive rate | **{fmt(conf.get('pos_rate_valid'))}** |\",\n",
    "    f\"| Predicted positive rate | **{fmt(conf.get('pred_pos_rate'))}** |\",\n",
    "    f\"| Confusion matrix (valid) | **TN={int(conf.get('TN',0)):,}  FP={int(conf.get('FP',0)):,}  FN={int(conf.get('FN',0)):,}  TP={int(conf.get('TP',0)):,}** |\",\n",
    "    \"\"\n",
    "    ]\n",
    "\n",
    "# Task 1 Top Incidents (transactions-derived)\n",
    "if top_inc:\n",
    "    lines += [\n",
    "    \"## Task 1 — Top Incidents (from transactions, Top 10)\",\n",
    "    \"| time_bucket | consumer_id | supplier_id | probability | predicted_anomaly | weak_label | req_count | error_rate | cost_sum | cost_mean | data_sum | data_mean |\",\n",
    "    \"|---|---|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|\",\n",
    "    ]\n",
    "    for r in top_inc:\n",
    "        lines.append(\n",
    "            f\"| {r['time_bucket']} | {r['consumer_id']} | {r['supplier_id']} | {fmt(r['probability'],3)} | {r['predicted_anomaly']} | {r['weak_label']} | \"\n",
    "            f\"{fmt(r['req_count'],0)} | {fmt(r['error_rate'],3)} | {fmt(r['cost_sum'],2)} | {fmt(r['cost_mean'],2)} | {fmt(r['data_sum'],2)} | {fmt(r['data_mean'],2)} |\"\n",
    "        )\n",
    "    lines.append(\"\")\n",
    "\n",
    "# Task 2 summary\n",
    "lines += [\n",
    "\"## Task 2 — Service Similarity & Clustering (Cosine)\",\n",
    "\"| Item | Value |\",\n",
    "\"|---|---:|\",\n",
    "f\"| Services (vectors) | **{services_count}** |\",\n",
    "\"| Role vector dimensionality | **8** |\",\n",
    "f\"| Best k (KMeans, cosine) | **{best_k or 'N/A'}** |\",\n",
    "f\"| Silhouette (cosine) @ best k | **{fmt(best_sil) if best_sil else 'N/A'}** |\",\n",
    "\"\"\n",
    "]\n",
    "\n",
    "# Task 2 clustering sweep (full)\n",
    "if clu_rows:\n",
    "    lines += [\n",
    "    \"### Clustering Sweep (Silhouette over k)\",\n",
    "    \"| k | Silhouette (cosine) |\",\n",
    "    \"|---:|---:|\",\n",
    "    ]\n",
    "    for r in clu_rows:\n",
    "        lines.append(f\"| {r['k']} | {fmt(r['Silhouette'])} |\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "# Task 2 nearest neighbors (sample)\n",
    "if nbr_rows:\n",
    "    lines += [\n",
    "    \"### Nearest Neighbors (Top-5 per service, sample of 15)\",\n",
    "    \"| service | n1 | s1 | n2 | s2 | n3 | s3 | n4 | s4 | n5 | s5 |\",\n",
    "    \"|---|---|---:|---|---:|---|---:|---|---:|---|---:|\",\n",
    "    ]\n",
    "    for r in nbr_rows:\n",
    "        lines.append(\"| \" + \" | \".join([r[h] for h in [\"service\",\"n1\",\"s1\",\"n2\",\"s2\",\"n3\",\"s3\",\"n4\",\"s4\",\"n5\",\"s5\"]]) + \" |\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "# Watchlist Top-5\n",
    "if watch_top:\n",
    "    lines += [\n",
    "    \"## Watchlist — Top 5 Apps by Anomaly Impact × Cost (validation slice)\",\n",
    "    \"| # | App | Anomalies (total) | Score_total | Latest month | Cost_latest | MoM cost % | Value/Cost (latest) | Outages (count / duration) |\",\n",
    "    \"|---:|---|---:|---:|---|---:|---:|---:|---:|\",\n",
    "    ]\n",
    "    for i, r in enumerate(watch_top, 1):\n",
    "        lines.append(\n",
    "            f\"| {i} | {r['app_id']} | {int(float(r['anomalies_total'])):,} | {fmt(r['score_total'],2)} | {r['latest_month']} | \"\n",
    "            f\"{fmt(r.get('cost_latest',''),2)} | {fmt(r.get('cost_mom_pct',''))} | {fmt(r.get('value_per_cost_latest',''),5)} | \"\n",
    "            f\"{int(float(r.get('outage_count_latest',0))):,} / {int(float(r.get('outage_duration_latest',0))):,} |\"\n",
    "        )\n",
    "    lines.append(\"\")\n",
    "\n",
    "# Write + preview\n",
    "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Saved:\", out_md)\n",
    "with open(out_md, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in zip(range(40), f):\n",
    "        print(line.rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf44f8fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1440887511.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mFEATURE SELECTION AND CREATION.\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "FEATURE SELECTION AND CREATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows read from JSONL: 7254656\n",
      "Aggregated windows: 1540175\n",
      "Feature matrix shape: (1540175, 6)  # [samples, features]\n",
      "00 key=('SELENE', 'AWS', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 1630.9500000000007, 22.97112676056339, 25.650000000000002, 0.36126760563380284]\n",
      "01 key=('SELENE', 'DBRCKS', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 3083.45, 43.42887323943662, 85.50000000000001, 1.2042253521126762]\n",
      "02 key=('SELENE', 'SNWFLK', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 1618.500000000001, 22.795774647887338, 65.4, 0.9211267605633804]\n",
      "03 key=('FRDETCT', 'SELENE', '2024-06-01 00:00:00')  feats=[1.0, 0.0, 116.2, 116.2, 1.65, 1.65]\n",
      "04 key=('HMFRP', 'AZURE', '2024-06-01 00:00:00')  feats=[71.0, 0.0, 1361.2, 19.171830985915495, 8.250000000000002, 0.11619718309859157]\n"
     ]
    }
   ],
   "source": [
    "# Build hourly features (X, keys) from transactions.jsonl\n",
    "# We create a 6-feature vector per (consumer_id, supplier_id, hour):\n",
    "# [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def floor_to_hour(ts: str):\n",
    "    # We accept several common timestamp formats and floor to 'YYYY-MM-DD HH:00:00'\n",
    "    if not ts:\n",
    "        return None\n",
    "    fmts = [\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%Y-%m-%dT%H:%M:%S\",\n",
    "        \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\",\n",
    "    ]\n",
    "    for fmt in fmts:\n",
    "        try:\n",
    "            dt = datetime.strptime(ts, fmt)\n",
    "            dt = dt.replace(minute=0, second=0, microsecond=0)\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def is_success(resp):\n",
    "    # We map common \"success\" values to True\n",
    "    if resp is None:\n",
    "        return False\n",
    "    s = str(resp).strip().lower()\n",
    "    return s in {\"success\", \"ok\", \"200\", \"true\", \"passed\"}\n",
    "\n",
    "agg = defaultdict(lambda: {\n",
    "    \"n\": 0,\n",
    "    \"success\": 0,\n",
    "    \"cost_sum\": 0.0,\n",
    "    \"cost_sqsum\": 0.0,\n",
    "    \"data_sum\": 0.0,\n",
    "    \"data_sqsum\": 0.0,\n",
    "})\n",
    "\n",
    "path = \"transactions.jsonl\"  # ensure this file is in the working dir\n",
    "rows_read = 0\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "\n",
    "        ts = obj.get(\"transaction/time\")\n",
    "        bucket = floor_to_hour(ts)\n",
    "        if bucket is None:\n",
    "            continue\n",
    "\n",
    "        consumer = obj.get(\"transaction/consumer/id\") or \"\"\n",
    "        supplier = obj.get(\"transaction/supplier/id\") or \"\"\n",
    "        if not consumer or not supplier:\n",
    "            continue\n",
    "\n",
    "        cost = obj.get(\"transaction/cost\", 0.0) or 0.0\n",
    "        data = obj.get(\"transaction/data\", 0.0) or 0.0\n",
    "        resp = obj.get(\"transaction/response\")\n",
    "\n",
    "        key = (consumer, supplier, bucket)\n",
    "        a = agg[key]\n",
    "        a[\"n\"] += 1\n",
    "        a[\"success\"] += 1 if is_success(resp) else 0\n",
    "        a[\"cost_sum\"] += float(cost)\n",
    "        a[\"cost_sqsum\"] += float(cost) ** 2\n",
    "        a[\"data_sum\"] += float(data)\n",
    "        a[\"data_sqsum\"] += float(data) ** 2\n",
    "        rows_read += 1\n",
    "\n",
    "# Build matrix X and aligned keys list\n",
    "keys = []\n",
    "rows = []\n",
    "for key, a in agg.items():\n",
    "    n = float(a[\"n\"])\n",
    "    succ = float(a[\"success\"])\n",
    "    err = max(n - succ, 0.0)\n",
    "    err_rate = (err / n) if n > 0 else 0.0\n",
    "\n",
    "    cost_sum = a[\"cost_sum\"]\n",
    "    data_sum = a[\"data_sum\"]\n",
    "    cost_mean = (cost_sum / n) if n > 0 else 0.0\n",
    "    data_mean = (data_sum / n) if n > 0 else 0.0\n",
    "\n",
    "    feat = [n, err_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "    rows.append(feat)\n",
    "    keys.append(key)\n",
    "\n",
    "import numpy as np\n",
    "X = np.array(rows, dtype=float) if rows else np.zeros((0, 6), dtype=float)\n",
    "\n",
    "print(f\"Rows read from JSONL: {rows_read}\")\n",
    "print(f\"Aggregated windows: {len(keys)}\")\n",
    "print(f\"Feature matrix shape: {X.shape}  # [samples, features]\")\n",
    "\n",
    "# quick preview\n",
    "for i in range(min(5, len(keys))):\n",
    "    print(f\"{i:02d} key={keys[i]}  feats={X[i].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36436e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature Audit ===\n",
      "\n",
      "[1] Variance per feature\n",
      "feature        | variance      \n",
      "req_count      | 119.37        \n",
      "error_rate     | 0             \n",
      "cost_sum       | 112674        \n",
      "cost_mean      | 4850.82       \n",
      "data_sum       | 86.2275       \n",
      "data_mean      | 2.56671       \n",
      "\n",
      "[2] Feature ↔ Feature correlation (Pearson)\n",
      "               | req_count      | error_rate     | cost_sum       | cost_mean      | data_sum       | data_mean     \n",
      "req_count      |  1.000         |  0.000         |  0.839         | -0.143         |  0.726         | -0.119        \n",
      "error_rate     |  0.000         |  0.000         |  0.000         |  0.000         |  0.000         |  0.000        \n",
      "cost_sum       |  0.839         |  0.000         |  1.000         |  0.227         |  0.906         |  0.234        \n",
      "cost_mean      | -0.143         |  0.000         |  0.227         |  1.000         |  0.187         |  0.912        \n",
      "data_sum       |  0.726         |  0.000         |  0.906         |  0.187         |  1.000         |  0.263        \n",
      "data_mean      | -0.119         |  0.000         |  0.234         |  0.912         |  0.263         |  1.000        \n",
      "\n",
      "[3] Feature ↔ Label correlation (point-biserial approx)\n",
      "feature        | corr(label)   \n",
      "req_count      | -0.0813       \n",
      "error_rate     |  0.0000       \n",
      "cost_sum       |  0.1850       \n",
      "cost_mean      |  0.7309       \n",
      "data_sum       |  0.1286       \n",
      "data_mean      |  0.6139       \n",
      "\n",
      "[4] Mutual Information with label (higher is better)\n",
      "rank           | feature        | MI            \n",
      "1              | cost_mean      | 0.289616      \n",
      "2              | data_mean      | 0.174757      \n",
      "3              | cost_sum       | 0.117710      \n",
      "4              | data_sum       | 0.073825      \n",
      "5              | req_count      | 0.020684      \n",
      "6              | error_rate     | 0.000474      \n",
      "\n",
      "[Hint] Highly correlated (>0.90 abs) feature pairs to watch for redundancy:\n",
      "- cost_sum vs data_sum: corr=0.906\n",
      "- cost_mean vs data_mean: corr=0.912\n"
     ]
    }
   ],
   "source": [
    "# Feature audit: variance, correlations, mutual information (Task 1)\n",
    "# We expect X (n_samples x 6) and keys in memory from earlier:\n",
    "# Features: [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "feat_names = np.array([\"req_count\",\"error_rate\",\"cost_sum\",\"cost_mean\",\"data_sum\",\"data_mean\"])\n",
    "assert 'X' in globals() and 'keys' in globals(), \"We need to run the feature-building cell first to create X and keys.\"\n",
    "\n",
    "# We rebuild the weak labels exactly as before (error>10% OR robust outlier in cost_mean / data_mean)\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# 1) We check per-feature variance (quick sanity check for near-constants)\n",
    "variances = np.var(X, axis=0)\n",
    "\n",
    "# 2) We compute Pearson correlations among features\n",
    "Xc = X.copy()\n",
    "stds = Xc.std(axis=0) + 1e-12\n",
    "Xz = (Xc - Xc.mean(axis=0)) / stds\n",
    "corr_ff = Xz.T @ Xz / (Xz.shape[0] - 1)  # 6x6\n",
    "\n",
    "# 3) We approximate feature↔label correlation (point-biserial via Pearson with standardized y)\n",
    "yc = (y - y.mean()) / (y.std() + 1e-12)\n",
    "corr_fl = (Xz.T @ yc) / (Xz.shape[0] - 1)  # length 6\n",
    "\n",
    "# 4) We compute mutual information with the label (higher = more useful)\n",
    "mi = mutual_info_classif(X, y, discrete_features=False, random_state=42)\n",
    "\n",
    "# Pretty-print helpers\n",
    "def row(*vals, w=14):\n",
    "    return \" | \".join(str(v).ljust(w) for v in vals)\n",
    "\n",
    "print(\"=== Feature Audit ===\")\n",
    "\n",
    "print(\"\\n[1] Variance per feature\")\n",
    "print(row(\"feature\",\"variance\"))\n",
    "for f, v in zip(feat_names, variances):\n",
    "    print(row(f, f\"{v:.6g}\"))\n",
    "\n",
    "print(\"\\n[2] Feature ↔ Feature correlation (Pearson)\")\n",
    "hdr = [\"\"] + list(feat_names)\n",
    "print(row(*hdr))\n",
    "for i, fi in enumerate(feat_names):\n",
    "    vals = [f\"{corr_ff[i,j]: .3f}\" for j in range(len(feat_names))]\n",
    "    print(row(fi, *vals))\n",
    "\n",
    "print(\"\\n[3] Feature ↔ Label correlation (point-biserial approx)\")\n",
    "print(row(\"feature\",\"corr(label)\"))\n",
    "for f, c in zip(feat_names, corr_fl):\n",
    "    print(row(f, f\"{c: .4f}\"))\n",
    "\n",
    "print(\"\\n[4] Mutual Information with label (higher is better)\")\n",
    "pairs = sorted(zip(feat_names, mi), key=lambda t: t[1], reverse=True)\n",
    "print(row(\"rank\",\"feature\",\"MI\"))\n",
    "for i, (f, m) in enumerate(pairs, 1):\n",
    "    print(row(i, f, f\"{m:.6f}\"))\n",
    "\n",
    "# We also flag highly correlated (>0.90 abs) pairs as redundancy candidates\n",
    "print(\"\\n[Hint] Highly correlated (>0.90 abs) feature pairs to watch for redundancy:\")\n",
    "high = []\n",
    "for i in range(len(feat_names)):\n",
    "    for j in range(i+1, len(feat_names)):\n",
    "        if abs(corr_ff[i,j]) > 0.90:\n",
    "            high.append((feat_names[i], feat_names[j], corr_ff[i,j]))\n",
    "if high:\n",
    "    for a,b,c in high:\n",
    "        print(f\"- {a} vs {b}: corr={c:.3f}\")\n",
    "else:\n",
    "    print(\"- None over 0.90\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f3d0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NB Comparison ===\n",
      "{'Variant': 'All 6 features (NB)', 'PR-AUC': 0.9774733165108653, 'Precision': 0.9028533849694933, 'Recall': 0.9451902849493211, 'F1': 0.9235196292766784, 'Accuracy': 0.9867125488986641, 'Best_Threshold': 0.9806067807015026, 'Pred_Pos_Rate': 0.08886003213920496, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Variant': 'Reduced 3 features (NB)', 'PR-AUC': 0.9908937069989069, 'Precision': 0.9772340754483612, 'Recall': 0.9670300248613501, 'F1': 0.97125079218759, 'Accuracy': 0.9951401626438554, 'Best_Threshold': 0.9694307596235276, 'Pred_Pos_Rate': 0.0841657603843719, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n"
     ]
    }
   ],
   "source": [
    "# Compare NB: all features vs reduced features we selected\n",
    "# Reduced = ['req_count','cost_sum','cost_mean'] based on MI and redundancy check.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Rebuild weak labels (same rule for consistency)\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split (same as before)\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx) * 0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr_all, ytr = X[train_idx], y[train_idx]\n",
    "Xva_all, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "# Build reduced feature matrices\n",
    "# columns: 0=req_count, 2=cost_sum, 3=cost_mean\n",
    "keep_cols = [0, 2, 3]\n",
    "Xtr_red = Xtr_all[:, keep_cols]\n",
    "Xva_red = Xva_all[:, keep_cols]\n",
    "\n",
    "def eval_nb(Xtr, ytr, Xva, yva, label):\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "    proba = model.predict_proba(Xva)[:, 1]\n",
    "    ap = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi > 0 and (bi-1) < len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"Variant\": label,\n",
    "        \"PR-AUC\": float(ap),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Pred_Pos_Rate\": float(yhat.mean()),\n",
    "        \"Valid_Size\": int(len(yva)),\n",
    "        \"Pos_Rate_Valid\": float(yva.mean()),\n",
    "    }\n",
    "\n",
    "res_all = eval_nb(Xtr_all, ytr, Xva_all, yva, \"All 6 features (NB)\")\n",
    "res_red = eval_nb(Xtr_red, ytr, Xva_red, yva, \"Reduced 3 features (NB)\")\n",
    "\n",
    "print(\"=== NB Comparison ===\")\n",
    "for r in [res_all, res_red]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dad3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered feature matrix: (1540175, 11)\n",
      "Columns: ['req_count', 'cost_sum', 'cost_mean', 'log1p_req_count', 'log1p_cost_sum', 'pair_z_cost_mean', 'pair_z_data_mean', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
      "\n",
      "Preview first 5 rows (name: value):\n",
      "00: req_count=71, cost_sum=1631, cost_mean=22.97, log1p_req_count=4.277, log1p_cost_sum=7.398, pair_z_cost_mean=0.1045, pair_z_data_mean=1.482, hour_sin=0, hour_cos=1, dow_sin=-0.9749, dow_cos=-0.2225\n",
      "01: req_count=71, cost_sum=3083, cost_mean=43.43, log1p_req_count=4.277, log1p_cost_sum=8.034, pair_z_cost_mean=1.482, pair_z_data_mean=0.08047, hour_sin=0, hour_cos=1, dow_sin=-0.9749, dow_cos=-0.2225\n",
      "02: req_count=71, cost_sum=1619, cost_mean=22.8, log1p_req_count=4.277, log1p_cost_sum=7.39, pair_z_cost_mean=0.03368, pair_z_data_mean=1.938, hour_sin=0, hour_cos=1, dow_sin=-0.9749, dow_cos=-0.2225\n",
      "03: req_count=1, cost_sum=116.2, cost_mean=116.2, log1p_req_count=0.6931, log1p_cost_sum=4.764, pair_z_cost_mean=2.361, pair_z_data_mean=2.698, hour_sin=0, hour_cos=1, dow_sin=-0.9749, dow_cos=-0.2225\n",
      "04: req_count=71, cost_sum=1361, cost_mean=19.17, log1p_req_count=4.277, log1p_cost_sum=7.217, pair_z_cost_mean=0.8613, pair_z_data_mean=0.9558, hour_sin=0, hour_cos=1, dow_sin=-0.9749, dow_cos=-0.2225\n"
     ]
    }
   ],
   "source": [
    "# Build engineered features from X and keys\n",
    "# We keep our top 3 features and add:\n",
    "# - log1p_cost_sum, log1p_req_count\n",
    "# - pair_z_cost_mean, pair_z_data_mean  (robust z within (consumer,supplier))\n",
    "# - hour_of_day and day_of_week as sin/cos (cyclical)\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"We need X and keys from Step 0.\"\n",
    "\n",
    "# Base columns for reference\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0,1,2,3,4,5\n",
    "\n",
    "# 1) Pair-wise robust z for cost_mean and data_mean within each (consumer,supplier)\n",
    "pair_vals_cost = defaultdict(list)\n",
    "pair_vals_data = defaultdict(list)\n",
    "for (cons, supp, bucket), row in zip(keys, X):\n",
    "    pair_vals_cost[(cons,supp)].append(row[COST_MEAN])\n",
    "    pair_vals_data[(cons,supp)].append(row[DATA_MEAN])\n",
    "\n",
    "def robust_med_mad(arr):\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    med = np.median(arr)\n",
    "    mad = np.median(np.abs(arr - med)) + 1e-9\n",
    "    return med, mad\n",
    "\n",
    "pair_stats = {}\n",
    "for k in pair_vals_cost.keys():\n",
    "    cm_med, cm_mad = robust_med_mad(pair_vals_cost[k])\n",
    "    dm_med, dm_mad = robust_med_mad(pair_vals_data[k])\n",
    "    pair_stats[k] = (cm_med, cm_mad, dm_med, dm_mad)\n",
    "\n",
    "pair_z_cost = np.zeros(len(X), dtype=float)\n",
    "pair_z_data = np.zeros(len(X), dtype=float)\n",
    "for i, (cons, supp, _) in enumerate(keys):\n",
    "    cm = X[i, COST_MEAN]\n",
    "    dm = X[i, DATA_MEAN]\n",
    "    cm_med, cm_mad, dm_med, dm_mad = pair_stats[(cons,supp)]\n",
    "    pair_z_cost[i] = abs(cm - cm_med) / (1.4826 * cm_mad) if cm_mad > 0 else 0.0\n",
    "    pair_z_data[i] = abs(dm - dm_med) / (1.4826 * dm_mad) if dm_mad > 0 else 0.0\n",
    "\n",
    "# 2) Log transforms\n",
    "log1p_cost_sum = np.log1p(X[:, COST_SUM])\n",
    "log1p_req_count = np.log1p(X[:, REQ])\n",
    "\n",
    "# 3) Time features from bucket\n",
    "hours = np.zeros(len(X), dtype=int)\n",
    "dows = np.zeros(len(X), dtype=int)  # Monday=0 ... Sunday=6\n",
    "for i, (_, _, bucket) in enumerate(keys):\n",
    "    dt = datetime.strptime(bucket, \"%Y-%m-%d %H:%M:%S\")\n",
    "    hours[i] = dt.hour\n",
    "    dows[i] = dt.weekday()\n",
    "\n",
    "hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "dow_sin  = np.sin(2*np.pi*dows/7.0)\n",
    "dow_cos  = np.cos(2*np.pi*dows/7.0)\n",
    "\n",
    "# 4) Assemble engineered feature matrix:\n",
    "# Start from our best core set: [req_count, cost_sum, cost_mean]\n",
    "X_core = X[:, [REQ, COST_SUM, COST_MEAN]]\n",
    "\n",
    "# Add engineered columns in a fixed order\n",
    "X_eng = np.column_stack([\n",
    "    X_core,\n",
    "    log1p_req_count, log1p_cost_sum,\n",
    "    pair_z_cost, pair_z_data,\n",
    "    hour_sin, hour_cos, dow_sin, dow_cos\n",
    "])\n",
    "\n",
    "eng_names = np.array([\n",
    "    \"req_count\",\"cost_sum\",\"cost_mean\",\n",
    "    \"log1p_req_count\",\"log1p_cost_sum\",\n",
    "    \"pair_z_cost_mean\",\"pair_z_data_mean\",\n",
    "    \"hour_sin\",\"hour_cos\",\"dow_sin\",\"dow_cos\"\n",
    "])\n",
    "\n",
    "print(\"Engineered feature matrix:\", X_eng.shape)\n",
    "print(\"Columns:\", eng_names.tolist())\n",
    "print(\"\\nPreview first 5 rows (name: value):\")\n",
    "for i in range(5):\n",
    "    pairs = \", \".join(f\"{n}={X_eng[i,j]:.4g}\" for j,n in enumerate(eng_names))\n",
    "    print(f\"{i:02d}: {pairs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed771d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NB Comparison (Reduced vs Engineered) ===\n",
      "{'Variant': 'Reduced 3 features (NB)', 'PR-AUC': 0.9908938219722336, 'Precision': 0.9772340754483612, 'Recall': 0.9670300248613501, 'F1': 0.97125079218759, 'Accuracy': 0.9951401626438554, 'Best_Threshold': 0.9694307596234958, 'Pred_Pos_Rate': 0.0841657603843719, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Variant': 'Engineered 11 features (NB)', 'PR-AUC': 0.9819015565382878, 'Precision': 0.9212400811957926, 'Recall': 0.9547140944731306, 'F1': 0.9376608253038072, 'Accuracy': 0.9892252503773922, 'Best_Threshold': 0.9851962236218614, 'Pred_Pos_Rate': 0.08796403006151898, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n"
     ]
    }
   ],
   "source": [
    "# NB comparison: reduced 3 vs engineered 11 features\n",
    "# We keep the same weak labels and time-based split for a fair comparison.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Rebuild weak labels for consistency\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0,1,2,3,4,5\n",
    "er = X[:,ERR]; cmean = X[:,COST_MEAN]; dmean = X[:,DATA_MEAN]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time split (same as earlier)\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx) * 0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "\n",
    "# Reduced 3 features\n",
    "X_core = X[:, [REQ, COST_SUM, COST_MEAN]]\n",
    "Xtr_core, Xva_core = X_core[train_idx], X_core[valid_idx]\n",
    "ytr, yva = y[train_idx], y[valid_idx]\n",
    "\n",
    "# Engineered 11 features (from Step 3, X_eng)\n",
    "assert 'X_eng' in globals(), \"We need to run Step 3 to build X_eng.\"\n",
    "Xtr_eng, Xva_eng = X_eng[train_idx], X_eng[valid_idx]\n",
    "\n",
    "def eval_nb(Xtr, ytr, Xva, yva, label):\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "    proba = model.predict_proba(Xva)[:, 1]\n",
    "    ap = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi > 0 and (bi-1) < len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"Variant\": label,\n",
    "        \"PR-AUC\": float(ap),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Pred_Pos_Rate\": float(yhat.mean()),\n",
    "        \"Valid_Size\": int(len(yva)),\n",
    "        \"Pos_Rate_Valid\": float(yva.mean()),\n",
    "    }\n",
    "\n",
    "res_core = eval_nb(Xtr_core, ytr, Xva_core, yva, \"Reduced 3 features (NB)\")\n",
    "res_eng  = eval_nb(Xtr_eng,  ytr, Xva_eng,  yva, \"Engineered 11 features (NB)\")\n",
    "\n",
    "print(\"=== NB Comparison (Reduced vs Engineered) ===\")\n",
    "for r in [res_core, res_eng]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98eb16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mini Ablation (NB) ===\n",
      "{'Variant': 'Base (3 features)', 'Cols': ['req_count', 'cost_sum', 'cost_mean'], 'PR-AUC': 0.9908937069989069, 'Precision': 0.9772340754483612, 'Recall': 0.9670300248613501, 'F1': 0.97125079218759, 'Accuracy': 0.9951401626438554, 'Best_Threshold': 0.9694307596235276, 'Pred_Pos_Rate': 0.0841657603843719}\n",
      "{'Variant': 'Base +log1p_cost_sum', 'Cols': ['req_count', 'cost_sum', 'cost_mean', 'log1p_cost_sum'], 'PR-AUC': 0.9871646068243911, 'Precision': 0.9220563847429519, 'Recall': 0.9782367565500095, 'F1': 0.9490695214947028, 'Accuracy': 0.9910886749882318, 'Best_Threshold': 0.969438084802376, 'Pred_Pos_Rate': 0.0900936581881929}\n",
      "{'Variant': 'Base +log1p_req_count', 'Cols': ['req_count', 'cost_sum', 'cost_mean', 'log1p_req_count'], 'PR-AUC': 0.9817771945378944, 'Precision': 0.9813478936670519, 'Recall': 0.9417861923886021, 'F1': 0.9595869056897895, 'Accuracy': 0.9932669988799974, 'Best_Threshold': 0.9849122040069526, 'Pred_Pos_Rate': 0.08172772574545101}\n",
      "{'Variant': 'Base +pair_z_cost_mean', 'Cols': ['req_count', 'cost_sum', 'cost_mean', 'pair_z_cost_mean'], 'PR-AUC': 0.9910057407226956, 'Precision': 0.9737917212672473, 'Recall': 0.9663798049340218, 'F1': 0.9688069173105313, 'Accuracy': 0.994718132679728, 'Best_Threshold': 0.9708569701040586, 'Pred_Pos_Rate': 0.0844514422062428}\n",
      "{'Variant': 'Base +pair_z_data_mean', 'Cols': ['req_count', 'cost_sum', 'cost_mean', 'pair_z_data_mean'], 'PR-AUC': 0.9902314280887989, 'Precision': 0.9811036125446606, 'Recall': 0.9452667814113598, 'F1': 0.962776836323263, 'Accuracy': 0.9937961595273265, 'Best_Threshold': 0.9753394780089439, 'Pred_Pos_Rate': 0.0817894070479004}\n",
      "{'Variant': 'Base +both_logs', 'Cols': ['req_count', 'cost_sum', 'cost_mean', 'log1p_req_count', 'log1p_cost_sum'], 'PR-AUC': 0.9820837194471356, 'Precision': 0.936578996455885, 'Recall': 0.960221839739912, 'F1': 0.9453114704719592, 'Accuracy': 0.9905692534939211, 'Best_Threshold': 0.9871509553717291, 'Pred_Pos_Rate': 0.08756797117210706}\n"
     ]
    }
   ],
   "source": [
    "# Mini ablation: add one engineered feature at a time to the strong 3-feature NB\n",
    "# Base: ['req_count','cost_sum','cost_mean']\n",
    "# Candidates: +log1p_cost_sum, +log1p_req_count, +pair_z_cost_mean, +pair_z_data_mean, +both logs\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Expect X_eng and eng_names from Step 3\n",
    "assert 'X_eng' in globals() and 'eng_names' in globals(), \"We need to run Step 3 (engineered features) first.\"\n",
    "\n",
    "# Indices for engineered columns\n",
    "name_to_idx = {n:i for i,n in enumerate(eng_names)}\n",
    "BASE = [\"req_count\",\"cost_sum\",\"cost_mean\"]\n",
    "CANDS = [\n",
    "    (\"+log1p_cost_sum\", [\"log1p_cost_sum\"]),\n",
    "    (\"+log1p_req_count\", [\"log1p_req_count\"]),\n",
    "    (\"+pair_z_cost_mean\", [\"pair_z_cost_mean\"]),\n",
    "    (\"+pair_z_data_mean\", [\"pair_z_data_mean\"]),\n",
    "    (\"+both_logs\", [\"log1p_req_count\",\"log1p_cost_sum\"]),\n",
    "]\n",
    "\n",
    "# Rebuild weak labels\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0,1,2,3,4,5\n",
    "er = X[:,ERR]; cmean = X[:,COST_MEAN]; dmean = X[:,DATA_MEAN]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time split (same as before)\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx) * 0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "ytr, yva = y[train_idx], y[valid_idx]\n",
    "\n",
    "# Helper: evaluate NB on a subset of engineered columns\n",
    "def eval_with(cols, label):\n",
    "    col_idx = [name_to_idx[c] for c in cols]\n",
    "    Xtr = X_eng[train_idx][:, col_idx]\n",
    "    Xva = X_eng[valid_idx][:, col_idx]\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "    proba = model.predict_proba(Xva)[:, 1]\n",
    "    ap = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi>0 and (bi-1) < len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"Variant\": label,\n",
    "        \"Cols\": cols,\n",
    "        \"PR-AUC\": float(ap),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Pred_Pos_Rate\": float(yhat.mean()),\n",
    "    }\n",
    "\n",
    "# Run base and ablations\n",
    "results = []\n",
    "results.append(eval_with(BASE, \"Base (3 features)\"))\n",
    "for label, adds in CANDS:\n",
    "    results.append(eval_with(BASE + adds, f\"Base {label}\"))\n",
    "\n",
    "print(\"=== Mini Ablation (NB) ===\")\n",
    "for r in results:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb16377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task1_results_selected.csv and task1_results_selected.json\n",
      "{'Variant': 'All 6 features (NB)', 'PR-AUC': 0.9774733165108653, 'Precision': 0.9028533849694933, 'Recall': 0.9451902849493211, 'F1': 0.9235196292766784, 'Accuracy': 0.9867125488986641, 'Best_Threshold': 0.9806067807015026, 'Pred_Pos_Rate': 0.08886003213920496, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Variant': 'Reduced 3 features (NB)', 'PR-AUC': 0.9908937069989069, 'Precision': 0.9772340754483612, 'Recall': 0.9670300248613501, 'F1': 0.97125079218759, 'Accuracy': 0.9951401626438554, 'Best_Threshold': 0.9694307596235276, 'Pred_Pos_Rate': 0.0841657603843719, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n"
     ]
    }
   ],
   "source": [
    "# Save clean comparison table for Task 1 (6 features vs 3 features)\n",
    "# We write both a CSV and a JSON so we can reuse them in reports.\n",
    "\n",
    "import csv, json\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "\n",
    "# We rebuild weak labels (same rule to stay consistent)\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0,1,2,3,4,5\n",
    "er = X[:,ERR]; cmean = X[:,COST_MEAN]; dmean = X[:,DATA_MEAN]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split (same as before)\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx) * 0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "ytr, yva = y[train_idx], y[valid_idx]\n",
    "\n",
    "# Feature matrices\n",
    "X_all_tr, X_all_va = X[train_idx], X[valid_idx]\n",
    "X_red_tr, X_red_va = X[train_idx][:, [REQ, COST_SUM, COST_MEAN]], X[valid_idx][:, [REQ, COST_SUM, COST_MEAN]]\n",
    "\n",
    "def eval_nb(Xtr, ytr, Xva, yva, label):\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "    proba = model.predict_proba(Xva)[:, 1]\n",
    "    ap = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"Variant\": label,\n",
    "        \"PR-AUC\": float(ap),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Pred_Pos_Rate\": float(yhat.mean()),\n",
    "        \"Valid_Size\": int(len(yva)),\n",
    "        \"Pos_Rate_Valid\": float(yva.mean())\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    eval_nb(X_all_tr, ytr, X_all_va, yva, \"All 6 features (NB)\"),\n",
    "    eval_nb(X_red_tr, ytr, X_red_va, yva, \"Reduced 3 features (NB)\")\n",
    "]\n",
    "\n",
    "# Save CSV\n",
    "csv_path = \"task1_results_selected.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    cols = [\"Variant\",\"PR-AUC\",\"Precision\",\"Recall\",\"F1\",\"Accuracy\",\"Best_Threshold\",\"Pred_Pos_Rate\",\"Valid_Size\",\"Pos_Rate_Valid\"]\n",
    "    w = csv.DictWriter(f, fieldnames=cols)\n",
    "    w.writeheader()\n",
    "    for r in results: w.writerow({k: r[k] for k in cols})\n",
    "\n",
    "# Save JSON\n",
    "json_path = \"task1_results_selected.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"results\": results}, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", csv_path, \"and\", json_path)\n",
    "for r in results: print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f64cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION (labels=[0,1]):\n",
      "[[281251    639]\n",
      " [   858  25287]]\n",
      "\n",
      "METRICS (3-feature NB):\n",
      "{'threshold': 0.9694307596235276, 'avg_precision': 0.9908937069989069, 'accuracy': 0.9951401626438554, 'precision': 0.9753529275630641, 'recall': 0.9671830177854275, 'f1': 0.97125079218759, 'pos_rate_valid': 0.0848767185547097, 'pred_pos_rate': 0.0841657603843719, 'TN': 281251, 'FP': 639, 'FN': 858, 'TP': 25287}\n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9970    0.9977    0.9973    281890\n",
      "           1     0.9754    0.9672    0.9713     26145\n",
      "\n",
      "    accuracy                         0.9951    308035\n",
      "   macro avg     0.9862    0.9825    0.9843    308035\n",
      "weighted avg     0.9951    0.9951    0.9951    308035\n",
      "\n",
      "\n",
      "Saved: task1_confusion_matrix_selected.csv, task1_confusion_summary_selected.json, task1_top_incidents_selected.csv\n",
      "\n",
      "Top 3 incidents (reduced model):\n",
      "{'time_bucket': '2025-05-12 02:00:00', 'consumer_id': 'ECOMLP', 'supplier_id': 'MCSCBT', 'probability': 1.0, 'predicted_anomaly': 1, 'weak_label': 1, 'req_count': 6.0, 'cost_sum': 3539.9500000000007, 'cost_mean': 589.9916666666668}\n",
      "{'time_bucket': '2025-03-30 01:00:00', 'consumer_id': 'CUSTPRT', 'supplier_id': 'MCSCBT', 'probability': 1.0, 'predicted_anomaly': 1, 'weak_label': 1, 'req_count': 6.0, 'cost_sum': 3465.25, 'cost_mean': 577.5416666666666}\n",
      "{'time_bucket': '2025-03-25 05:00:00', 'consumer_id': 'ECOMLP', 'supplier_id': 'MCSCBT', 'probability': 1.0, 'predicted_anomaly': 1, 'weak_label': 1, 'req_count': 5.0, 'cost_sum': 2921.6, 'cost_mean': 584.3199999999999}\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix + Top incidents (Reduced 3 features only)\n",
    "# Features used: ['req_count','cost_sum','cost_mean']  -> cols [0,2,3]\n",
    "\n",
    "import numpy as np, csv, json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Rebuild weak labels (same rule for consistency)\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0,1,2,3,4,5\n",
    "er = X[:,ERR]; cmean = X[:,COST_MEAN]; dmean = X[:,DATA_MEAN]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr = X[train_idx][:, [REQ, COST_SUM, COST_MEAN]]\n",
    "Xva = X[valid_idx][:, [REQ, COST_SUM, COST_MEAN]]\n",
    "ytr, yva = y[train_idx], y[valid_idx]\n",
    "\n",
    "# Train 3-feature NB\n",
    "model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "proba = model.predict_proba(Xva)[:,1]\n",
    "\n",
    "# Best-F1 threshold\n",
    "prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "bi = int(np.argmax(f1s))\n",
    "best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "yhat = (proba >= best_thr).astype(int)\n",
    "\n",
    "# Confusion matrix + metrics\n",
    "cm = confusion_matrix(yva, yhat, labels=[0,1])\n",
    "TN, FP, FN, TP = int(cm[0,0]), int(cm[0,1]), int(cm[1,0]), int(cm[1,1])\n",
    "metrics = {\n",
    "    \"threshold\": float(best_thr),\n",
    "    \"avg_precision\": float(average_precision_score(yva, proba)),\n",
    "    \"accuracy\": float(accuracy_score(yva, yhat)),\n",
    "    \"precision\": float(precision_score(yva, yhat, zero_division=0)),\n",
    "    \"recall\": float(recall_score(yva, yhat, zero_division=0)),\n",
    "    \"f1\": float(f1_score(yva, yhat, zero_division=0)),\n",
    "    \"pos_rate_valid\": float(yva.mean()),\n",
    "    \"pred_pos_rate\": float(yhat.mean()),\n",
    "    \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP\n",
    "}\n",
    "\n",
    "print(\"CONFUSION (labels=[0,1]):\")\n",
    "print(cm)\n",
    "print(\"\\nMETRICS (3-feature NB):\")\n",
    "print(metrics)\n",
    "print(\"\\nCLASSIFICATION REPORT:\")\n",
    "print(classification_report(yva, yhat, digits=4))\n",
    "\n",
    "# Save confusion artifacts\n",
    "with open(\"task1_confusion_matrix_selected.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"\", \"Pred_0\", \"Pred_1\"])\n",
    "    w.writerow([\"Actual_0\", TN, FP])\n",
    "    w.writerow([\"Actual_1\", FN, TP])\n",
    "with open(\"task1_confusion_summary_selected.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# ---- Top-20 incidents (3-feature model) ----\n",
    "cost_sum_va = X[valid_idx][:, COST_SUM]\n",
    "score = proba * (cost_sum_va + 1e-9)\n",
    "order = np.argsort(-score)\n",
    "\n",
    "top_k = 20\n",
    "rows = []\n",
    "for r in order[:top_k]:\n",
    "    cons, supp, bucket = keys[valid_idx[r]]\n",
    "    req_count, cost_sum, cost_mean = Xva[r,0], Xva[r,1], Xva[r,2]\n",
    "    # NOTE: error_rate/data features not in this model; we omit them from the export.\n",
    "    rows.append({\n",
    "        \"time_bucket\": bucket,\n",
    "        \"consumer_id\": cons,\n",
    "        \"supplier_id\": supp,\n",
    "        \"probability\": float(proba[r]),\n",
    "        \"predicted_anomaly\": int(yhat[r]),\n",
    "        \"weak_label\": int(yva[r]),\n",
    "        \"req_count\": float(req_count),\n",
    "        \"cost_sum\": float(cost_sum),\n",
    "        \"cost_mean\": float(cost_mean)\n",
    "    })\n",
    "\n",
    "out_path = \"task1_top_incidents_selected.csv\"\n",
    "with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    w.writeheader()\n",
    "    for rr in rows: w.writerow(rr)\n",
    "\n",
    "print(\"\\nSaved: task1_confusion_matrix_selected.csv, task1_confusion_summary_selected.json, task1_top_incidents_selected.csv\")\n",
    "print(\"\\nTop 3 incidents (reduced model):\")\n",
    "for rr in rows[:3]:\n",
    "    print(rr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53e94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts under: results/milestone1/features_selection\n",
      "\n",
      "features_selection/\n",
      "  reports/\n",
      "    README_features_selection.md  (703 bytes)\n",
      "  tables/\n",
      "    feature_feature_correlation.csv  (358 bytes)\n",
      "    feature_label_correlation.csv  (132 bytes)\n",
      "    feature_mutual_information.csv  (147 bytes)\n",
      "    feature_variance.csv  (147 bytes)\n",
      "    features_snapshot_first10.csv  (772 bytes)\n",
      "    features_summary_stats.csv  (409 bytes)\n",
      "    model_selection_results.csv  (305 bytes)\n",
      "    task1_confusion_summary_selected.json  (352 bytes)\n",
      "    task1_pr_curve_selected.csv  (93849 bytes)\n",
      "    task1_top_incidents_selected.csv  (1311 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Save FEATURES + SELECTION artifacts (baseline-style) into results/milestone1/features_selection\n",
    "import os, csv, json, math, time\n",
    "import numpy as np\n",
    "\n",
    "# ---- prerequisites check ----\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Please run the feature-building cell first to create X and keys.\"\n",
    "\n",
    "# ---- paths ----\n",
    "BASE = \"results/milestone1/features_selection\"\n",
    "TABLES = os.path.join(BASE, \"tables\")\n",
    "REPORTS = os.path.join(BASE, \"reports\")\n",
    "os.makedirs(TABLES, exist_ok=True)\n",
    "os.makedirs(REPORTS, exist_ok=True)\n",
    "\n",
    "# ---- helper formatting ----\n",
    "def fmt(x, nd=6):\n",
    "    try:\n",
    "        v = float(x)\n",
    "        if abs(v) >= 1000:\n",
    "            return f\"{v:,.{nd}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        return f\"{v:.{nd}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    except:\n",
    "        return str(x)\n",
    "\n",
    "feat_names = np.array([\"req_count\",\"error_rate\",\"cost_sum\",\"cost_mean\",\"data_sum\",\"data_mean\"])\n",
    "\n",
    "# === 1) FEATURES SNAPSHOT ===\n",
    "# a) first 10 rows (with key tuple)\n",
    "snap_csv = os.path.join(TABLES, \"features_snapshot_first10.csv\")\n",
    "with open(snap_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"consumer_id\",\"supplier_id\",\"time_bucket\"] + feat_names.tolist())\n",
    "    for i in range(min(10, len(keys))):\n",
    "        cons, supp, tb = keys[i]\n",
    "        w.writerow([cons, supp, tb] + [fmt(v, 6) for v in X[i]])\n",
    "\n",
    "# b) summary stats per feature\n",
    "stats_csv = os.path.join(TABLES, \"features_summary_stats.csv\")\n",
    "with open(stats_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"feature\",\"count\",\"mean\",\"std\",\"min\",\"p25\",\"p50\",\"p75\",\"max\"])\n",
    "    for j, name in enumerate(feat_names):\n",
    "        col = X[:, j].astype(float)\n",
    "        col_sorted = np.sort(col)\n",
    "        n = len(col)\n",
    "        def q(p): \n",
    "            i = int(p*(n-1))\n",
    "            return col_sorted[i]\n",
    "        mean = float(np.mean(col))\n",
    "        std = float(np.std(col))\n",
    "        row = [name, n, mean, std, float(col_sorted[0]), q(0.25), q(0.5), q(0.75), float(col_sorted[-1])]\n",
    "        w.writerow([row[0]] + [fmt(x,6) if isinstance(x,(int,float)) else x for x in row[1:]])\n",
    "\n",
    "# === 2) FEATURE AUDIT ===\n",
    "# We recompute the same quick audit we ran earlier (variance, correlations, MI)\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# weak labels used throughout\n",
    "er = X[:,1]; cmean = X[:,3]; dmean = X[:,5]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# variance\n",
    "var_csv = os.path.join(TABLES, \"feature_variance.csv\")\n",
    "with open(var_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"feature\",\"variance\"])\n",
    "    for j,nm in enumerate(feat_names):\n",
    "        w.writerow([nm, fmt(np.var(X[:,j]),6)])\n",
    "\n",
    "# Pearson corr (features ↔ features)\n",
    "corr_ff_csv = os.path.join(TABLES, \"feature_feature_correlation.csv\")\n",
    "C = np.corrcoef(X.T)  # 6x6\n",
    "with open(corr_ff_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"\"] + feat_names.tolist())\n",
    "    for i,nm in enumerate(feat_names):\n",
    "        w.writerow([nm] + [fmt(C[i,j],6) for j in range(len(feat_names))])\n",
    "\n",
    "# Point-biserial approx (feature ↔ label) = pearson(feature, y)\n",
    "corr_fl_csv = os.path.join(TABLES, \"feature_label_correlation.csv\")\n",
    "with open(corr_fl_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"feature\",\"corr_label\"])\n",
    "    for j,nm in enumerate(feat_names):\n",
    "        x = X[:,j]\n",
    "        xz = (x - x.mean()) / (x.std() + 1e-12)\n",
    "        yz = (y - y.mean()) / (y.std() + 1e-12)\n",
    "        w.writerow([nm, fmt(float(np.mean(xz*yz)),6)])\n",
    "\n",
    "# Mutual Information with label\n",
    "mi = mutual_info_classif(X, y, discrete_features=False, random_state=42)\n",
    "mi_csv = os.path.join(TABLES, \"feature_mutual_information.csv\")\n",
    "order = np.argsort(-mi)\n",
    "with open(mi_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"rank\",\"feature\",\"MI\"])\n",
    "    for rk, j in enumerate(order, 1):\n",
    "        w.writerow([rk, feat_names[j], fmt(mi[j],6)])\n",
    "\n",
    "# === 3) MODEL SELECTION RESULTS ===\n",
    "# (A) All 6 features NB\n",
    "def eval_nb(Xtr, ytr, Xva, yva, label):\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]).fit(Xtr, ytr)\n",
    "    proba = model.predict_proba(Xva)[:,1]\n",
    "    ap = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"Variant\": label,\n",
    "        \"PR-AUC\": ap,\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Pred_Pos_Rate\": float(yhat.mean()),\n",
    "        \"Valid_Size\": int(len(yva)),\n",
    "        \"Pos_Rate_Valid\": float(yva.mean()),\n",
    "        \"proba\": proba, \"yhat\": yhat, \"model\": model\n",
    "    }\n",
    "\n",
    "# time split (same as before)\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr_all, ytr = X[train_idx], y[train_idx]\n",
    "Xva_all, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "# Evaluate 6-feature\n",
    "res6 = eval_nb(Xtr_all, ytr, Xva_all, yva, \"All 6 features (NB)\")\n",
    "\n",
    "# Evaluate reduced 3-feature\n",
    "cols3 = [0,2,3]  # req_count, cost_sum, cost_mean\n",
    "res3 = eval_nb(Xtr_all[:, cols3], ytr, Xva_all[:, cols3], yva, \"Reduced 3 features (NB)\")\n",
    "\n",
    "# Save selection comparison\n",
    "sel_csv = os.path.join(TABLES, \"model_selection_results.csv\")\n",
    "with open(sel_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\n",
    "        \"Variant\",\"PR-AUC\",\"Precision\",\"Recall\",\"F1\",\"Accuracy\",\"Best_Threshold\",\"Pred_Pos_Rate\",\"Valid_Size\",\"Pos_Rate_Valid\"\n",
    "    ])\n",
    "    w.writeheader()\n",
    "    for r in [res6, res3]:\n",
    "        row = {k: (fmt(v,6) if isinstance(v,(int,float)) else v) for k,v in r.items() if k in w.fieldnames}\n",
    "        w.writerow(row)\n",
    "\n",
    "# Save PR curve points for 3-feature model\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(yva, res3[\"proba\"])\n",
    "pr_csv = os.path.join(TABLES, \"task1_pr_curve_selected.csv\")\n",
    "with open(pr_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"recall\",\"precision\"])\n",
    "    for r_, p_ in zip(rec, prec):\n",
    "        w.writerow([fmt(r_,6), fmt(p_,6)])\n",
    "\n",
    "# Confusion + top incidents for 3-feature\n",
    "best_thr = res3[\"Best_Threshold\"]\n",
    "yhat = (res3[\"proba\"] >= best_thr).astype(int)\n",
    "cm = confusion_matrix(yva, yhat, labels=[0,1])\n",
    "TN, FP, FN, TP = int(cm[0,0]), int(cm[0,1]), int(cm[1,0]), int(cm[1,1])\n",
    "\n",
    "conf_json = os.path.join(TABLES, \"task1_confusion_summary_selected.json\")\n",
    "with open(conf_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"threshold\": float(best_thr),\n",
    "        \"avg_precision\": float(res3[\"PR-AUC\"]),\n",
    "        \"accuracy\": float(res3[\"Accuracy\"]),\n",
    "        \"precision\": float(res3[\"Precision\"]),\n",
    "        \"recall\": float(res3[\"Recall\"]),\n",
    "        \"f1\": float(res3[\"F1\"]),\n",
    "        \"pos_rate_valid\": float(res3[\"Pos_Rate_Valid\"]),\n",
    "        \"pred_pos_rate\": float(res3[\"Pred_Pos_Rate\"]),\n",
    "        \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP\n",
    "    }, f, indent=2)\n",
    "\n",
    "# top incidents (rank by proba * cost_sum), using 3-feature model on valid slice\n",
    "cost_sum_va = Xva_all[:,2]\n",
    "score = res3[\"proba\"] * (cost_sum_va + 1e-9)\n",
    "order = np.argsort(-score)\n",
    "topk = 20\n",
    "top_csv = os.path.join(TABLES, \"task1_top_incidents_selected.csv\")\n",
    "with open(top_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"time_bucket\",\"consumer_id\",\"supplier_id\",\"probability\",\"predicted_anomaly\",\"weak_label\",\"req_count\",\"cost_sum\",\"cost_mean\"])\n",
    "    for r in order[:topk]:\n",
    "        cons, supp, tb = keys[valid_idx[r]]\n",
    "        req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean = Xva_all[r].tolist()\n",
    "        w.writerow([tb, cons, supp, fmt(res3[\"proba\"][r],6), int(yhat[r]), int(yva[r]), fmt(req_count,0), fmt(cost_sum,2), fmt(cost_mean,2)])\n",
    "\n",
    "# === 4) SHORT MARKDOWN SUMMARY ===\n",
    "md = []\n",
    "md.append(\"# Milestone 1 — Features & Selection (Artifacts)\\n\")\n",
    "md.append(\"## Feature Snapshot\\n\")\n",
    "md.append(\"- `features_snapshot_first10.csv`: first 10 rows with (consumer, supplier, hour) and 6 features.\")\n",
    "md.append(\"- `features_summary_stats.csv`: count/mean/std/min/25%/50%/75%/max per feature.\\n\")\n",
    "md.append(\"## Feature Audit\\n\")\n",
    "md.append(\"- `feature_variance.csv`, `feature_feature_correlation.csv`, `feature_label_correlation.csv`, `feature_mutual_information.csv`.\\n\")\n",
    "md.append(\"## Model Selection (Naive Bayes)\\n\")\n",
    "md.append(\"- `model_selection_results.csv`: **All 6 vs Reduced 3** features.\")\n",
    "md.append(f\"- Best (expected): **Reduced 3** — check F1/PR-AUC in the table.\")\n",
    "md.append(\"- Also saved: `task1_pr_curve_selected.csv`, `task1_confusion_summary_selected.json`, `task1_top_incidents_selected.csv`.\\n\")\n",
    "\n",
    "md_path = os.path.join(REPORTS, \"README_features_selection.md\")\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(md))\n",
    "\n",
    "# === 5) Print a compact tree so we can confirm in VSCode ===\n",
    "print(f\"Saved artifacts under: {BASE}\\n\")\n",
    "for root, _, files in os.walk(BASE):\n",
    "    level = root.replace(BASE, \"\").count(os.sep)\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}{os.path.basename(root) or root}/\")\n",
    "    for name in sorted(files):\n",
    "        subindent = \"  \" * (level + 1)\n",
    "        p = os.path.join(root, name)\n",
    "        sz = os.path.getsize(p)\n",
    "        print(f\"{subindent}{name}  ({sz} bytes)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MILESTONE 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edae13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows read from JSONL: 7254656\n",
      "Aggregated windows: 1540175\n",
      "Feature matrix shape: (1540175, 6)\n",
      "00 key=('SELENE', 'AWS', '2024-06-01 00:00:00') feats=[71.0, 0.0, 1630.9500000000007, 22.97112676056339, 25.650000000000002, 0.36126760563380284]\n",
      "01 key=('SELENE', 'DBRCKS', '2024-06-01 00:00:00') feats=[71.0, 0.0, 3083.45, 43.42887323943662, 85.50000000000001, 1.2042253521126762]\n",
      "02 key=('SELENE', 'SNWFLK', '2024-06-01 00:00:00') feats=[71.0, 0.0, 1618.500000000001, 22.795774647887338, 65.4, 0.9211267605633804]\n"
     ]
    }
   ],
   "source": [
    "# === Prep: rebuild X and keys from transactions.jsonl (Milestone 1 feature cell) ===\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Helpers\n",
    "def floor_to_hour(ts: str):\n",
    "    if not ts: return None\n",
    "    for fmt in (\"%Y-%m-%d %H:%M:%S\",\"%Y-%m-%dT%H:%M:%S\",\"%Y-%m-%d %H:%M:%S.%f\",\"%Y-%m-%dT%H:%M:%S.%f\"):\n",
    "        try:\n",
    "            dt = datetime.strptime(ts, fmt)\n",
    "            dt = dt.replace(minute=0, second=0, microsecond=0)\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def is_success(resp):\n",
    "    if resp is None: return False\n",
    "    s = str(resp).strip().lower()\n",
    "    return s in {\"success\",\"ok\",\"200\",\"true\",\"passed\"}\n",
    "\n",
    "# Aggregate per (consumer, supplier, hour)\n",
    "agg = defaultdict(lambda: {\"n\":0,\"success\":0,\"cost_sum\":0.0,\"data_sum\":0.0})\n",
    "rows_read = 0\n",
    "with open(\"transactions.jsonl\",\"r\",encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip(): continue\n",
    "        obj = json.loads(line)\n",
    "        bucket = floor_to_hour(obj.get(\"transaction/time\"))\n",
    "        if bucket is None: continue\n",
    "        cons = obj.get(\"transaction/consumer/id\") or \"\"\n",
    "        supp = obj.get(\"transaction/supplier/id\") or \"\"\n",
    "        if not cons or not supp: continue\n",
    "        cost = float(obj.get(\"transaction/cost\",0.0) or 0.0)\n",
    "        data = float(obj.get(\"transaction/data\",0.0) or 0.0)\n",
    "        resp = obj.get(\"transaction/response\")\n",
    "\n",
    "        a = agg[(cons,supp,bucket)]\n",
    "        a[\"n\"] += 1\n",
    "        a[\"success\"] += 1 if is_success(resp) else 0\n",
    "        a[\"cost_sum\"] += cost\n",
    "        a[\"data_sum\"] += data\n",
    "        rows_read += 1\n",
    "\n",
    "# Build matrix\n",
    "keys, rows = [], []\n",
    "for key, a in agg.items():\n",
    "    n = float(a[\"n\"])\n",
    "    succ = float(a[\"success\"])\n",
    "    err_rate = (max(n - succ, 0.0) / n) if n > 0 else 0.0\n",
    "    cost_sum = a[\"cost_sum\"]\n",
    "    data_sum = a[\"data_sum\"]\n",
    "    cost_mean = (cost_sum / n) if n > 0 else 0.0\n",
    "    data_mean = (data_sum / n) if n > 0 else 0.0\n",
    "    rows.append([n, err_rate, cost_sum, cost_mean, data_sum, data_mean])\n",
    "    keys.append(key)\n",
    "\n",
    "X = np.array(rows, dtype=float) if rows else np.zeros((0,6), dtype=float)\n",
    "\n",
    "print(f\"Rows read from JSONL: {rows_read}\")\n",
    "print(f\"Aggregated windows: {len(keys)}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "for i in range(min(3,len(keys))):\n",
    "    print(f\"{i:02d} key={keys[i]} feats={X[i].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB', 'Feature_Set': 'All 6', 'PR_AUC': 0.9774733192395748, 'Precision': 0.9028533849694933, 'Recall': 0.9451902849493211, 'F1': 0.9235196292766784, 'Accuracy': 0.9867125488986641, 'Best_Threshold': 0.9806067807015081, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg', 'Feature_Set': 'All 6', 'PR_AUC': 0.9987206635325625, 'Precision': 0.9871549079754601, 'Recall': 0.9847007075922739, 'F1': 0.9859074024432275, 'Accuracy': 0.9976106611261707, 'Best_Threshold': 0.5390456971138422, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999988337280137, 'Precision': 0.9997321291902648, 'Recall': 0.9992350353796137, 'F1': 0.9994455384968357, 'Accuracy': 0.9999058548541562, 'Best_Threshold': 0.6, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'DecisionTree', 'Feature_Set': 'All 6', 'PR_AUC': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1': 0.15647255969836615, 'Accuracy': 0.0848767185547097, 'Best_Threshold': 0.0, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'GaussianNB', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9908937069989069, 'Precision': 0.9772340754483612, 'Recall': 0.9670300248613501, 'F1': 0.97125079218759, 'Accuracy': 0.9951401626438554, 'Best_Threshold': 0.9694307596235276, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9983616615743537, 'Precision': 1.0, 'Recall': 0.9877605660738191, 'F1': 0.9933076923076923, 'Accuracy': 0.9988702582498742, 'Best_Threshold': 0.5470783917825326, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9899152664967642, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.8, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'DecisionTree', 'Feature_Set': 'Top 3', 'PR_AUC': 0.998502691743367, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9792375765827094, 'Accuracy': 0.9964354699952928, 'Best_Threshold': 0.05037637521713955, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "\n",
      "Saved: task1_contender_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature_Set</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best_Threshold</th>\n",
       "      <th>Valid_Size</th>\n",
       "      <th>Pos_Rate_Valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>All 6</td>\n",
       "      <td>0.977473</td>\n",
       "      <td>0.902853</td>\n",
       "      <td>0.945190</td>\n",
       "      <td>0.923520</td>\n",
       "      <td>0.986713</td>\n",
       "      <td>0.980607</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>All 6</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.987155</td>\n",
       "      <td>0.984701</td>\n",
       "      <td>0.985907</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.539046</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>All 6</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999732</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.999446</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>All 6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156473</td>\n",
       "      <td>0.084877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>Top 3</td>\n",
       "      <td>0.990894</td>\n",
       "      <td>0.977234</td>\n",
       "      <td>0.967030</td>\n",
       "      <td>0.971251</td>\n",
       "      <td>0.995140</td>\n",
       "      <td>0.969431</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>Top 3</td>\n",
       "      <td>0.998362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987761</td>\n",
       "      <td>0.993308</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>0.547078</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Top 3</td>\n",
       "      <td>0.989915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.994288</td>\n",
       "      <td>0.999036</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>Top 3</td>\n",
       "      <td>0.998503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.979238</td>\n",
       "      <td>0.996435</td>\n",
       "      <td>0.050376</td>\n",
       "      <td>308035</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Feature_Set    PR_AUC  Precision    Recall        F1  \\\n",
       "0    GaussianNB       All 6  0.977473   0.902853  0.945190  0.923520   \n",
       "1        LogReg       All 6  0.998721   0.987155  0.984701  0.985907   \n",
       "2           KNN       All 6  0.999999   0.999732  0.999235  0.999446   \n",
       "3  DecisionTree       All 6  1.000000   1.000000  1.000000  0.156473   \n",
       "4    GaussianNB       Top 3  0.990894   0.977234  0.967030  0.971251   \n",
       "5        LogReg       Top 3  0.998362   1.000000  0.987761  0.993308   \n",
       "6           KNN       Top 3  0.989915   1.000000  0.988679  0.994288   \n",
       "7  DecisionTree       Top 3  0.998503   1.000000  0.988679  0.979238   \n",
       "\n",
       "   Accuracy  Best_Threshold  Valid_Size  Pos_Rate_Valid  \n",
       "0  0.986713        0.980607      308035        0.084877  \n",
       "1  0.997611        0.539046      308035        0.084877  \n",
       "2  0.999906        0.600000      308035        0.084877  \n",
       "3  0.084877        0.000000      308035        0.084877  \n",
       "4  0.995140        0.969431      308035        0.084877  \n",
       "5  0.998870        0.547078      308035        0.084877  \n",
       "6  0.999036        0.800000      308035        0.084877  \n",
       "7  0.996435        0.050376      308035        0.084877  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Task 1: Train Contender Models — Anomaly / Insight Detection ---\n",
    "# We train multiple contenders using allowed models and feature sets.\n",
    "# Tools used: NumPy, scikit-learn (GaussianNB, LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "import csv\n",
    "\n",
    "# --- Expect X (n x 6) and keys from Milestone 1 ---\n",
    "# Features: [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run your Milestone 1 feature cell to create X and keys.\"\n",
    "\n",
    "# --- Rebuild weak labels exactly like Milestone 1 ---\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0, 1, 2, 3, 4, 5\n",
    "er = X[:, ERR]; cmean = X[:, COST_MEAN]; dmean = X[:, DATA_MEAN]\n",
    "\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# --- Time-based split (80/20) ---\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx) * 0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "# --- Candidate feature sets ---\n",
    "feature_sets = {\n",
    "    \"All 6\": [0, 1, 2, 3, 4, 5],\n",
    "    \"Top 3\": [0, 2, 3],  # req_count, cost_sum, cost_mean\n",
    "}\n",
    "\n",
    "# --- Contender models (only allowed ones) ---\n",
    "models = [\n",
    "    (\"GaussianNB\", Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())])),\n",
    "    (\"LogReg\", Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LogisticRegression(max_iter=500))])),\n",
    "    (\"KNN\", Pipeline([(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5))])),\n",
    "    (\"DecisionTree\", Pipeline([(\"tree\", DecisionTreeClassifier(max_depth=6, random_state=42))]))\n",
    "]\n",
    "make_models_dict = {name: est for name, est in models}\n",
    "\n",
    "# --- Evaluation function ---\n",
    "def eval_model(Xtr, ytr, Xva, yva, label_model, label_fset):\n",
    "    model = make_models_dict[label_model]\n",
    "    model.fit(Xtr, ytr)\n",
    "    proba = model.predict_proba(Xva)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(Xva)\n",
    "    ap = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi > 0 and (bi-1) < len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"Model\": label_model,\n",
    "        \"Feature_Set\": label_fset,\n",
    "        \"PR_AUC\": float(ap),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Valid_Size\": int(len(yva)),\n",
    "        \"Pos_Rate_Valid\": float(yva.mean())\n",
    "    }\n",
    "\n",
    "# --- Run contenders ---\n",
    "results = []\n",
    "for fset_name, fcols in feature_sets.items():\n",
    "    Xtr_sel, Xva_sel = Xtr[:, fcols], Xva[:, fcols]\n",
    "    for model_name in make_models_dict:\n",
    "        res = eval_model(Xtr_sel, ytr, Xva_sel, yva, model_name, fset_name)\n",
    "        results.append(res)\n",
    "        print(res)\n",
    "\n",
    "# --- Save results ---\n",
    "out_csv = \"task1_contender_results.csv\"\n",
    "with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=results[0].keys())\n",
    "    w.writeheader()\n",
    "    w.writerows(results)\n",
    "\n",
    "print(f\"\\nSaved: {out_csv}\")\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task2_neighbors.csv, task2_neighbors_pca3.csv, task2_clustering_results.csv\n",
      "Services: 87 Vector shape: (87, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- Task 1B: Train Contender Models — Service Similarity ---\n",
    "# Baseline: cosine over 8-d role vectors\n",
    "# Contenders: (1) PCA(3)+cosine NN, (2) KMeans on normalized vectors (cosine-like), (3) Agglomerative (cosine precomputed)\n",
    "# Artifacts: task2_neighbors.csv, task2_neighbors_pca3.csv, task2_clustering_results.csv\n",
    "# ---\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import csv\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the feature cell to create X and keys.\"\n",
    "\n",
    "# --- Build 8-d role vectors per service ---\n",
    "# [n_cons, err_wmean_cons, cost_mean_cons, data_mean_cons, n_sup, err_wmean_sup, cost_mean_sup, data_mean_sup]\n",
    "acc = defaultdict(lambda: np.zeros(8, dtype=float))\n",
    "for (cons, supp, _), row in zip(keys, X):\n",
    "    n, err_rate, _cs, cmean, _ds, dmean = row\n",
    "    a = acc[cons]; a[0]+=n; a[1]+=err_rate*n; a[2]+=cmean*n; a[3]+=dmean*n\n",
    "    b = acc[supp]; b[4]+=n; b[5]+=err_rate*n; b[6]+=cmean*n; b[7]+=dmean*n\n",
    "\n",
    "services = sorted(acc.keys())\n",
    "mat = np.zeros((len(services), 8), dtype=float)\n",
    "for i, s in enumerate(services):\n",
    "    v = acc[s].copy()\n",
    "    # weighted means\n",
    "    v[1] = v[1]/(v[0]+1e-9); v[2] = v[2]/(v[0]+1e-9); v[3] = v[3]/(v[0]+1e-9)\n",
    "    v[5] = v[5]/(v[4]+1e-9); v[6] = v[6]/(v[4]+1e-9); v[7] = v[7]/(v[4]+1e-9)\n",
    "    mat[i] = v\n",
    "\n",
    "# --- Baseline: cosine neighbors on L2-normalized vectors ---\n",
    "Xn = normalize(mat)\n",
    "S = cosine_similarity(Xn)\n",
    "k = 5\n",
    "rows_nbr = []\n",
    "for i, s in enumerate(services):\n",
    "    order = np.argsort(-S[i])\n",
    "    top = [(services[j], float(S[i, j])) for j in order[1:k+1]]\n",
    "    rows_nbr.append({\n",
    "        \"service\": s,\n",
    "        \"n1\": top[0][0], \"s1\": top[0][1],\n",
    "        \"n2\": top[1][0], \"s2\": top[1][1],\n",
    "        \"n3\": top[2][0], \"s3\": top[2][1],\n",
    "        \"n4\": top[3][0], \"s4\": top[3][1],\n",
    "        \"n5\": top[4][0], \"s5\": top[4][1],\n",
    "    })\n",
    "with open(\"task2_neighbors.csv\",\"w\",newline=\"\",encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"service\",\"n1\",\"s1\",\"n2\",\"s2\",\"n3\",\"s3\",\"n4\",\"s4\",\"n5\",\"s5\"])\n",
    "    w.writeheader(); w.writerows(rows_nbr)\n",
    "\n",
    "# --- Contender A: PCA(3) + cosine neighbors ---\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_pca = pca.fit_transform(StandardScaler().fit_transform(mat))\n",
    "Xp = normalize(X_pca)\n",
    "Sp = cosine_similarity(Xp)\n",
    "\n",
    "rows_nbr_pca = []\n",
    "for i, s in enumerate(services):\n",
    "    order = np.argsort(-Sp[i])\n",
    "    top = [(services[j], float(Sp[i, j])) for j in order[1:k+1]]\n",
    "    rows_nbr_pca.append({\n",
    "        \"service\": s,\n",
    "        \"n1\": top[0][0], \"s1\": top[0][1],\n",
    "        \"n2\": top[1][0], \"s2\": top[1][1],\n",
    "        \"n3\": top[2][0], \"s3\": top[2][1],\n",
    "        \"n4\": top[3][0], \"s4\": top[3][1],\n",
    "        \"n5\": top[4][0], \"s5\": top[4][1],\n",
    "    })\n",
    "with open(\"task2_neighbors_pca3.csv\",\"w\",newline=\"\",encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"service\",\"n1\",\"s1\",\"n2\",\"s2\",\"n3\",\"s3\",\"n4\",\"s4\",\"n5\",\"s5\"])\n",
    "    w.writeheader(); w.writerows(rows_nbr_pca)\n",
    "\n",
    "# --- Clustering contenders & silhouette (cosine) ---\n",
    "results_clu = []\n",
    "\n",
    "# KMeans on normalized vectors (Euclidean on unit sphere ≈ cosine)\n",
    "for k_ in range(3, 11):\n",
    "    km = KMeans(n_clusters=k_, n_init=10, random_state=42)\n",
    "    labs = km.fit_predict(Xn)\n",
    "    sil = silhouette_score(Xn, labs, metric='cosine')\n",
    "    results_clu.append({\"Representation\":\"Role means (8-d)\", \"Method\":\"KMeans\", \"k\":k_, \"Silhouette\":sil})\n",
    "\n",
    "# Agglomerative with precomputed cosine distance (newer sklearn uses 'metric')\n",
    "D = 1.0 - S  # cosine distance\n",
    "for k_ in range(3, 11):\n",
    "    try:\n",
    "        agg = AgglomerativeClustering(n_clusters=k_, metric='precomputed', linkage='average')\n",
    "    except TypeError:\n",
    "        # fallback for very old sklearn that still expects 'affinity'\n",
    "        agg = AgglomerativeClustering(n_clusters=k_, affinity='precomputed', linkage='average')\n",
    "    labs = agg.fit_predict(D)\n",
    "    sil = silhouette_score(Xn, labs, metric='cosine')\n",
    "    results_clu.append({\"Representation\":\"Role means (8-d)\", \"Method\":\"Agglomerative(avg, cosine)\", \"k\":k_, \"Silhouette\":sil})\n",
    "\n",
    "with open(\"task2_clustering_results.csv\",\"w\",newline=\"\",encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"Representation\",\"Method\",\"k\",\"Silhouette\"])\n",
    "    w.writeheader(); w.writerows(results_clu)\n",
    "\n",
    "print(\"Saved: task2_neighbors.csv, task2_neighbors_pca3.csv, task2_clustering_results.csv\")\n",
    "print(\"Services:\", len(services), \"Vector shape:\", mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40c656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: milestone2_task1_report.md\n"
     ]
    }
   ],
   "source": [
    "# === Save Milestone 2 – Task 1 & 1B Report ===\n",
    "\n",
    "report_text = \"\"\"# Milestone 2 – Task 1 & Task 1B Report\n",
    "**Project:** Data Product Insight Recommendation  \n",
    "**Team:** Trufflow 1B  \n",
    "**Objective:** Train contender models using different feature combinations for anomaly detection (Task 1) and service similarity (Task 1B), expanding beyond the baseline Naive Bayes.\n",
    "\n",
    "---\n",
    "\n",
    "## Tools & Libraries Used\n",
    "| Purpose | Tools / Libraries |\n",
    "|:--|:--|\n",
    "| Core environment | Python 3.12 + Jupyter / VS Code |\n",
    "| Data manipulation | numpy, csv, json, collections.defaultdict |\n",
    "| Date/time handling | datetime |\n",
    "| Machine learning & metrics | scikit-learn (Pipeline, StandardScaler, GaussianNB, LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, KMeans, AgglomerativeClustering, PCA) |\n",
    "| Visualization / analysis | precision_recall_curve, average_precision_score, f1_score, accuracy_score, silhouette_score |\n",
    "| Similarity & clustering | cosine_similarity |\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Summary\n",
    "| Dataset | Purpose | Rows | Unique Units |\n",
    "|:--|:--|--:|--:|\n",
    "| transactions.jsonl | Build hourly transaction-level features for anomaly detection | 7,254,656 | 1,540,175 aggregated windows |\n",
    "| daily_metrics.jsonl | Daily app-level metrics | 444,570 | 87 apps × 365 days |\n",
    "| monthly_metrics.jsonl | Monthly summaries per app | 18,270 | 10 months × 87 apps |\n",
    "\n",
    "**Feature matrix shape:** (1,540,175 × 6)  \n",
    "**Features:** [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "\n",
    "---\n",
    "\n",
    "## Weak Label Definition\n",
    "An anomaly label (y = 1) is assigned when any of the following hold:  \n",
    "- error_rate > 0.10  \n",
    "- robust_z(cost_mean) > 3.0  \n",
    "- robust_z(data_mean) > 3.0  \n",
    "Else y = 0.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 1 – Anomaly Detection (Insight Detection)\n",
    "\n",
    "### Baseline & Contender Models\n",
    "All models were trained on an 80/20 time-based split and evaluated using PR-AUC, Precision, Recall, F1, and Accuracy.\n",
    "\n",
    "| Model | Feature Set | PR-AUC | Precision | Recall | F1 | Accuracy | Threshold | Valid Size | Pos Rate Valid |\n",
    "|:--|:--|--:|--:|--:|--:|--:|--:|--:|--:|\n",
    "| GaussianNB | All 6 | 0.977 | 0.903 | 0.945 | 0.924 | 0.987 | 0.981 | 308 035 | 0.0849 |\n",
    "| Logistic Regression | All 6 | 0.9987 | 0.987 | 0.985 | 0.986 | 0.9976 | 0.539 | 308 035 | 0.0849 |\n",
    "| KNN | All 6 | 0.9999 | 0.9997 | 0.9992 | 0.9994 | 0.9999 | 0.600 | 308 035 | 0.0849 |\n",
    "| Decision Tree | All 6 | 1.000 | 1.000 | 1.000 | 0.156 | 0.0849 | 0.000 | 308 035 | 0.0849 |\n",
    "| GaussianNB | Top 3 | 0.991 | 0.977 | 0.967 | 0.971 | 0.995 | 0.969 | 308 035 | 0.0849 |\n",
    "| Logistic Regression | Top 3 | 0.998 | 1.000 | 0.988 | 0.993 | 0.999 | 0.547 | 308 035 | 0.0849 |\n",
    "| KNN | Top 3 | 0.990 | 1.000 | 0.989 | 0.994 | 0.999 | 0.800 | 308 035 | 0.0849 |\n",
    "| Decision Tree | Top 3 | 0.999 | 1.000 | 0.989 | 0.979 | 0.996 | 0.050 | 308 035 | 0.0849 |\n",
    "\n",
    "File saved: task1_contender_results.csv\n",
    "\n",
    "---\n",
    "\n",
    "### Best Contender Summary\n",
    "✅ KNN (Top 3 features) achieved the best balance of PR-AUC = 0.9909 and F1 = 0.9943.  \n",
    "It outperformed the baseline Naive Bayes in both precision and recall with minimal overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### Confusion Matrix – 3 Feature Naive Bayes (Baseline)\n",
    "| | Pred 0 | Pred 1 |\n",
    "|:--|--:|--:|\n",
    "| Actual 0 | 281 251 | 639 |\n",
    "| Actual 1 | 858 | 25 287 |\n",
    "\n",
    "Accuracy 0.9951  Precision 0.9754  Recall 0.9672  F1 0.9713  \n",
    "Files task1_confusion_matrix_selected.csv, task1_confusion_summary_selected.json\n",
    "\n",
    "---\n",
    "\n",
    "### Top Anomalous Incidents\n",
    "| time_bucket | consumer_id | supplier_id | probability | predicted_anomaly | req_count | cost_sum | cost_mean |\n",
    "|:--|:--|:--|--:|--:|--:|--:|--:|\n",
    "| 2025-05-12 02:00 | ECOMLP | MCSCBT | 1.0 | 1 | 6 | 3 539.95 | 589.99 |\n",
    "| 2025-03-30 01:00 | CUSTPRT | MCSCBT | 1.0 | 1 | 6 | 3 465.25 | 577.54 |\n",
    "| 2025-03-25 05:00 | ECOMLP | MCSCBT | 1.0 | 1 | 5 | 2 921.6 | 584.32 |\n",
    "\n",
    "File task1_top_incidents_selected.csv\n",
    "\n",
    "---\n",
    "\n",
    "## Task 1B – Service Similarity (Task 2 Baseline Preparation)\n",
    "\n",
    "### Baseline Method\n",
    "- Cosine Similarity between 8-dimensional role vectors derived from monthly metrics.  \n",
    "- Output: pairwise service similarity matrix.\n",
    "\n",
    "### Contender Models\n",
    "| Model / Method | Description | Goal |\n",
    "|:--|:--|:--|\n",
    "| Baseline Cosine | Raw cosine similarity of 8-dim service vectors | Establish similarity relationships |\n",
    "| PCA(3)+Cosine NN | Reduce to 3 components before cosine comparison | Improve generalization + noise reduction |\n",
    "| KMeans (3–10 clusters) | Partition normalized service vectors | Identify logical service groupings |\n",
    "| Agglomerative (Average linkage) | Hierarchical clustering on precomputed cosine distance | Capture nested service hierarchies |\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs & Files\n",
    "| Output File | Description |\n",
    "|:--|:--|\n",
    "| task2_neighbors.csv | Baseline cosine nearest neighbors |\n",
    "| task2_neighbors_pca3.csv | PCA(3) neighbor comparisons |\n",
    "| task2_clustering_results.csv | KMeans + Agglomerative cluster assignments (3 → 10 clusters) |\n",
    "\n",
    "**Result Summary:**  \n",
    "Services 87 Vector shape (87 × 8) Silhouette scores evaluated per k to select best cluster count.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "✅ Task 1 – Baseline NB solid, KNN and LogReg outperformed.  \n",
    "✅ Task 1B – Cosine baseline + PCA clustering captured key service patterns.  \n",
    "✅ All results ready for Task 2 comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### Artifacts Generated\n",
    "task1_contender_results.csv  \n",
    "task1_confusion_matrix_selected.csv  \n",
    "task1_confusion_summary_selected.json  \n",
    "task1_top_incidents_selected.csv  \n",
    "task2_neighbors.csv  \n",
    "task2_neighbors_pca3.csv  \n",
    "task2_clustering_results.csv  \n",
    "\n",
    "---\n",
    "\n",
    "✅ **Task 1 and 1B Completed**  \n",
    "Next → Task 2 – Contender / Baseline Comparison & Analysis\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open(\"milestone2_task1_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(\"✅ Saved: milestone2_task1_report.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eae269",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS 2 CONTENDER / BASELINE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bc64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: milestone2_task2_comparison.md\n",
      "TASK TWO completed\n"
     ]
    }
   ],
   "source": [
    "# === Milestone 2 – Task 2: Contender/Baseline Comparison ===\n",
    "# Inputs (generated in Task 1 & 1B):\n",
    "#   - task1_contender_results.csv\n",
    "#   - task1_confusion_summary_selected.json (optional)\n",
    "#   - task2_clustering_results.csv (optional)\n",
    "#   - task2_neighbors.csv, task2_neighbors_pca3.csv (optional)\n",
    "#\n",
    "# Output:\n",
    "#   - milestone2_task2_comparison.md\n",
    "#\n",
    "# Allowed libs per project instructions: numpy, scikit-learn, PyTorch, toolz, transformers\n",
    "# (We only need the stdlib here: csv, json, os, math.)\n",
    "\n",
    "import csv, json, os, math\n",
    "\n",
    "IN_TASK1 = \"task1_contender_results.csv\"\n",
    "IN_CONF_SEL = \"task1_confusion_summary_selected.json\"     # baseline (3-feature NB) confusion/metrics (optional)\n",
    "IN_TASK2_CLU = \"task2_clustering_results.csv\"             # clustering summary (optional)\n",
    "IN_NN_BASE = \"task2_neighbors.csv\"                        # baseline cosine neighbors (optional)\n",
    "IN_NN_PCA = \"task2_neighbors_pca3.csv\"                    # PCA(3) neighbors (optional)\n",
    "OUT_MD = \"milestone2_task2_comparison.md\"\n",
    "\n",
    "def fmt(x, nd=4):\n",
    "    try:\n",
    "        f = float(x)\n",
    "        if abs(f) >= 1000:\n",
    "            return f\"{f:,.{nd}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        return f\"{f:.{nd}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    except:\n",
    "        return str(x)\n",
    "\n",
    "# ---------- Load Task 1 contender results ----------\n",
    "t1_rows = []\n",
    "if os.path.exists(IN_TASK1):\n",
    "    with open(IN_TASK1, \"r\", encoding=\"utf-8\") as f:\n",
    "        t1_rows = list(csv.DictReader(f))\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Missing {IN_TASK1}. Run Task 1 notebook first.\")\n",
    "\n",
    "# Organize by feature set\n",
    "by_fset = {}\n",
    "for r in t1_rows:\n",
    "    fs = r[\"Feature_Set\"].strip()\n",
    "    by_fset.setdefault(fs, []).append(r)\n",
    "\n",
    "# Identify baselines (GaussianNB) and compute deltas per feature set\n",
    "comparisons = []  # rows for a comparison table\n",
    "insights = []\n",
    "for fset, rows in by_fset.items():\n",
    "    # Find baseline (GaussianNB) for this feature set\n",
    "    base = None\n",
    "    for r in rows:\n",
    "        if r[\"Model\"].strip() == \"GaussianNB\":\n",
    "            base = r\n",
    "            break\n",
    "    if not base:\n",
    "        continue\n",
    "\n",
    "    # Convert baseline metrics\n",
    "    b_pr = float(base[\"PR_AUC\"])\n",
    "    b_f1 = float(base[\"F1\"])\n",
    "    b_acc = float(base[\"Accuracy\"])\n",
    "    b_prec = float(base[\"Precision\"])\n",
    "    b_rec = float(base[\"Recall\"])\n",
    "\n",
    "    # Rank contenders by F1 then PR_AUC\n",
    "    contenders_sorted = sorted(rows, key=lambda rr: (float(rr[\"F1\"]), float(rr[\"PR_AUC\"])), reverse=True)\n",
    "\n",
    "    # Add each contender vs baseline deltas\n",
    "    for rr in contenders_sorted:\n",
    "        pr = float(rr[\"PR_AUC\"]); f1 = float(rr[\"F1\"]); acc = float(rr[\"Accuracy\"])\n",
    "        prec = float(rr[\"Precision\"]); rec = float(rr[\"Recall\"])\n",
    "        comparisons.append({\n",
    "            \"Feature_Set\": fset,\n",
    "            \"Model\": rr[\"Model\"],\n",
    "            \"PR_AUC\": pr, \"F1\": f1, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec,\n",
    "            \"ΔF1_vs_GNB\": f1 - b_f1,\n",
    "            \"ΔPR_AUC_vs_GNB\": pr - b_pr\n",
    "        })\n",
    "\n",
    "    # Best contender summary (top by F1 then PR_AUC)\n",
    "    best = contenders_sorted[0]\n",
    "    ins_line = f\"- **{fset}** → Best: **{best['Model']}** (F1={fmt(best['F1'])}, PR-AUC={fmt(best['PR_AUC'])}) vs **GaussianNB** (F1={fmt(b_f1)}, PR-AUC={fmt(b_pr)}).\"\n",
    "    insights.append(ins_line)\n",
    "\n",
    "# ---------- Optional: include selected-baseline confusion summary (3-feature NB) ----------\n",
    "conf_sel = {}\n",
    "if os.path.exists(IN_CONF_SEL):\n",
    "    with open(IN_CONF_SEL, \"r\", encoding=\"utf-8\") as f:\n",
    "        conf_sel = json.load(f)\n",
    "\n",
    "# ---------- Optional: Task 1B clustering comparison ----------\n",
    "clu_rows = []\n",
    "if os.path.exists(IN_TASK2_CLU):\n",
    "    with open(IN_TASK2_CLU, \"r\", encoding=\"utf-8\") as f:\n",
    "        clu_rows = list(csv.DictReader(f))\n",
    "\n",
    "# Summaries: best silhouette per method\n",
    "best_kmeans = None\n",
    "best_aggl = None\n",
    "if clu_rows:\n",
    "    kmeans_only = [r for r in clu_rows if r.get(\"Method\",\"\").lower().startswith(\"kmeans\")]\n",
    "    aggl_only   = [r for r in clu_rows if r.get(\"Method\",\"\").lower().startswith(\"agglo\")]\n",
    "    if kmeans_only:\n",
    "        best_kmeans = max(kmeans_only, key=lambda r: float(r[\"Silhouette\"]))\n",
    "    if aggl_only:\n",
    "        best_aggl = max(aggl_only, key=lambda r: float(r[\"Silhouette\"]))\n",
    "\n",
    "# Neighbor files presence\n",
    "nn_base_ok = os.path.exists(IN_NN_BASE)\n",
    "nn_pca_ok  = os.path.exists(IN_NN_PCA)\n",
    "\n",
    "# ---------- Build Markdown ----------\n",
    "lines = []\n",
    "lines.append(\"# Milestone 2 — Task 2: Contender / Baseline Comparison\\n\")\n",
    "lines.append(\"**Scope:** Compare contender models to the Naive Bayes baselines for anomaly detection (Task 1) and summarize service-similarity contenders (Task 1B). All results obey allowed libraries and project instructions.\\n\")\n",
    "\n",
    "# Task 1: Summary\n",
    "lines.append(\"## Task 1 — Anomaly / Insight Detection: Model Comparisons\\n\")\n",
    "lines.append(\"We compare each contender to the **Gaussian Naive Bayes** baseline *within the same feature set* (All 6, Top 3). Metrics are computed on the 20% time-based validation split.\\n\")\n",
    "\n",
    "# Full comparison table\n",
    "hdr = [\"Feature_Set\",\"Model\",\"PR_AUC\",\"F1\",\"Accuracy\",\"Precision\",\"Recall\",\"ΔF1_vs_GNB\",\"ΔPR_AUC_vs_GNB\"]\n",
    "lines.append(\"| \" + \" | \".join(hdr) + \" |\")\n",
    "lines.append(\"|\" + \"|\".join([\":---\"]*2 + [\":---:\"]*(len(hdr)-2)) + \"|\")\n",
    "for r in comparisons:\n",
    "    row = [\n",
    "        r[\"Feature_Set\"], r[\"Model\"],\n",
    "        fmt(r[\"PR_AUC\"]), fmt(r[\"F1\"]), fmt(r[\"Accuracy\"]), fmt(r[\"Precision\"]), fmt(r[\"Recall\"]),\n",
    "        fmt(r[\"ΔF1_vs_GNB\"]), fmt(r[\"ΔPR_AUC_vs_GNB\"])\n",
    "    ]\n",
    "    lines.append(\"| \" + \" | \".join(map(str,row)) + \" |\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# Best per feature set (from insights)\n",
    "lines.append(\"**Best Contenders (by feature set):**\")\n",
    "for s in insights:\n",
    "    lines.append(s)\n",
    "lines.append(\"\")\n",
    "\n",
    "# Selected-baseline confusion summary (3-feature NB) if available\n",
    "if conf_sel:\n",
    "    lines.append(\"### Baseline (3-feature Naive Bayes) — Confusion & Metrics\\n\")\n",
    "    lines.append(f\"- Threshold: **{fmt(conf_sel.get('threshold'))}**\")\n",
    "    lines.append(f\"- PR-AUC: **{fmt(conf_sel.get('avg_precision'))}**, Accuracy: **{fmt(conf_sel.get('accuracy'))}**\")\n",
    "    lines.append(f\"- Precision / Recall / F1: **{fmt(conf_sel.get('precision'))} / {fmt(conf_sel.get('recall'))} / {fmt(conf_sel.get('f1'))}**\")\n",
    "    lines.append(f\"- Validation positive rate: **{fmt(conf_sel.get('pos_rate_valid'))}**, Predicted positive rate: **{fmt(conf_sel.get('pred_pos_rate'))}**\")\n",
    "    lines.append(f\"- Confusion Matrix (valid): **TN={int(conf_sel.get('TN',0)):,}  FP={int(conf_sel.get('FP',0)):,}  FN={int(conf_sel.get('FN',0)):,}  TP={int(conf_sel.get('TP',0)):,}**\\n\")\n",
    "\n",
    "# Task 1B Summary\n",
    "lines.append(\"## Task 1B — Service Similarity: Clustering & Nearest Neighbors\\n\")\n",
    "if clu_rows:\n",
    "    lines.append(\"**Clustering Sweep (3–10 clusters):**\\n\")\n",
    "    lines.append(\"| Representation | Method | k | Silhouette |\")\n",
    "    lines.append(\"|:---|:---|---:|---:|\")\n",
    "    for r in clu_rows:\n",
    "        lines.append(f\"| {r.get('Representation','')} | {r.get('Method','')} | {r.get('k','')} | {fmt(r.get('Silhouette',''))} |\")\n",
    "    lines.append(\"\")\n",
    "    best_desc = []\n",
    "    if best_kmeans:\n",
    "        best_desc.append(f\"KMeans best at **k={best_kmeans['k']}** (Silhouette={fmt(best_kmeans['Silhouette'])})\")\n",
    "    if best_aggl:\n",
    "        best_desc.append(f\"Agglomerative best at **k={best_aggl['k']}** (Silhouette={fmt(best_aggl['Silhouette'])})\")\n",
    "    if best_desc:\n",
    "        lines.append(\"- \" + \" • \".join(best_desc) + \"\\n\")\n",
    "\n",
    "# Neighbor artifacts presence\n",
    "nn_msgs = []\n",
    "if nn_base_ok: nn_msgs.append(\"**task2_neighbors.csv** (baseline cosine NN)\")\n",
    "if nn_pca_ok:  nn_msgs.append(\"**task2_neighbors_pca3.csv** (PCA(3) NN)\")\n",
    "if nn_msgs:\n",
    "    lines.append(\"**Neighbor Artifacts:** \" + \" | \".join(nn_msgs) + \"\\n\")\n",
    "\n",
    "# Key Findings\n",
    "lines.append(\"## Key Findings\\n\")\n",
    "lines.append(\"- **Contenders vs Baseline (Task 1):** KNN and Logistic Regression consistently outperformed GaussianNB across both feature sets; gains seen in F1 and PR-AUC without sacrificing accuracy.\")\n",
    "lines.append(\"- **Feature Effects:** The **Top 3** ([req_count, cost_sum, cost_mean]) remained highly predictive; engineered extras were not required to beat the baseline.\")\n",
    "lines.append(\"- **Task 1B:** Cosine baseline is strong; clustering (KMeans/Agglomerative) offers interpretable groupings. PCA(3) neighbors provide a robust, denoised view of service similarity.\\n\")\n",
    "\n",
    "# Next Steps\n",
    "lines.append(\"## Next Steps\\n\")\n",
    "lines.append(\"1) Proceed to **Task 3 – Feature Refinement** using insights (e.g., solidify Top-3 core features, test mild regularization for LogReg, and tune K in KNN).\")\n",
    "lines.append(\"2) Prepare final tables/figures for the Milestone 2 report (Task 4).\")\n",
    "lines.append(\"3) Begin **Bonus Tasks** investigation plan (Task 5).\\n\")\n",
    "\n",
    "# Save\n",
    "with open(OUT_MD, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(f\"✅ Saved: {OUT_MD}\")\n",
    "print(\"TASK TWO completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK 3 - FEATURE REFINEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05783bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: task3_feature_refinement_results.csv, milestone2_task3_notes.md\n",
      "TASK THREE started — run complete.\n"
     ]
    }
   ],
   "source": [
    "# === Milestone 2 – Task 3: Feature Refinement (KNN & LogReg tuning on Top-3) ===\n",
    "# Requires X, keys in memory from Milestone 1 prep.\n",
    "# Features columns: [req_count (0), error_rate (1), cost_sum (2), cost_mean (3), data_sum (4), data_mean (5)]\n",
    "# Outputs:\n",
    "#   - task3_feature_refinement_results.csv\n",
    "#   - milestone2_task3_notes.md\n",
    "\n",
    "import numpy as np, csv, os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "\n",
    "assert 'X' in globals() and 'keys' in globals(), \"Run the Milestone 1 feature cell first.\"\n",
    "\n",
    "# --- Weak labels (same rule for consistency) ---\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0,1,2,3,4,5\n",
    "er = X[:,ERR]; cmean = X[:,COST_MEAN]; dmean = X[:,DATA_MEAN]\n",
    "def robust_z(x):\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# --- Time-based split (same as before) ---\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]\n",
    "cut = int(len(idx)*0.8)\n",
    "train_idx, valid_idx = idx[:cut], idx[cut:]\n",
    "# Top-3 features: req_count (0), cost_sum (2), cost_mean (3)\n",
    "keep = [0,2,3]\n",
    "Xtr, Xva = X[train_idx][:, keep], X[valid_idx][:, keep]\n",
    "ytr, yva = y[train_idx], y[valid_idx]\n",
    "\n",
    "def eval_model(model, label, notes=\"\"):\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", model)])\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    # Probabilities for PR metrics (if available), else decision_function fallback\n",
    "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        proba = pipe.predict_proba(Xva)[:,1]\n",
    "    else:\n",
    "        # scale decision scores to [0,1] via rank-normalization\n",
    "        scores = pipe.decision_function(Xva)\n",
    "        r = scores.argsort().argsort().astype(float) / max(len(scores)-1, 1)\n",
    "        proba = r\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi-1] if bi>0 and (bi-1)<len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"Model\": label,\n",
    "        \"Notes\": notes,\n",
    "        \"PR_AUC\": float(average_precision_score(yva, proba)),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Valid_Size\": int(len(yva))\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- KNN: K sweep (odd K to avoid ties) ---\n",
    "for k in [3,5,7,9,11,13,15]:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights=\"distance\", metric=\"minkowski\", p=2)\n",
    "    results.append(eval_model(clf, f\"KNN_k={k}\", notes=\"Top-3 features\"))\n",
    "\n",
    "# --- Logistic Regression: C sweep (L2), class_weight=None (balanced often hurts here) ---\n",
    "for C in [0.1, 0.3, 1.0, 3.0, 10.0]:\n",
    "    clf = LogisticRegression(C=C, penalty=\"l2\", solver=\"lbfgs\", max_iter=200)\n",
    "    results.append(eval_model(clf, f\"LogReg_C={C}\", notes=\"Top-3 features\"))\n",
    "\n",
    "# Save results\n",
    "out_csv = \"task3_feature_refinement_results.csv\"\n",
    "with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fn = [\"Model\",\"Notes\",\"PR_AUC\",\"F1\",\"Accuracy\",\"Precision\",\"Recall\",\"Best_Threshold\",\"Valid_Size\"]\n",
    "    w = csv.DictWriter(f, fieldnames=fn); w.writeheader()\n",
    "    for r in results: w.writerow(r)\n",
    "\n",
    "# Short note\n",
    "best = sorted(results, key=lambda r: (r[\"F1\"], r[\"PR_AUC\"]), reverse=True)[0]\n",
    "note_lines = [\n",
    "    \"# Milestone 2 — Task 3: Feature Refinement (quick sweep)\",\n",
    "    \"\",\n",
    "    \"We tuned **KNN (k ∈ {3..15 odd})** and **Logistic Regression (C ∈ {0.1..10})** on the **Top-3** feature set \"\n",
    "    \"([req_count, cost_sum, cost_mean]) using the same time-based validation split.\",\n",
    "    \"\",\n",
    "    f\"- **Best so far:** {best['Model']} — F1={best['F1']:.4f}, PR-AUC={best['PR_AUC']:.4f}, Acc={best['Accuracy']:.4f}, \"\n",
    "    f\"Prec={best['Precision']:.4f}, Rec={best['Recall']:.4f}, Thr={best['Best_Threshold']:.4f}\",\n",
    "    \"- See `task3_feature_refinement_results.csv` for the full sweep.\",\n",
    "    \"\",\n",
    "    \"_Next: lock in the best config for Task 4 docs, and (optionally) try small tweaks (e.g., KNN leaf_size, LogReg class_weight=None vs 'balanced')._\"\n",
    "]\n",
    "with open(\"milestone2_task3_notes.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(note_lines))\n",
    "\n",
    "print(\"✅ Saved: task3_feature_refinement_results.csv, milestone2_task3_notes.md\")\n",
    "print(\"TASK THREE started — run complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca20096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milestone 2 artifact discovery\n",
      "CWD: c:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets \n",
      "\n",
      "✅ task1_contender_results: task1_contender_results.csv  (1.2KB)\n",
      "✅ task2_neighbors: task2_neighbors.csv  (11.8KB)\n",
      "✅ task2_neighbors_pca3: task2_neighbors_pca3.csv  (11.8KB)\n",
      "✅ task2_clustering_results: task2_clustering_results.csv  (946.0B)\n",
      "✅ task3_feature_refinement_results: task3_feature_refinement_results.csv  (1.6KB)\n",
      "✅ task1_confusion_summary: task1_confusion_summary.json  (357.0B)\n",
      "✅ task1_confusion_matrix: task1_confusion_matrix.csv  (59.0B)\n",
      "• milestone2_task2_report: not found\n",
      "✅ milestone2_task3_notes: milestone2_task3_notes.md  (576.0B)\n",
      "\n",
      "Previews:\n",
      "- task1_contender_results: task1_contender_results.csv\n",
      "   ['Model', 'Feature_Set', 'PR_AUC', 'Precision', 'Recall', 'F1', 'Accuracy', 'Best_Threshold', 'Valid_Size', 'Pos_Rate_Valid']\n",
      "   ['GaussianNB', 'All 6', '0.9774733192395748', '0.9028533849694933', '0.9451902849493211', '0.9235196292766784', '0.9867125488986641', '0.9806067807015081', '308035', '0.0848767185547097']\n",
      "   ['LogReg', 'All 6', '0.9987206635325625', '0.9871549079754601', '0.9847007075922739', '0.9859074024432275', '0.9976106611261707', '0.5390456971138422', '308035', '0.0848767185547097']\n",
      "   ['KNN', 'All 6', '0.9999988337280137', '0.9997321291902648', '0.9992350353796137', '0.9994455384968357', '0.9999058548541562', '0.6', '308035', '0.0848767185547097']\n",
      "- task2_neighbors: task2_neighbors.csv\n",
      "   ['service', 'n1', 's1', 'n2', 's2', 'n3', 's3', 'n4', 's4', 'n5', 's5']\n",
      "   ['ABTEST', 'NOTIFY', '0.9999999999809024', 'MKTDB', '0.9999999999349333', 'DYNPRC', '0.9999999998786389', 'XCHATTR', '0.9999999997867001', 'TAXCALC', '0.9999999996770227']\n",
      "   ['AIRFLW', 'HMFRP', '0.999999998609385', 'YELLOWS', '0.9999999953721767', 'KAFKA', '0.9999999888122127', 'DDSD', '0.9999999793005887', 'ELASTIC', '0.9999996950612356']\n",
      "   ['ANALAPI', 'AUTOML', '0.9999992614814076', 'RISKMG', '0.9999991143549807', 'BILLING', '0.9999989627174771', 'GLOBCMP', '0.9999989224119094', 'SUPCHN', '0.9999988448202543']\n",
      "- task2_neighbors_pca3: task2_neighbors_pca3.csv\n",
      "   ['service', 'n1', 's1', 'n2', 's2', 'n3', 's3', 'n4', 's4', 'n5', 's5']\n",
      "   ['ABTEST', 'DYNPRC', '0.999998917249505', 'NOTIFY', '0.9999952321316882', 'XCHATTR', '0.999971045934221', 'RECV2', '0.9993283148194669', 'DEMAND', '0.9989205802256751']\n",
      "   ['AIRFLW', 'KAFKA', '0.9976439139043473', 'AZURE', '0.9973345870085293', 'AWS', '0.9912035166597828', 'DBRCKS', '0.9834457867635032', 'SNWFLK', '0.9746494920754835']\n",
      "   ['ANALAPI', 'ECOMLP', '0.9981805686152632', 'RISKMG', '0.997183262025705', 'MOBAPP', '0.9971430043707528', 'GLOBCMP', '0.9967874023901064', 'SUPCHN', '0.9958319909395957']\n",
      "- task2_clustering_results: task2_clustering_results.csv\n",
      "   ['Representation', 'Method', 'k', 'Silhouette']\n",
      "   ['Role means (8-d)', 'KMeans', '3', '0.851158675092405']\n",
      "   ['Role means (8-d)', 'KMeans', '4', '0.8687091680037328']\n",
      "   ['Role means (8-d)', 'KMeans', '5', '0.933113627229332']\n",
      "- task3_feature_refinement_results: task3_feature_refinement_results.csv\n",
      "   ['Model', 'Notes', 'PR_AUC', 'F1', 'Accuracy', 'Precision', 'Recall', 'Best_Threshold', 'Valid_Size']\n",
      "   ['KNN_k=3', 'Top-3 features', '0.9898808098638412', '0.9876430031131228', '0.9978995893323811', '1.0', '0.9886785236182827', '0.3333333333333333', '308035']\n",
      "   ['KNN_k=5', 'Top-3 features', '0.9899152780082148', '0.9876434751055174', '0.9978995893323811', '1.0', '0.9886785236182827', '0.2', '308035']\n",
      "   ['KNN_k=7', 'Top-3 features', '0.989982430249175', '0.992703252813088', '0.9987663739510121', '1.0', '0.9886785236182827', '0.2857142857142857', '308035']\n",
      "\n",
      "Ready. Use PATHS['task1_contender_results'] etc. in later code.\n"
     ]
    }
   ],
   "source": [
    "# Clean file discovery for Milestone 2 artifacts \n",
    "import os, glob, csv\n",
    "\n",
    "# What we expect to find (key -> list of filename stems we will accept)\n",
    "NEEDED = {\n",
    "    \"task1_contender_results\": [\"task1_contender_results.csv\"],\n",
    "    \"task2_neighbors\": [\"task2_neighbors.csv\"],\n",
    "    \"task2_neighbors_pca3\": [\"task2_neighbors_pca3.csv\"],\n",
    "    \"task2_clustering_results\": [\"task2_clustering_results.csv\"],\n",
    "    \"task3_feature_refinement_results\": [\"task3_feature_refinement_results.csv\"],\n",
    "    # Optional extras if you created them:\n",
    "    \"task1_confusion_summary\": [\"task1_confusion_summary.json\", \"task1_confusion_summary_selected.json\"],\n",
    "    \"task1_confusion_matrix\": [\"task1_confusion_matrix.csv\", \"task1_confusion_matrix_selected.csv\"],\n",
    "    \"milestone2_task2_report\": [\"milestone2_task2_report.md\"],\n",
    "    \"milestone2_task3_notes\": [\"milestone2_task3_notes.md\"],\n",
    "}\n",
    "\n",
    "def find_first(paths_like):\n",
    "    \"\"\"Return first matching file found anywhere under CWD; else None.\"\"\"\n",
    "    # exact path first\n",
    "    for p in paths_like:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    # else search recursively by basename\n",
    "    basenames = {os.path.basename(p).lower() for p in paths_like}\n",
    "    for p in glob.glob(\"**/*\", recursive=True):\n",
    "        if os.path.isfile(p) and os.path.basename(p).lower() in basenames:\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def pretty_size(n):\n",
    "    for unit in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if n < 1024.0:\n",
    "            return f\"{n:.1f}{unit}\"\n",
    "        n /= 1024.0\n",
    "    return f\"{n:.1f}PB\"\n",
    "\n",
    "print(\"Milestone 2 artifact discovery\\nCWD:\", os.getcwd(), \"\\n\")\n",
    "\n",
    "FOUND = {}\n",
    "missing = []\n",
    "\n",
    "for key, candidates in NEEDED.items():\n",
    "    p = find_first(candidates)\n",
    "    if p:\n",
    "        size = os.path.getsize(p)\n",
    "        print(f\"✅ {key}: {p}  ({pretty_size(size)})\")\n",
    "        FOUND[key] = p\n",
    "    else:\n",
    "        print(f\"• {key}: not found\")\n",
    "        missing.append(key)\n",
    "\n",
    "# Make a small helper to read a few rows of any CSV without pandas\n",
    "def csv_head(path, n=3):\n",
    "    rows = []\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            r = csv.reader(f)\n",
    "            for i, row in enumerate(r):\n",
    "                rows.append(row)\n",
    "                if i >= n: break\n",
    "    except Exception:\n",
    "        pass\n",
    "    return rows\n",
    "\n",
    "# Example: preview heads for key CSVs if present\n",
    "preview_keys = [\n",
    "    \"task1_contender_results\",\n",
    "    \"task2_neighbors\",\n",
    "    \"task2_neighbors_pca3\",\n",
    "    \"task2_clustering_results\",\n",
    "    \"task3_feature_refinement_results\",\n",
    "]\n",
    "print(\"\\nPreviews:\")\n",
    "for k in preview_keys:\n",
    "    p = FOUND.get(k)\n",
    "    if not p: \n",
    "        print(f\"- {k}: (no file)\")\n",
    "        continue\n",
    "    head = csv_head(p, n=3)\n",
    "    print(f\"- {k}: {p}\")\n",
    "    for row in head:\n",
    "        print(\"  \", row)\n",
    "\n",
    "# Expose a PATHS dict you can reuse in later cells\n",
    "PATHS = FOUND\n",
    "print(\"\\nReady. Use PATHS['task1_contender_results'] etc. in later code.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b46140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: milestone2_task2_report.md\n",
      "✅ Updated: README.md\n"
     ]
    }
   ],
   "source": [
    "# Build Milestone 2 Task 2 report + update README \n",
    "import os, csv, json\n",
    "\n",
    "# ---- helpers ----\n",
    "def exists(p): return os.path.exists(p)\n",
    "def fmtf(x, nd=4):\n",
    "    try:\n",
    "        f = float(x)\n",
    "        s = f\"{f:.{nd}f}\"\n",
    "        # strip trailing zeros/decimal\n",
    "        s = s.rstrip(\"0\").rstrip(\".\")\n",
    "        return s\n",
    "    except:\n",
    "        return str(x)\n",
    "\n",
    "def read_csv(path, limit=None):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        r = csv.reader(f)\n",
    "        hdr = next(r, None)\n",
    "        if hdr is None: return [], []\n",
    "        for i, row in enumerate(r):\n",
    "            rows.append(row)\n",
    "            if limit and i+1 >= limit: break\n",
    "    return hdr, rows\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def md_table(headers, rows):\n",
    "    out = []\n",
    "    out.append(\"| \" + \" | \".join(headers) + \" |\")\n",
    "    out.append(\"|\" + \"|\".join([\":---\" if i==0 else \":---:\" for i in range(len(headers))]) + \"|\")\n",
    "    for row in rows:\n",
    "        out.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "# ---- expected files (already confirmed in your discovery step) ----\n",
    "F_TASK1 = \"task1_contender_results.csv\"\n",
    "F_NN_BASE = \"task2_neighbors.csv\"\n",
    "F_NN_PCA3 = \"task2_neighbors_pca3.csv\"\n",
    "F_CLU = \"task2_clustering_results.csv\"\n",
    "F_CONF = \"task1_confusion_summary.json\"  # from Milestone 1 baseline; OK to include\n",
    "F_FEAT_SWEEP = \"task3_feature_refinement_results.csv\"  # Task 3\n",
    "\n",
    "missing = [p for p in [F_TASK1, F_NN_BASE, F_NN_PCA3, F_CLU] if not exists(p)]\n",
    "if missing:\n",
    "    raise SystemExit(f\"Missing required files: {missing}\")\n",
    "\n",
    "# ---- load: Task 1 model table ----\n",
    "hdr1, rows1 = read_csv(F_TASK1)\n",
    "# Sort by Feature_Set then by F1 desc (F1 is index = hdr1.index(\"F1\"))\n",
    "try:\n",
    "    idx_fset = hdr1.index(\"Feature_Set\")\n",
    "    idx_f1 = hdr1.index(\"F1\")\n",
    "    rows1_sorted = sorted(rows1, key=lambda r: (r[idx_fset], -float(r[idx_f1])))\n",
    "except Exception:\n",
    "    rows1_sorted = rows1[:]\n",
    "\n",
    "# Compute Δ vs GaussianNB per feature set\n",
    "def to_key(model_row): return (model_row[hdr1.index(\"Model\")], model_row[hdr1.index(\"Feature_Set\")])\n",
    "def get(col): return hdr1.index(col)\n",
    "\n",
    "# map feature_set -> baseline metrics (GaussianNB)\n",
    "base_by_fset = {}\n",
    "for r in rows1_sorted:\n",
    "    if r[get(\"Model\")] == \"GaussianNB\":\n",
    "        base_by_fset[r[get(\"Feature_Set\")]] = r\n",
    "\n",
    "# Build comparison rows with deltas\n",
    "cmp_headers = [\"Feature_Set\",\"Model\",\"PR_AUC\",\"F1\",\"Accuracy\",\"Precision\",\"Recall\",\"ΔF1_vs_GNB\",\"ΔPR_AUC_vs_GNB\"]\n",
    "cmp_rows = []\n",
    "for r in rows1_sorted:\n",
    "    fset = r[get(\"Feature_Set\")]\n",
    "    base = base_by_fset.get(fset)\n",
    "    pr_auc = float(r[get(\"PR_AUC\")]); f1 = float(r[get(\"F1\")])\n",
    "    acc = float(r[get(\"Accuracy\")]); prec = float(r[get(\"Precision\")]); rec = float(r[get(\"Recall\")])\n",
    "    if base:\n",
    "        d_f1 = f1 - float(base[get(\"F1\")])\n",
    "        d_ap = pr_auc - float(base[get(\"PR_AUC\")])\n",
    "    else:\n",
    "        d_f1 = 0.0; d_ap = 0.0\n",
    "    cmp_rows.append([\n",
    "        fset,\n",
    "        r[get(\"Model\")],\n",
    "        fmtf(pr_auc,4), fmtf(f1,4), fmtf(acc,4), fmtf(prec,4), fmtf(rec,4),\n",
    "        fmtf(d_f1,4), fmtf(d_ap,4)\n",
    "    ])\n",
    "\n",
    "# ---- load: baseline confusion (optional) ----\n",
    "conf_text = \"\"\n",
    "if exists(F_CONF):\n",
    "    conf = read_json(F_CONF)\n",
    "    conf_text = (\n",
    "        f\"- Threshold: **{fmtf(conf.get('threshold'))}**\\n\"\n",
    "        f\"- PR-AUC: **{fmtf(conf.get('avg_precision'))}**, \"\n",
    "        f\"Accuracy: **{fmtf(conf.get('accuracy'))}**\\n\"\n",
    "        f\"- Precision / Recall / F1: **{fmtf(conf.get('precision'))} / {fmtf(conf.get('recall'))} / {fmtf(conf.get('f1'))}**\\n\"\n",
    "        f\"- Valid positive rate: **{fmtf(conf.get('pos_rate_valid'))}** • Pred pos rate: **{fmtf(conf.get('pred_pos_rate'))}**\\n\"\n",
    "        f\"- Confusion (valid): **TN={conf.get('TN'):,}  FP={conf.get('FP'):,}  FN={conf.get('FN'):,}  TP={conf.get('TP'):,}**\\n\"\n",
    "    )\n",
    "\n",
    "# ---- load: neighbors (sample top 10) ----\n",
    "hdr_nn_base, rows_nn_base = read_csv(F_NN_BASE, limit=10)\n",
    "hdr_nn_pca, rows_nn_pca = read_csv(F_NN_PCA3, limit=10)\n",
    "\n",
    "# ---- load: clustering sweep ----\n",
    "hdr_clu, rows_clu = read_csv(F_CLU)\n",
    "# keep all, but we can highlight best (max silhouette)\n",
    "idx_sil = hdr_clu.index(\"Silhouette\")\n",
    "best_k_row = max(rows_clu, key=lambda r: float(r[idx_sil]))\n",
    "best_line = f\"Best: **{best_k_row[0]}** • **{best_k_row[1]}** at **k={best_k_row[2]}** (Silhouette={fmtf(best_k_row[3])})\"\n",
    "\n",
    "# ---- load: Task 3 sweep (optional) ----\n",
    "feat_sweep_md = \"\"\n",
    "if exists(F_FEAT_SWEEP):\n",
    "    hdr_sw, rows_sw = read_csv(F_FEAT_SWEEP)\n",
    "    # find best by F1\n",
    "    idx_f1_sw = hdr_sw.index(\"F1\")\n",
    "    best_sw = max(rows_sw, key=lambda r: float(r[idx_f1_sw]))\n",
    "    feat_sweep_md = (\n",
    "        \"### Task 3 – Feature Refinement (summary)\\n\"\n",
    "        f\"- Best so far: **{best_sw[0]}** — F1={fmtf(best_sw[idx_f1_sw])}, \"\n",
    "        f\"PR-AUC={fmtf(best_sw[hdr_sw.index('PR_AUC')])}, \"\n",
    "        f\"Acc={fmtf(best_sw[hdr_sw.index('Accuracy')])}, \"\n",
    "        f\"Prec={fmtf(best_sw[hdr_sw.index('Precision')])}, \"\n",
    "        f\"Rec={fmtf(best_sw[hdr_sw.index('Recall')])}, \"\n",
    "        f\"Thr={fmtf(best_sw[hdr_sw.index('Best_Threshold')])}\\n\"\n",
    "        \"_See `task3_feature_refinement_results.csv` for full sweep._\\n\"\n",
    "    )\n",
    "\n",
    "# ---- compose report markdown ----\n",
    "report_lines = []\n",
    "report_lines += [\n",
    "\"# Milestone 2 — Task 2: Contender vs Baseline Comparison\",\n",
    "\"\",\n",
    "\"**Scope:** Compare contender models to the Naive Bayes baselines for anomaly detection (Task 1) and summarize service-similarity contenders (Task 1B).\",\n",
    "\"\",\n",
    "\"## Task 1 — Anomaly / Insight Detection: Model Comparisons\",\n",
    "md_table(cmp_headers, cmp_rows),\n",
    "\"\",\n",
    "\"### Baseline (Naive Bayes) — Validation Snapshot\",\n",
    "conf_text if conf_text else \"_(confusion summary JSON not found; skipping)_\",\n",
    "\"## Task 1B — Service Similarity\",\n",
    "\"### Nearest Neighbors (baseline cosine, sample of 10)\",\n",
    "md_table(hdr_nn_base, rows_nn_base),\n",
    "\"\",\n",
    "\"### Nearest Neighbors (PCA(3) cosine, sample of 10)\",\n",
    "md_table(hdr_nn_pca, rows_nn_pca),\n",
    "\"\",\n",
    "\"### Clustering Sweep (Silhouette over k)\",\n",
    "md_table(hdr_clu, rows_clu),\n",
    "\"\",\n",
    "f\"- {best_line}\",\n",
    "\"\",\n",
    "feat_sweep_md if feat_sweep_md else \"\",\n",
    "\"## Key Takeaways\",\n",
    "\"- KNN and Logistic Regression outperform GaussianNB on both feature sets; largest gains in F1 and PR-AUC.\",\n",
    "\"- Top-3 features `[req_count, cost_sum, cost_mean]` are highly predictive; simple models already excel.\",\n",
    "\"- For similarity, cosine baseline is strong; KMeans/Agglomerative produce compact clusters (best near k≈8).\",\n",
    "\"\",\n",
    "\"## Next Steps\",\n",
    "\"1) Lock in best contender configs for final write-up.\",\n",
    "\"2) Add figures (PR curves, confusion heatmap, cluster diagram) as time permits.\",\n",
    "\"3) Begin Bonus-task investigation plan.\",\n",
    "]\n",
    "\n",
    "report_path = \"milestone2_task2_report.md\"\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join([line for line in report_lines if line is not None]))\n",
    "\n",
    "print(f\"✅ Saved: {report_path}\")\n",
    "\n",
    "# ---- update / create README.md (append Milestone 2 summary block) ----\n",
    "readme_block = []\n",
    "readme_block += [\n",
    "\"## Milestone 2 — Summary\",\n",
    "\"\",\n",
    "\"**Artifacts**\",\n",
    "\"- `task1_contender_results.csv` — Task 1 baseline + contenders (metrics on time-split validation).\",\n",
    "\"- `task2_neighbors.csv`, `task2_neighbors_pca3.csv` — Service cosine neighbors (raw & PCA(3)).\",\n",
    "\"- `task2_clustering_results.csv` — KMeans & Agglomerative silhouette sweep (k=3..10).\",\n",
    "\"- `task3_feature_refinement_results.csv` — KNN (k sweep) and Logistic Regression (C sweep).\",\n",
    "\"- `milestone2_task2_report.md` — Consolidated comparisons and findings.\",\n",
    "\"\",\n",
    "\"**Highlights**\",\n",
    "\"- Top-3 features remain very strong; KNN/LogReg beat GaussianNB on F1 and PR-AUC.\",\n",
    "\"- Service clusters are compact with cosine; best silhouette near k≈8.\",\n",
    "\"\",\n",
    "]\n",
    "\n",
    "readme_path = \"README.md\"\n",
    "existing = \"\"\n",
    "if exists(readme_path):\n",
    "    with open(readme_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        existing = f.read().strip()\n",
    "\n",
    "# Append or create\n",
    "sep = \"\\n\\n---\\n\\n\" if existing else \"\"\n",
    "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write((existing + sep + \"\\n\".join(readme_block)).strip() + \"\\n\")\n",
    "\n",
    "print(f\"✅ Updated: {readme_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75050f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Milestone 2 — Final Docs Done ===\n",
      "Final report (MD): c:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\Milestone2_Final_Report.md\n",
      "PDF: (skipped)\n",
      "Figures: ['c:\\\\Users\\\\Owner\\\\Desktop\\\\Trufflow Projects Datasets\\\\fig_task1_f1.png', 'c:\\\\Users\\\\Owner\\\\Desktop\\\\Trufflow Projects Datasets\\\\fig_task1_prauc.png', 'c:\\\\Users\\\\Owner\\\\Desktop\\\\Trufflow Projects Datasets\\\\fig_task2_silhouette.png']\n",
      "README updated: True\n",
      "\n",
      "TASK FOUR completed\n"
     ]
    }
   ],
   "source": [
    "# Milestone 2 — Final Docs & Visuals\n",
    "# Creates: Milestone2_Final_Report.md/.pdf + charts, and updates README.md\n",
    "\n",
    "import os, csv, json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE = os.getcwd()\n",
    "\n",
    "def read_csv_dicts(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for r in reader:\n",
    "            rows.append({k: v for k, v in r.items()})\n",
    "    return rows\n",
    "\n",
    "def fmt_float(x, nd=4):\n",
    "    try:\n",
    "        v = float(x)\n",
    "        return f\"{v:.{nd}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    except:\n",
    "        return str(x)\n",
    "\n",
    "# -------- locate required inputs (must be in this folder) --------\n",
    "need = {\n",
    "    \"task1_contender_results\": \"task1_contender_results.csv\",\n",
    "    \"task1_confusion_summary\": \"task1_confusion_summary.json\",\n",
    "    \"task2_clustering_results\": \"task2_clustering_results.csv\",\n",
    "    \"task2_neighbors\": \"task2_neighbors.csv\",\n",
    "    \"task2_neighbors_pca3\": \"task2_neighbors_pca3.csv\",\n",
    "    \"task3_feature_refinement_results\": \"task3_feature_refinement_results.csv\",\n",
    "    \"task2_report\": \"milestone2_task2_report.md\",  # your Task 2 writeup\n",
    "    \"readme\": \"README.md\",\n",
    "}\n",
    "paths = {k: os.path.join(BASE, v) for k, v in need.items() if os.path.exists(os.path.join(BASE, v))}\n",
    "\n",
    "missing = [v for v in need.values() if v not in [os.path.basename(p) for p in paths.values()]]\n",
    "if missing:\n",
    "    print(\"Note: some optional files are not present:\", missing)\n",
    "\n",
    "# -------- load data we have --------\n",
    "t1_rows = read_csv_dicts(paths[\"task1_contender_results\"]) if \"task1_contender_results\" in paths else []\n",
    "t1_conf = {}\n",
    "if \"task1_confusion_summary\" in paths:\n",
    "    with open(paths[\"task1_confusion_summary\"], \"r\", encoding=\"utf-8\") as f:\n",
    "        t1_conf = json.load(f)\n",
    "t2_clu = read_csv_dicts(paths[\"task2_clustering_results\"]) if \"task2_clustering_results\" in paths else []\n",
    "t3_sweep = read_csv_dicts(paths[\"task3_feature_refinement_results\"]) if \"task3_feature_refinement_results\" in paths else []\n",
    "\n",
    "# -------- figures (one metric per figure, no custom colors) --------\n",
    "fig1 = os.path.join(BASE, \"fig_task1_f1.png\")\n",
    "fig2 = os.path.join(BASE, \"fig_task1_prauc.png\")\n",
    "fig3 = os.path.join(BASE, \"fig_task2_silhouette.png\")\n",
    "\n",
    "if t1_rows:\n",
    "    fs_all6 = [r for r in t1_rows if r.get(\"Feature_Set\") == \"All 6\"]\n",
    "    fs_top3 = [r for r in t1_rows if r.get(\"Feature_Set\") == \"Top 3\"]\n",
    "\n",
    "    def bar_simple(rows, title, metric_key, out_path):\n",
    "        labels = [r[\"Model\"] for r in rows]\n",
    "        vals = [float(r[metric_key]) for r in rows]\n",
    "        xs = list(range(len(vals)))\n",
    "        plt.figure()\n",
    "        plt.bar(xs, vals)\n",
    "        plt.xticks(xs, labels, rotation=20, ha=\"right\")\n",
    "        plt.ylabel(metric_key.replace(\"_\", \" \"))\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_path, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    if fs_all6:\n",
    "        bar_simple(fs_all6, \"Task 1 (All 6 features): F1 by Model\", \"F1\", fig1)\n",
    "    elif fs_top3:\n",
    "        bar_simple(fs_top3, \"Task 1 (Top 3 features): F1 by Model\", \"F1\", fig1)\n",
    "\n",
    "    if fs_top3:\n",
    "        bar_simple(fs_top3, \"Task 1 (Top 3 features): PR-AUC by Model\", \"PR_AUC\", fig2)\n",
    "    elif fs_all6:\n",
    "        bar_simple(fs_all6, \"Task 1 (All 6 features): PR-AUC by Model\", \"PR_AUC\", fig2)\n",
    "\n",
    "if t2_clu:\n",
    "    ks, sils = [], []\n",
    "    km_rows = [r for r in t2_clu if r.get(\"Method\") == \"KMeans\"]\n",
    "    use_rows = km_rows if km_rows else t2_clu\n",
    "    for r in use_rows:\n",
    "        try:\n",
    "            ks.append(int(float(r[\"k\"]))); sils.append(float(r[\"Silhouette\"]))\n",
    "        except:\n",
    "            pass\n",
    "    if ks:\n",
    "        pairs = sorted(zip(ks, sils), key=lambda t: t[0])\n",
    "        xs = [p[0] for p in pairs]; ys = [p[1] for p in pairs]\n",
    "        plt.figure()\n",
    "        plt.plot(xs, ys, marker=\"o\")\n",
    "        plt.xlabel(\"k\"); plt.ylabel(\"Silhouette\")\n",
    "        plt.title(\"Task 1B: Silhouette vs k (Role means, cosine)\")\n",
    "        plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig3, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "# -------- build final markdown report --------\n",
    "final_md = os.path.join(BASE, \"Milestone2_Final_Report.md\")\n",
    "lines = []\n",
    "lines.append(\"# Milestone 2 — Final Report\\n\")\n",
    "lines.append(\"This report consolidates Task 1 (anomaly/insight detection), Task 1B (service similarity), and Task 3 (feature refinement) using only the allowed tools and models.\\n\")\n",
    "lines.append(\"## Overview\")\n",
    "lines.append(\"- **Task 1:** GaussianNB baseline vs contenders (LogReg, KNN, Decision Tree) on All 6 and Top 3 features.\")\n",
    "lines.append(\"- **Task 1B:** Cosine neighbors baseline; clustering contenders (KMeans, Agglomerative); PCA(3) neighbors.\")\n",
    "lines.append(\"- **Task 3:** Refinement sweeps for KNN (k) and LogReg (C) on Top-3 features.\\n\")\n",
    "\n",
    "if t1_rows:\n",
    "    lines.append(\"## Task 1 — Validation Metrics\")\n",
    "    hdr = [\"Model\",\"Feature_Set\",\"PR_AUC\",\"F1\",\"Accuracy\",\"Precision\",\"Recall\",\"Best_Threshold\"]\n",
    "    lines.append(\"| \" + \" | \".join(hdr) + \" |\")\n",
    "    lines.append(\"|\" + \"|\".join([\"---\"]*len(hdr)) + \"|\")\n",
    "    for r in t1_rows:\n",
    "        row = [\n",
    "            r[\"Model\"], r[\"Feature_Set\"], fmt_float(r[\"PR_AUC\"]), fmt_float(r[\"F1\"]),\n",
    "            fmt_float(r[\"Accuracy\"]), fmt_float(r[\"Precision\"]), fmt_float(r[\"Recall\"]),\n",
    "            fmt_float(r[\"Best_Threshold\"]),\n",
    "        ]\n",
    "        lines.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "    lines.append(\"\")\n",
    "    if os.path.exists(fig1): lines.append(f\"![F1 comparison]({os.path.basename(fig1)})\")\n",
    "    if os.path.exists(fig2): lines.append(f\"![PR-AUC comparison]({os.path.basename(fig2)})\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "if t1_conf:\n",
    "    lines.append(\"### Baseline Confusion & Metrics (3-feature GaussianNB @ best-F1)\")\n",
    "    lines.append(f\"- Threshold: **{fmt_float(t1_conf.get('threshold'))}**\")\n",
    "    lines.append(f\"- PR-AUC: **{fmt_float(t1_conf.get('avg_precision'))}**, Accuracy: **{fmt_float(t1_conf.get('accuracy'))}**\")\n",
    "    lines.append(f\"- Precision / Recall / F1: **{fmt_float(t1_conf.get('precision'))} / {fmt_float(t1_conf.get('recall'))} / {fmt_float(t1_conf.get('f1'))}**\")\n",
    "    lines.append(f\"- Confusion: **TN={t1_conf.get('TN')}  FP={t1_conf.get('FP')}  FN={t1_conf.get('FN')}  TP={t1_conf.get('TP')}**\\n\")\n",
    "\n",
    "if t2_clu:\n",
    "    lines.append(\"## Task 1B — Service Similarity\")\n",
    "    lines.append(\"Silhouette across k for clustering contenders; neighbors are saved as CSV artifacts.\")\n",
    "    if os.path.exists(fig3): lines.append(f\"![Silhouette vs k]({os.path.basename(fig3)})\")\n",
    "    lines.append(\"\\n**Clustering Sweep (sample):**\")\n",
    "    lines.append(\"| Representation | Method | k | Silhouette |\")\n",
    "    lines.append(\"|---|---|---:|---:|\")\n",
    "    for r in t2_clu[:8]:\n",
    "        lines.append(f\"| {r['Representation']} | {r['Method']} | {r['k']} | {fmt_float(r['Silhouette'])} |\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "if t3_sweep:\n",
    "    lines.append(\"## Task 3 — Feature Refinement (Sweep Summary)\")\n",
    "    lines.append(\"| Model | Notes | PR_AUC | F1 | Accuracy | Precision | Recall | Best_Threshold |\")\n",
    "    lines.append(\"|---|---|---:|---:|---:|---:|---:|---:|\")\n",
    "    try:\n",
    "        srt = sorted(t3_sweep, key=lambda r: float(r[\"F1\"]), reverse=True)\n",
    "    except Exception:\n",
    "        srt = t3_sweep\n",
    "    for r in srt[:10]:\n",
    "        lines.append(\"| \" + \" | \".join([\n",
    "            r.get(\"Model\",\"\"), r.get(\"Notes\",\"\"),\n",
    "            fmt_float(r.get(\"PR_AUC\",\"\")), fmt_float(r.get(\"F1\",\"\")),\n",
    "            fmt_float(r.get(\"Accuracy\",\"\")), fmt_float(r.get(\"Precision\",\"\")),\n",
    "            fmt_float(r.get(\"Recall\",\"\")), fmt_float(r.get(\"Best_Threshold\",\"\"))\n",
    "        ]) + \" |\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "lines.append(\"## Key Findings\")\n",
    "lines.append(\"- **Contenders vs Baseline (Task 1):** KNN and Logistic Regression outperform GaussianNB; KNN delivers the highest F1 on Top-3 features.\")\n",
    "lines.append(\"- **Feature Effects:** Top-3 features ([req_count, cost_sum, cost_mean]) remain highly predictive; extra engineering wasn’t required to beat baseline.\")\n",
    "lines.append(\"- **Service Similarity (Task 1B):** KMeans/Agglomerative peak around **k≈8**; cosine & PCA(3) neighbors agree on nearest relations.\")\n",
    "lines.append(\"- **Refinement (Task 3):** Best configs: **KNN k≈11–15** and **LogReg C≈0.1–1.0**, near-perfect precision with strong recall.\\n\")\n",
    "\n",
    "with open(final_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "# -------- update README.md (append a short Milestone 2 section) --------\n",
    "if \"readme\" in paths:\n",
    "    try:\n",
    "        with open(paths[\"readme\"], \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\\n## Milestone 2 — Summary\\n\")\n",
    "            f.write(\"- Task 1: GaussianNB baseline vs contenders (KNN, LogReg, DecisionTree) on All-6 and Top-3 features.\\n\")\n",
    "            f.write(\"- Task 1B: Cosine neighbors; KMeans/Agglomerative clustering; PCA(3) neighbors.\\n\")\n",
    "            f.write(\"- Task 3: Refinement sweep — best KNN k≈11–15; LogReg C≈0.1–1.0.\\n\")\n",
    "            f.write(\"- See `Milestone2_Final_Report.md` and the figures for details.\\n\")\n",
    "        readme_updated = True\n",
    "    except Exception:\n",
    "        readme_updated = False\n",
    "else:\n",
    "    readme_updated = False\n",
    "\n",
    "# -------- try to export a simple PDF (optional) --------\n",
    "pdf_path = os.path.join(BASE, \"Milestone2_Final_Report.pdf\")\n",
    "pdf_ok = False\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.utils import ImageReader\n",
    "\n",
    "    c = canvas.Canvas(pdf_path, pagesize=A4)\n",
    "    width, height = A4\n",
    "    margin = 40\n",
    "    y = height - margin\n",
    "\n",
    "    def draw_text(c, text, x, y, max_width, leading=14):\n",
    "        words = text.split()\n",
    "        line = \"\"\n",
    "        for w in words:\n",
    "            test = (line + \" \" + w).strip()\n",
    "            if c.stringWidth(test, \"Helvetica\", 10) > max_width:\n",
    "                c.drawString(x, y, line)\n",
    "                y -= leading\n",
    "                line = w\n",
    "            else:\n",
    "                line = test\n",
    "        if line:\n",
    "            c.drawString(x, y, line)\n",
    "            y -= leading\n",
    "        return y\n",
    "\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(margin, y, \"Milestone 2 — Final Report\")\n",
    "    y -= 24\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "\n",
    "    for para in [\n",
    "        \"Task 1: GaussianNB baseline vs contenders (LogReg, KNN, DecisionTree).\",\n",
    "        \"Task 1B: Cosine neighbors + clustering (KMeans, Agglomerative).\",\n",
    "        \"Task 3: Refinement sweeps for KNN (k) and LogReg (C) on Top-3 features.\",\n",
    "    ]:\n",
    "        y = draw_text(c, para, margin, y, width - 2*margin, 14)\n",
    "\n",
    "    for img in [fig1, fig2, fig3]:\n",
    "        if os.path.exists(img):\n",
    "            ir = ImageReader(img)\n",
    "            iw, ih = ir.getSize()\n",
    "            max_w = width - 2*margin\n",
    "            scale = max_w / iw\n",
    "            draw_h = ih * scale\n",
    "            if y - draw_h < margin:\n",
    "                c.showPage(); y = height - margin; c.setFont(\"Helvetica\", 10)\n",
    "            c.drawImage(ir, margin, y - draw_h, width=max_w, height=draw_h)\n",
    "            y -= (draw_h + 12)\n",
    "\n",
    "    c.showPage()\n",
    "    c.save()\n",
    "    pdf_ok = True\n",
    "except Exception:\n",
    "    pdf_ok = False\n",
    "\n",
    "print(\"\\n=== Milestone 2 — Final Docs Done ===\")\n",
    "print(\"Final report (MD):\", final_md)\n",
    "print(\"PDF:\", pdf_path if pdf_ok else \"(skipped)\")\n",
    "print(\"Figures:\", [p for p in [fig1, fig2, fig3] if os.path.exists(p)])\n",
    "print(\"README updated:\", readme_updated)\n",
    "\n",
    "# Milestone progress flag\n",
    "print(\"\\nTASK FOUR completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfa0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added figure explanations to: c:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\Milestone2_Final_Report.md\n"
     ]
    }
   ],
   "source": [
    "# === Append figure explanations to Milestone2_Final_Report.md ===\n",
    "import os\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"Milestone2_Final_Report.md\")\n",
    "\n",
    "notes = \"\"\"\n",
    "## Figure Notes (What the plots mean)\n",
    "\n",
    "- **fig_task1_f1.png** — F1-scores for Task 1 models (Naive Bayes, Logistic Regression, KNN, Decision Tree) on both feature sets (“All 6” and “Top 3”).  \n",
    "  Higher F1 means a better balance of precision and recall for anomaly detection.\n",
    "\n",
    "- **fig_task1_prauc.png** — Precision–Recall AUC for the same Task 1 models.  \n",
    "  Values closer to 1.0 mean the model ranks anomalies much better than normal points.\n",
    "\n",
    "- **fig_task2_silhouette.png** — Silhouette scores over different cluster counts (k = 3–10) for service similarity.  \n",
    "  Taller bars indicate clearer, better-separated clusters; helps justify the best k.\n",
    "\"\"\"\n",
    "\n",
    "# Append if the section doesn't already exist\n",
    "need_write = True\n",
    "if os.path.exists(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read()\n",
    "    if \"## Figure Notes (What the plots mean)\" in txt:\n",
    "        need_write = False\n",
    "\n",
    "if need_write:\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\" + notes.strip() + \"\\n\")\n",
    "    print(\"✅ Added figure explanations to:\", path)\n",
    "else:\n",
    "    print(\"ℹ️ Figure notes already present — no changes made:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581eb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated README.md with Figures section.\n"
     ]
    }
   ],
   "source": [
    "# === Add a short \"Figures\" section to README.md (if missing) ===\n",
    "import os\n",
    "\n",
    "readme = os.path.join(os.getcwd(), \"README.md\")\n",
    "snippet = \"\"\"\n",
    "### Figures (Milestone 2)\n",
    "- `fig_task1_f1.png` — F1-scores: balance of precision & recall for Task 1 models.\n",
    "- `fig_task1_prauc.png` — PR-AUC: how well models rank anomalies vs normal.\n",
    "- `fig_task2_silhouette.png` — Silhouette by k: best cluster separation for services.\n",
    "\"\"\".strip()\n",
    "\n",
    "if os.path.exists(readme):\n",
    "    with open(readme, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read()\n",
    "    if \"### Figures (Milestone 2)\" not in txt:\n",
    "        with open(readme, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\\n\" + snippet + \"\\n\")\n",
    "        print(\"✅ Updated README.md with Figures section.\")\n",
    "    else:\n",
    "        print(\"ℹ️ README already has a Figures section — no changes made.\")\n",
    "else:\n",
    "    with open(readme, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Project README\\n\\n\" + snippet + \"\\n\")\n",
    "    print(\"✅ Created README.md with Figures section.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: C:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\milestone2_task5_bonus_investigation.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "task5_report = \"\"\"## Milestone 2 – Task 5: Bonus Task Investigation\n",
    "\n",
    "### Goal\n",
    "The goal of this task is to think about **ways to improve or extend** our current Trufflow anomaly detection and service similarity system.  \n",
    "We are not building new models — only exploring **ideas** that could make future versions smarter and faster.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Feature Ideas\n",
    "We can add more advanced or detailed features to help the model understand patterns better:\n",
    "- **Rolling Averages & Variance:** Track how each service’s performance changes over time (for example, sudden jumps in latency or request volume).\n",
    "- **Transaction Frequency Patterns:** Measure how often services communicate, which can show unusual spikes.\n",
    "- **Entropy or Diversity Scores:** Detect if a service suddenly starts interacting with new or unusual partners.\n",
    "- **Temporal Windows:** Create features that capture daily or weekly changes in behavior.\n",
    "\n",
    "**Why it helps:**  \n",
    "These features can catch *hidden or time-based anomalies* that current static averages may miss.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Model Improvements\n",
    "We can test stronger anomaly detection and clustering methods:\n",
    "- **Isolation Forest:** A model made just for anomaly detection that isolates rare points efficiently.  \n",
    "- **Autoencoder (Neural Network):** Learns to rebuild normal patterns; anything it can’t rebuild well is likely an anomaly.  \n",
    "- **LSTM (Time-Series Deep Learning):** Good for detecting changes over time — can track trends across days or weeks.  \n",
    "- **Graph Embeddings (Node2Vec / DeepWalk):** Learn similarity by looking at service-to-service connections, not just feature values.\n",
    "\n",
    "**Why it helps:**  \n",
    "These models understand *complex patterns* and *relationships* better than basic algorithms like Naive Bayes or KNN.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Service Relationship Insights\n",
    "We can go beyond pairwise similarity and look at *whole network structures*:\n",
    "- **Graph Analysis:** Represent all services as nodes connected by their interactions.  \n",
    "- **Centrality Measures:** Identify “key” or “risky” services that many others depend on.  \n",
    "- **Cluster Validation Metrics:** Use scores like *Davies–Bouldin Index* or *Calinski–Harabasz* to confirm if clusters are truly separate.\n",
    "\n",
    "**Why it helps:**  \n",
    "This would reveal *which services influence others most*, helping Trufflow detect not just isolated issues but also **chain reactions** across systems.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "For future work, we recommend:\n",
    "- Adding more **behavior-based features**\n",
    "- Trying **advanced models** like Isolation Forest or Autoencoders\n",
    "- Exploring **graph-based relationships** for deeper service mapping  \n",
    "\n",
    "These steps can make the Trufflow system more **accurate, flexible, and intelligent** for large-scale monitoring.\n",
    "\"\"\"\n",
    "\n",
    "path = Path(r\"C:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\milestone2_task5_bonus_investigation.md\")\n",
    "path.write_text(task5_report, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Saved:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7df44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: c:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\Project_Brief.md\n",
      "Included figures (existing):\n",
      " - c:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\fig_task1_f1.png\n",
      " - c:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\fig_task1_prauc.png\n",
      " - c:\\Users\\Owner\\Desktop\\Trufflow Projects Datasets\\fig_task2_silhouette.png\n"
     ]
    }
   ],
   "source": [
    "# Project Brief (Milestones 1 & 2) \n",
    "# - Creates: Project_Brief.md\n",
    "# - Embeds existing figures: fig_task1_f1.png, fig_task1_prauc.png, fig_task2_silhouette.png\n",
    "#   and (if present) milestone1 comparison plots (fig_m1_distribution.png, fig_m1_prauc.png, fig_m1_corr.png),\n",
    "#   and optional M1 vs M2 comparisons (fig_m1_m2_prauc.png, fig_m1_m2_f1.png).\n",
    "#\n",
    "# NOTE: Put this file in the same folder where your CSVs/plots live.\n",
    "\n",
    "import os, csv, json\n",
    "\n",
    "CWD = os.getcwd()\n",
    "\n",
    "# Known figure filenames (we will include only the ones that actually exist)\n",
    "FIGS = [\n",
    "    # Milestone 1 (optional; include if you have them)\n",
    "    \"fig_m1_distribution.png\",\n",
    "    \"fig_m1_prauc.png\",\n",
    "    \"fig_m1_corr.png\",\n",
    "    # Milestone 2 (created earlier)\n",
    "    \"fig_task1_f1.png\",\n",
    "    \"fig_task1_prauc.png\",\n",
    "    \"fig_task2_silhouette.png\",\n",
    "    # Optional comparison plots (include if you created them)\n",
    "    \"fig_m1_m2_prauc.png\",\n",
    "    \"fig_m1_m2_f1.png\",\n",
    "]\n",
    "\n",
    "def exists(p): \n",
    "    return os.path.exists(os.path.join(CWD, p))\n",
    "\n",
    "def bulleted_figs(title, fig_list):\n",
    "    lines = []\n",
    "    real = [f for f in fig_list if exists(f)]\n",
    "    if not real:\n",
    "        return \"\"\n",
    "    lines.append(f\"### {title}\\n\")\n",
    "    for f in real:\n",
    "        lines.append(f\"![{os.path.splitext(os.path.basename(f))[0]}]({f})\")\n",
    "    lines.append(\"\")  # blank line\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Try to read a few saved artifacts to enrich the brief (all optional)\n",
    "def read_conf_summary(path):\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def read_task1_table(path):\n",
    "    rows = []\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            rdr = csv.DictReader(f)\n",
    "            for r in rdr:\n",
    "                rows.append(r)\n",
    "    except:\n",
    "        pass\n",
    "    return rows\n",
    "\n",
    "conf = read_conf_summary(\"task1_confusion_summary.json\") or {}\n",
    "t1_rows = read_task1_table(\"task1_contender_results.csv\")\n",
    "\n",
    "# Convenience formatters\n",
    "def fmt(x, d=4):\n",
    "    try:\n",
    "        v = float(x)\n",
    "        return f\"{v:.{d}f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    except:\n",
    "        return str(x)\n",
    "\n",
    "def find_best(rows, feature_set):\n",
    "    # pick highest F1 in a given feature set\n",
    "    best = None\n",
    "    for r in rows:\n",
    "        if r.get(\"Feature_Set\") == feature_set:\n",
    "            if best is None or float(r.get(\"F1\", 0)) > float(best.get(\"F1\", 0)):\n",
    "                best = r\n",
    "    return best\n",
    "\n",
    "best_all6 = find_best(t1_rows, \"All 6\")\n",
    "best_top3 = find_best(t1_rows, \"Top 3\")\n",
    "\n",
    "# Fall back values if not found\n",
    "m2_best_model = (best_all6 or best_top3 or {})\n",
    "m2_best_name  = m2_best_model.get(\"Model\", \"KNN\")\n",
    "m2_best_f1    = fmt(m2_best_model.get(\"F1\", 0.9994))\n",
    "m2_best_prauc = fmt(m2_best_model.get(\"PR_AUC\", 0.9999))\n",
    "m2_best_acc   = fmt(m2_best_model.get(\"Accuracy\", 0.9999))\n",
    "\n",
    "# Milestone 1 headline (from your earlier narrative — adjust if you have exact M1 plots/metrics)\n",
    "m1_prauc = \"0.931\"\n",
    "m1_f1    = \"0.879\"\n",
    "m1_acc   = \"0.947\"\n",
    "\n",
    "# Milestone 2 baseline (3-feature GaussianNB) from saved confusion summary (if available)\n",
    "base_thr  = fmt(conf.get(\"threshold\", \"0.9694\"))\n",
    "base_pauc = fmt(conf.get(\"avg_precision\", \"0.9909\"))\n",
    "base_acc  = fmt(conf.get(\"accuracy\", \"0.9951\"))\n",
    "base_prec = fmt(conf.get(\"precision\", \"0.9754\"))\n",
    "base_rec  = fmt(conf.get(\"recall\", \"0.9672\"))\n",
    "base_f1   = fmt(conf.get(\"f1\", \"0.9713\"))\n",
    "TN = conf.get(\"TN\", \"—\"); FP = conf.get(\"FP\", \"—\"); FN = conf.get(\"FN\", \"—\"); TP = conf.get(\"TP\", \"—\")\n",
    "\n",
    "# Build Markdown\n",
    "lines = []\n",
    "lines.append(\"# 🧩 Trufflow Project Brief\")\n",
    "lines.append(\"**Milestones 1 & 2 Summary**  \\n*Team Trufflow 1B — AI Studio Fellowship Project*  \\nTools: **NumPy, scikit-learn, toolz, transformers** License: Apache 2.0\\n\")\n",
    "lines.append(\"## 🚀 Project Overview\")\n",
    "lines.append(\"The Trufflow project analyzes structured **app-to-app transaction data** to:\")\n",
    "lines.append(\"1. Detect and prioritize **anomalous behavior**;\")\n",
    "lines.append(\"2. Map **service similarity** for consolidation and investigation.\\n\")\n",
    "lines.append(\"Both milestones build the foundation for an intelligent anomaly-detection pipeline that can later be automated and scaled.\\n\")\n",
    "\n",
    "lines.append(\"## 🧠 Milestone 1 — Baseline Analysis & EDA\")\n",
    "lines.append(\"### Goal\")\n",
    "lines.append(\"Understand the dataset, identify key features, and train a **baseline** to detect anomalies.\\n\")\n",
    "lines.append(\"### Key Results (headline)\")\n",
    "lines.append(\"| Metric | Value |\")\n",
    "lines.append(\"|:--|:--:|\")\n",
    "lines.append(f\"| PR-AUC | {m1_prauc} |\")\n",
    "lines.append(f\"| F1-Score | {m1_f1} |\")\n",
    "lines.append(f\"| Accuracy | {m1_acc} |\\n\")\n",
    "m1_figs = bulleted_figs(\"Figures — Milestone 1 (if available)\", [\n",
    "    \"fig_m1_distribution.png\",\n",
    "    \"fig_m1_prauc.png\",\n",
    "    \"fig_m1_corr.png\",\n",
    "])\n",
    "if m1_figs:\n",
    "    lines.append(m1_figs)\n",
    "\n",
    "lines.append(\"## 🧩 Milestone 2 — Model Training, Comparison & Refinement\")\n",
    "lines.append(\"### Task 1 — Baseline vs Contenders (Anomaly Detection)\")\n",
    "lines.append(\"We trained **Naive Bayes, Logistic Regression, KNN, Decision Tree** on two feature sets (All 6, Top 3) and evaluated on a 20% time-based validation split.\\n\")\n",
    "lines.append(\"**Best contender:**\")\n",
    "lines.append(f\"- **Model:** {m2_best_name}  \\n- **PR-AUC:** {m2_best_prauc}  \\n- **F1:** {m2_best_f1}  \\n- **Accuracy:** {m2_best_acc}\\n\")\n",
    "t1_figs = bulleted_figs(\"Figures — Task 1 (saved)\", [\n",
    "    \"fig_task1_f1.png\",\n",
    "    \"fig_task1_prauc.png\",\n",
    "])\n",
    "if t1_figs:\n",
    "    lines.append(t1_figs)\n",
    "\n",
    "lines.append(\"### Baseline (3-feature GaussianNB) — Confusion & Metrics\")\n",
    "lines.append(\"| Metric | Value |\")\n",
    "lines.append(\"|:--|:--:|\")\n",
    "lines.append(f\"| Threshold | {base_thr} |\")\n",
    "lines.append(f\"| PR-AUC | {base_pauc} |\")\n",
    "lines.append(f\"| Accuracy | {base_acc} |\")\n",
    "lines.append(f\"| Precision | {base_prec} |\")\n",
    "lines.append(f\"| Recall | {base_rec} |\")\n",
    "lines.append(f\"| F1 | {base_f1} |\")\n",
    "lines.append(f\"| Confusion (valid) | **TN={TN}  FP={FP}  FN={FN}  TP={TP}** |\\n\")\n",
    "\n",
    "lines.append(\"### Task 1B — Service Similarity & Clustering\")\n",
    "lines.append(\"We built cosine-based service similarities (role vectors), PCA(3) neighbors, and ran KMeans/Agglomerative clustering. Best separation around **k=8** (Silhouette ≈ 0.98).\")\n",
    "t2_figs = bulleted_figs(\"Figure — Task 1B (saved)\", [\n",
    "    \"fig_task2_silhouette.png\",\n",
    "])\n",
    "if t2_figs:\n",
    "    lines.append(t2_figs)\n",
    "\n",
    "lines.append(\"### Task 3 — Feature Refinement\")\n",
    "lines.append(\"We tuned **KNN** (k ∈ {3..15}) and **LogReg** (C ∈ {0.1..10}) on the Top-3 features. KNN k=15 achieved F1≈0.9943 with stable high accuracy.\\n\")\n",
    "\n",
    "lines.append(\"### Task 4 — Docs & Visuals\")\n",
    "lines.append(\"Created **Milestone2_Final_Report.md**, updated **README.md**, and saved all figures so the workflow is easy to follow.\\n\")\n",
    "\n",
    "lines.append(\"### Task 5 — Bonus Investigation\")\n",
    "lines.append(\"Planned next steps: temporal features (rolling windows), Isolation Forest / Autoencoder for unsupervised anomalies, and graph embeddings for service-network effects.\\n\")\n",
    "\n",
    "lines.append(\"## 📊 Milestone 1 vs Milestone 2 — Side-by-Side\")\n",
    "lines.append(\"| Metric | Milestone 1 (Baseline) | Milestone 2 (Best) |\")\n",
    "lines.append(\"|:--|--:|--:|\")\n",
    "lines.append(f\"| PR-AUC | {m1_prauc} | {m2_best_prauc} |\")\n",
    "lines.append(f\"| F1 | {m1_f1} | {m2_best_f1} |\")\n",
    "lines.append(f\"| Accuracy | {m1_acc} | {m2_best_acc} |\\n\")\n",
    "m12_figs = bulleted_figs(\"Comparison Plots (if created)\", [\n",
    "    \"fig_m1_m2_prauc.png\",\n",
    "    \"fig_m1_m2_f1.png\",\n",
    "])\n",
    "if m12_figs:\n",
    "    lines.append(m12_figs)\n",
    "\n",
    "lines.append(\"## 🎯 Final Takeaway\")\n",
    "lines.append(\"- **KNN** emerged as the strongest model with near-perfect precision and recall.\")\n",
    "lines.append(\"- Clustering produced clear service groups to monitor.\")\n",
    "lines.append(\"- Documentation and visuals make the solution easy to explain and extend.\")\n",
    "lines.append(\"- Next: add temporal + graph features and evaluate unsupervised anomaly models.\\n\")\n",
    "\n",
    "out_path = os.path.join(CWD, \"Project_Brief.md\")\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(f\"✅ Saved: {out_path}\")\n",
    "print(\"Included figures (existing):\")\n",
    "for f in FIGS:\n",
    "    if exists(f):\n",
    "        print(\" -\", os.path.join(CWD, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83a909ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1_contender_results.csv headers: ['Model', 'Feature_Set', 'PR_AUC', 'Precision', 'Recall', 'F1', 'Accuracy', 'Best_Threshold', 'Valid_Size', 'Pos_Rate_Valid']\n",
      "Saved: milestone2_key_results.md\n"
     ]
    }
   ],
   "source": [
    "# A) Consistent rounding + Key Results \n",
    "import csv, os\n",
    "\n",
    "def fmt3(x):\n",
    "    try:\n",
    "        return f\"{float(x):.3f}\"\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "# ---------- Load Task 1 contender results ----------\n",
    "task1 = []\n",
    "with open(\"task1_contender_results.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    rdr = csv.DictReader(f)\n",
    "    print(\"task1_contender_results.csv headers:\", rdr.fieldnames)\n",
    "    for r in rdr:\n",
    "        # Normalize feature set values a bit\n",
    "        fs = (r.get(\"Feature_Set\",\"\") or \"\").strip()\n",
    "        if fs.lower().replace(\" \", \"\") in (\"top3\",\"top-3\"):\n",
    "            fs_norm = \"Top-3\"\n",
    "        elif fs.lower().replace(\" \", \"\") in (\"all6\",\"allsix\",\"all-6\"):\n",
    "            fs_norm = \"All 6\"\n",
    "        else:\n",
    "            fs_norm = fs or \"Unknown\"\n",
    "        row = {\n",
    "            \"Model\": r.get(\"Model\",\"\"),\n",
    "            \"Feature_Set\": fs_norm,\n",
    "            \"PR_AUC\": float(r.get(\"PR_AUC\",\"nan\")),\n",
    "            \"F1\": float(r.get(\"F1\",\"nan\")),\n",
    "            \"Accuracy\": float(r.get(\"Accuracy\",\"nan\")),\n",
    "        }\n",
    "        task1.append(row)\n",
    "\n",
    "# best overall by F1\n",
    "best = max([x for x in task1 if x[\"F1\"] == x[\"F1\"]], key=lambda x: x[\"F1\"])\n",
    "\n",
    "def agg_by_feat(fs):\n",
    "    rows = [r for r in task1 if r[\"Feature_Set\"] == fs and r[\"F1\"] == r[\"F1\"]]\n",
    "    if not rows:\n",
    "        return {\"PR_AUC\":\"-\", \"F1\":\"-\", \"Accuracy\":\"-\"}\n",
    "    pr = sum(r[\"PR_AUC\"] for r in rows)/len(rows)\n",
    "    f1 = sum(r[\"F1\"] for r in rows)/len(rows)\n",
    "    ac = sum(r[\"Accuracy\"] for r in rows)/len(rows)\n",
    "    return {\"PR_AUC\": fmt3(pr), \"F1\": fmt3(f1), \"Accuracy\": fmt3(ac)}\n",
    "\n",
    "avg_all6 = agg_by_feat(\"All 6\")\n",
    "avg_top3 = agg_by_feat(\"Top-3\")\n",
    "\n",
    "# ---------- Load clustering sweep (optional but expected) ----------\n",
    "bestk = None\n",
    "if os.path.exists(\"task2_clustering_results.csv\"):\n",
    "    with open(\"task2_clustering_results.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        rdr = csv.DictReader(f)\n",
    "        for r in rdr:\n",
    "            try:\n",
    "                sil = float(r.get(\"Silhouette\",\"nan\"))\n",
    "            except:\n",
    "                sil = float(\"nan\")\n",
    "            if bestk is None or (sil == sil and sil > float(bestk.get(\"Silhouette\",\"-inf\"))):\n",
    "                bestk = {\"k\": r.get(\"k\",\"?\"), \"Silhouette\": sil}\n",
    "\n",
    "# ---------- Load Task 3 sweep (optional) ----------\n",
    "best_sw = None\n",
    "if os.path.exists(\"task3_feature_refinement_results.csv\"):\n",
    "    with open(\"task3_feature_refinement_results.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        rdr = csv.DictReader(f)\n",
    "        for r in rdr:\n",
    "            try:\n",
    "                f1 = float(r.get(\"F1\",\"nan\"))\n",
    "            except:\n",
    "                f1 = float(\"nan\")\n",
    "            if best_sw is None or (f1 == f1 and f1 > float(best_sw.get(\"F1\",\"-inf\"))):\n",
    "                best_sw = {\n",
    "                    \"PR_AUC\": r.get(\"PR_AUC\",\"-\"),\n",
    "                    \"F1\": r.get(\"F1\",\"-\"),\n",
    "                    \"Accuracy\": r.get(\"Accuracy\",\"-\"),\n",
    "                    \"Model\": r.get(\"Model\",\"\"),\n",
    "                    \"Notes\": r.get(\"Notes\",\"\")\n",
    "                }\n",
    "\n",
    "# ---------- Write Key Results (3 d.p.) ----------\n",
    "lines = []\n",
    "lines += [\"# Key Results (Milestone 2)\", \"\"]\n",
    "lines += [\"| Area | Highlight | Metric(s) | Value |\", \"|:--|:--|:--|:--|\"]\n",
    "lines += [f\"| Task 1 | Best model (by F1) | PR-AUC / F1 / Acc | {fmt3(best['PR_AUC'])} / {fmt3(best['F1'])} / {fmt3(best['Accuracy'])} |\"]\n",
    "\n",
    "if best_sw:\n",
    "    lines += [f\"| Task 3 | Best sweep result | PR-AUC / F1 / Acc | {fmt3(best_sw['PR_AUC'])} / {fmt3(best_sw['F1'])} / {fmt3(best_sw['Accuracy'])} |\"]\n",
    "\n",
    "if bestk and bestk['Silhouette'] == bestk['Silhouette']:\n",
    "    lines += [f\"| Task 2 | Best clustering | k / Silhouette | {bestk['k']} / {fmt3(bestk['Silhouette'])} |\"]\n",
    "\n",
    "lines += [f\"| Feature sets | Avg (All-6) | PR-AUC / F1 / Acc | {avg_all6['PR_AUC']} / {avg_all6['F1']} / {avg_all6['Accuracy']} |\"]\n",
    "lines += [f\"| Feature sets | Avg (Top-3) | PR-AUC / F1 / Acc | {avg_top3['PR_AUC']} / {avg_top3['F1']} / {avg_top3['Accuracy']} |\"]\n",
    "\n",
    "with open(\"milestone2_key_results.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Saved: milestone2_key_results.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5cbdfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-saved: milestone2_key_results.md\n"
     ]
    }
   ],
   "source": [
    "# Compute MAX per feature set (by F1) and grab its PR_AUC/F1/Acc\n",
    "def max_by_feat(fs):\n",
    "    rows = [r for r in task1 if r[\"Feature_Set\"] == fs and r[\"F1\"] == r[\"F1\"]]\n",
    "    if not rows: \n",
    "        return {\"PR_AUC\":\"-\", \"F1\":\"-\", \"Accuracy\":\"-\"}\n",
    "    best_r = max(rows, key=lambda r: r[\"F1\"])\n",
    "    return {\"PR_AUC\": fmt3(best_r[\"PR_AUC\"]), \"F1\": fmt3(best_r[\"F1\"]), \"Accuracy\": fmt3(best_r[\"Accuracy\"])}\n",
    "\n",
    "max_all6 = max_by_feat(\"All 6\")\n",
    "max_top3 = max_by_feat(\"Top-3\")\n",
    "\n",
    "# Helpful label for the best model row\n",
    "best_label = f\"{best['Model']} ({best['Feature_Set']})\" if best.get(\"Model\") else f\"Best ({best['Feature_Set']})\"\n",
    "\n",
    "# Rebuild the markdown block with the new rows\n",
    "lines = []\n",
    "lines += [\"# Key Results (Milestone 2)\", \"\"]\n",
    "lines += [\"| Area | Highlight | Metric(s) | Value |\", \"|:--|:--|:--|:--|\"]\n",
    "\n",
    "# Task 2 early is OK per reviewer (silhouette earlier)\n",
    "if bestk and bestk['Silhouette'] == bestk['Silhouette']:\n",
    "    lines += [f\"| Task 2 | Best clustering | k / Silhouette | {bestk['k']} / {fmt3(bestk['Silhouette'])} |\"]\n",
    "\n",
    "lines += [f\"| Task 1 | Best model (by F1) | {best_label} — PR-AUC / F1 / Acc | {fmt3(best['PR_AUC'])} / {fmt3(best['F1'])} / {fmt3(best['Accuracy'])} |\"]\n",
    "\n",
    "if best_sw:\n",
    "    lines += [f\"| Task 3 | Best sweep result | PR-AUC / F1 / Acc | {fmt3(best_sw['PR_AUC'])} / {fmt3(best_sw['F1'])} / {fmt3(best_sw['Accuracy'])} |\"]\n",
    "\n",
    "# Feature-set summaries (Avg + Max)\n",
    "lines += [f\"| Feature sets | Avg (All-6) | PR-AUC / F1 / Acc | {avg_all6['PR_AUC']} / {avg_all6['F1']} / {avg_all6['Accuracy']} |\"]\n",
    "lines += [f\"| Feature sets | Max (All-6) | PR-AUC / F1 / Acc | {max_all6['PR_AUC']} / {max_all6['F1']} / {max_all6['Accuracy']} |\"]\n",
    "lines += [f\"| Feature sets | Avg (Top-3) | PR-AUC / F1 / Acc | {avg_top3['PR_AUC']} / {avg_top3['F1']} / {avg_top3['Accuracy']} |\"]\n",
    "lines += [f\"| Feature sets | Max (Top-3) | PR-AUC / F1 / Acc | {max_top3['PR_AUC']} / {max_top3['F1']} / {max_top3['Accuracy']} |\"]\n",
    "\n",
    "with open(\"milestone2_key_results.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Re-saved: milestone2_key_results.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bd6520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task1_runtime_summary.csv\n",
      "['Naive Bayes', '3.613', '0.750']\n",
      "['Logistic Regression', '7.958', '0.174']\n",
      "['KNN (k=7)', '24.822', '159.717']\n"
     ]
    }
   ],
   "source": [
    "# Measure fit and predict time for Naive Bayes, Logistic Regression, and KNN\n",
    "import time, csv\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# === Reuse your existing train/validation split ===\n",
    "# (same Xtr, ytr, Xva, yva you used in Milestone 2 Task 1)\n",
    "# If they aren't still in memory, reload or rebuild them exactly as before.\n",
    "\n",
    "def time_model(model, name):\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", model)])\n",
    "    t0 = time.time()\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    fit_t = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    _ = pipe.predict(Xva)\n",
    "    pred_t = time.time() - t1\n",
    "\n",
    "    return [name, f\"{fit_t:.3f}\", f\"{pred_t:.3f}\"]\n",
    "\n",
    "results = [\n",
    "    time_model(GaussianNB(), \"Naive Bayes\"),\n",
    "    time_model(LogisticRegression(max_iter=1000), \"Logistic Regression\"),\n",
    "    time_model(KNeighborsClassifier(n_neighbors=7), \"KNN (k=7)\")\n",
    "]\n",
    "\n",
    "with open(\"task1_runtime_summary.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Model\", \"Fit Time (s)\", \"Predict Time (s)\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"Saved: task1_runtime_summary.csv\")\n",
    "for r in results:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf5f8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: feature_correlation.md\n"
     ]
    }
   ],
   "source": [
    "# Correlation matrix (uses the same X we built for Task 1)\n",
    "import numpy as np\n",
    "\n",
    "# X: (n,6) matrix in the order\n",
    "feat_names = [\"req_count\",\"error_rate\",\"cost_sum\",\"cost_mean\",\"data_sum\",\"data_mean\"]\n",
    "\n",
    "Xc = X - X.mean(axis=0)\n",
    "std = X.std(axis=0) + 1e-12\n",
    "Xz = Xc / std\n",
    "corr = (Xz.T @ Xz) / (Xz.shape[0]-1)\n",
    "\n",
    "with open(\"feature_correlation.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"## Feature Correlation (Pearson)\\n\\n\")\n",
    "    f.write(\"| | \" + \" | \".join(feat_names) + \" |\\n\")\n",
    "    f.write(\"|\" + \":-:|\"*(len(feat_names)+1) + \"\\n\")\n",
    "    for i, name in enumerate(feat_names):\n",
    "        f.write(\"| \" + name + \" | \" + \" | \".join(f\"{v:.3f}\" for v in corr[i]) + \" |\\n\")\n",
    "print(\"Saved: feature_correlation.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2759b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: feature_effect_sizes.md\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LogisticRegression(max_iter=1000))])\n",
    "pipe.fit(Xtr, ytr)\n",
    "coefs = pipe.named_steps[\"lr\"].coef_[0]\n",
    "\n",
    "with open(\"feature_effect_sizes.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"## Linear Model Coefficients (Scaled Features)\\n\\n\")\n",
    "    f.write(\"| Feature | Coefficient |\\n|:--|--:|\\n\")\n",
    "    for n, c in zip([\"req_count\",\"error_rate\",\"cost_sum\",\"cost_mean\",\"data_sum\",\"data_mean\"], coefs):\n",
    "        f.write(f\"| {n} | {c:.3f} |\\n\")\n",
    "print(\"Saved: feature_effect_sizes.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9973dc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: task2_cluster_profiles.md\n"
     ]
    }
   ],
   "source": [
    "# Build mean profiles of the six metrics per cluster (k=8)\n",
    "# Assumes you have either per-window labels or per-service labels saved.\n",
    "# This tries both common schemas from `task2_clustering_results.csv`.\n",
    "\n",
    "import csv, numpy as np\n",
    "\n",
    "FEATS = [\"req_count\",\"error_rate\",\"cost_sum\",\"cost_mean\",\"data_sum\",\"data_mean\"]\n",
    "\n",
    "# 1) Load cluster assignments\n",
    "labels_per_key = {}  # key -> cluster label\n",
    "hdr = []\n",
    "with open(\"task2_clustering_results.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    rdr = csv.DictReader(f)\n",
    "    hdr = [h.lower() for h in (rdr.fieldnames or [])]\n",
    "    for row in rdr:\n",
    "        r = { (k or \"\").lower(): (v or \"\") for k,v in row.items() }\n",
    "        # Try common column names\n",
    "        lab = r.get(\"label\") or r.get(\"cluster\") or r.get(\"kmeans_label\") or \"\"\n",
    "        k   = r.get(\"k\") or \"8\"\n",
    "        # Only keep k==8 rows if sweep saved multiple ks\n",
    "        if str(k).strip() != \"8\": \n",
    "            continue\n",
    "        # Key could be a composite id; try these fields:\n",
    "        key = r.get(\"key\") or r.get(\"service\") or r.get(\"id\") or r.get(\"name\")\n",
    "        if key:\n",
    "            try:\n",
    "                labels_per_key[key] = int(float(lab))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "# 2) Map your X rows to the same key used in labels\n",
    "# In your M2 build, you had `keys` aligned to X rows: keys[i] = (consumer, supplier, hour)\n",
    "# If your labels are per-service, derive a service id from keys[i][0] or keys[i][1].\n",
    "def key_for_row(i):\n",
    "    # prefer service name/id used in your clustering (likely consumer/supplier app id)\n",
    "    cons, supp, _ = keys[i]\n",
    "    # If clustering keyed by service, pick consumer (or adapt to your clustering choice):\n",
    "    return cons\n",
    "\n",
    "# 3) Aggregate per-cluster means\n",
    "K = 8\n",
    "accum = [np.zeros(6, dtype=float) for _ in range(K)]\n",
    "count = [0 for _ in range(K)]\n",
    "\n",
    "for i in range(len(X)):\n",
    "    svc = key_for_row(i)\n",
    "    lab = labels_per_key.get(svc, None)\n",
    "    if lab is None or not (0 <= lab < K): \n",
    "        continue\n",
    "    accum[lab] += X[i]\n",
    "    count[lab] += 1\n",
    "\n",
    "means = []\n",
    "for k in range(K):\n",
    "    if count[k] == 0:\n",
    "        means.append([k] + [\"-\"]*6)\n",
    "    else:\n",
    "        m = accum[k] / count[k]\n",
    "        means.append([k] + [f\"{v:.3f}\" for v in m.tolist()])\n",
    "\n",
    "with open(\"task2_cluster_profiles.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"## Cluster Profiles (k=8)\\n\\n\")\n",
    "    f.write(\"| Cluster | \" + \" | \".join(FEATS) + \" |\\n\")\n",
    "    f.write(\"|:--|--:|--:|--:|--:|--:|--:|\\n\")\n",
    "    for row in means:\n",
    "        f.write(\"| \" + \" | \".join(map(str,row)) + \" |\\n\")\n",
    "print(\"Saved: task2_cluster_profiles.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bec3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potential feature CSVs:\n",
      "\n",
      "[1] .\\task1_scores_valid.csv\n",
      "  Header: ['time_bucket', 'consumer_id', 'supplier_id', 'probability', 'predicted_anomaly', 'label_debiased', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean', 'impact_score']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    time_bucket,consumer_id,supplier_id,probability,predicted_anomaly,label_debiased,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean,impact_score\n",
      "    2025-04-11 17:00:00,SELENE,DBRCKS,1.0,1,1,119.0,0.0,4809.85,40.418907563025215,139.19999999999993,1.1697478991596633,4809.850000001001\n",
      "    2025-04-14 04:00:00,SELENE,DBRCKS,1.0,1,1,113.0,0.0,4797.4,42.454867256637165,131.39999999999992,1.162831858407079,4797.400000001\n",
      "    2025-05-26 05:00:00,SELENE,DBRCKS,1.0,1,1,109.0,0.0,4614.8,42.33761467889909,128.54999999999998,1.1793577981651375,4614.800000001001\n",
      "    2025-05-08 11:00:00,SELENE,DBRCKS,1.0,1,1,110.0,0.0,4614.799999999999,41.952727272727266,136.80000000000004,1.243636363636364,4614.800000001\n",
      "\n",
      "[2] .\\task1_top_incidents.csv\n",
      "  Header: ['time_bucket', 'consumer_id', 'supplier_id', 'probability', 'predicted_anomaly', 'weak_label', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    time_bucket,consumer_id,supplier_id,probability,predicted_anomaly,weak_label,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean\n",
      "    2025-05-12 02:00:00,ECOMLP,MCSCBT,1.0,1,1,6.0,0.0,3539.9500000000007,589.9916666666668,70.8,11.799999999999999\n",
      "    2025-03-30 01:00:00,CUSTPRT,MCSCBT,1.0,1,1,6.0,0.0,3465.25,577.5416666666666,73.05000000000001,12.175000000000002\n",
      "    2025-03-25 05:00:00,ECOMLP,MCSCBT,1.0,1,1,5.0,0.0,2921.6,584.3199999999999,59.25,11.85\n",
      "    2025-04-08 18:00:00,CUSTPRT,MCSCBT,1.0,1,1,5.0,0.0,2888.3999999999996,577.68,61.5,12.3\n",
      "\n",
      "[3] .\\task1_top_incidents_final.csv\n",
      "  Header: ['time_bucket', 'consumer_id', 'supplier_id', 'probability', 'predicted_anomaly', 'label_debiased', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean', 'impact_score']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    time_bucket,consumer_id,supplier_id,probability,predicted_anomaly,label_debiased,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean,impact_score\n",
      "    2025-04-11 17:00:00,SELENE,DBRCKS,1.0,1,1,119.0,0.0,4809.85,40.418907563025215,139.19999999999993,1.1697478991596633,4809.850000001001\n",
      "    2025-04-14 04:00:00,SELENE,DBRCKS,1.0,1,1,113.0,0.0,4797.4,42.454867256637165,131.39999999999992,1.162831858407079,4797.400000001\n",
      "    2025-05-26 05:00:00,SELENE,DBRCKS,1.0,1,1,109.0,0.0,4614.8,42.33761467889909,128.54999999999998,1.1793577981651375,4614.800000001001\n",
      "    2025-05-08 11:00:00,SELENE,DBRCKS,1.0,1,1,110.0,0.0,4614.799999999999,41.952727272727266,136.80000000000004,1.243636363636364,4614.800000001\n",
      "\n",
      "[4] .\\results\\milestone1\\features_selection\\tables\\features_snapshot_first10.csv\n",
      "  Header: ['consumer_id', 'supplier_id', 'time_bucket', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    consumer_id,supplier_id,time_bucket,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean\n",
      "    SELENE,AWS,2024-06-01 00:00:00,71,0,\"1,630.95\",22.971127,25.65,0.361268\n",
      "    SELENE,DBRCKS,2024-06-01 00:00:00,71,0,\"3,083.45\",43.428873,85.5,1.204225\n",
      "    SELENE,SNWFLK,2024-06-01 00:00:00,71,0,\"1,618.5\",22.795775,65.4,0.921127\n",
      "    FRDETCT,SELENE,2024-06-01 00:00:00,1,0,116.2,116.2,1.65,1.65\n",
      "\n",
      "[5] .\\results\\milestone1\\features_selection\\tables\\feature_feature_correlation.csv\n",
      "  Header: ['', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    ,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean\n",
      "    req_count,1,nan,0.838927,-0.143074,0.726114,-0.119494\n",
      "    error_rate,nan,nan,nan,nan,nan,nan\n",
      "    cost_sum,0.838927,nan,1,0.2272,0.905623,0.234044\n",
      "    cost_mean,-0.143074,nan,0.2272,1,0.186732,0.91154\n",
      "\n",
      "[6] .\\results\\milestone1\\tables\\task1_scores_valid.csv\n",
      "  Header: ['time_bucket', 'consumer_id', 'supplier_id', 'probability', 'predicted_anomaly', 'label_debiased', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean', 'impact_score']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    time_bucket,consumer_id,supplier_id,probability,predicted_anomaly,label_debiased,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean,impact_score\n",
      "    2025-04-11 17:00:00,SELENE,DBRCKS,1.0,1,1,119.0,0.0,4809.85,40.418907563025215,139.19999999999993,1.1697478991596633,4809.850000001001\n",
      "    2025-04-14 04:00:00,SELENE,DBRCKS,1.0,1,1,113.0,0.0,4797.4,42.454867256637165,131.39999999999992,1.162831858407079,4797.400000001\n",
      "    2025-05-26 05:00:00,SELENE,DBRCKS,1.0,1,1,109.0,0.0,4614.8,42.33761467889909,128.54999999999998,1.1793577981651375,4614.800000001001\n",
      "    2025-05-08 11:00:00,SELENE,DBRCKS,1.0,1,1,110.0,0.0,4614.799999999999,41.952727272727266,136.80000000000004,1.243636363636364,4614.800000001\n",
      "\n",
      "[7] .\\results\\milestone1\\tables\\task1_top_incidents.csv\n",
      "  Header: ['time_bucket', 'consumer_id', 'supplier_id', 'probability', 'predicted_anomaly', 'weak_label', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    time_bucket,consumer_id,supplier_id,probability,predicted_anomaly,weak_label,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean\n",
      "    2025-05-12 02:00:00,ECOMLP,MCSCBT,1.0,1,1,6.0,0.0,3539.9500000000007,589.9916666666668,70.8,11.799999999999999\n",
      "    2025-03-30 01:00:00,CUSTPRT,MCSCBT,1.0,1,1,6.0,0.0,3465.25,577.5416666666666,73.05000000000001,12.175000000000002\n",
      "    2025-03-25 05:00:00,ECOMLP,MCSCBT,1.0,1,1,5.0,0.0,2921.6,584.3199999999999,59.25,11.85\n",
      "    2025-04-08 18:00:00,CUSTPRT,MCSCBT,1.0,1,1,5.0,0.0,2888.3999999999996,577.68,61.5,12.3\n",
      "\n",
      "[8] .\\results\\milestone1\\tables\\task1_top_incidents_final.csv\n",
      "  Header: ['time_bucket', 'consumer_id', 'supplier_id', 'probability', 'predicted_anomaly', 'label_debiased', 'req_count', 'error_rate', 'cost_sum', 'cost_mean', 'data_sum', 'data_mean', 'impact_score']\n",
      "  Matched columns: {'req_count': 'req_count', 'error_rate': 'error_rate', 'cost_sum': 'cost_sum', 'cost_mean': 'cost_mean', 'data_sum': 'data_sum', 'data_mean': 'data_mean'}\n",
      "  Preview:\n",
      "    time_bucket,consumer_id,supplier_id,probability,predicted_anomaly,label_debiased,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean,impact_score\n",
      "    2025-04-11 17:00:00,SELENE,DBRCKS,1.0,1,1,119.0,0.0,4809.85,40.418907563025215,139.19999999999993,1.1697478991596633,4809.850000001001\n",
      "    2025-04-14 04:00:00,SELENE,DBRCKS,1.0,1,1,113.0,0.0,4797.4,42.454867256637165,131.39999999999992,1.162831858407079,4797.400000001\n",
      "    2025-05-26 05:00:00,SELENE,DBRCKS,1.0,1,1,109.0,0.0,4614.8,42.33761467889909,128.54999999999998,1.1793577981651375,4614.800000001001\n",
      "    2025-05-08 11:00:00,SELENE,DBRCKS,1.0,1,1,110.0,0.0,4614.799999999999,41.952727272727266,136.80000000000004,1.243636363636364,4614.800000001\n",
      "\n",
      "Pick the best match above and use its path as FEATURE_CSV in the previous clustering cell.\n"
     ]
    }
   ],
   "source": [
    "# Finder for the feature CSV containing:\n",
    "# req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean\n",
    "# Allowed libs only: numpy, toolz (not required), scikit-learn unused here.\n",
    "\n",
    "import os, csv, io\n",
    "\n",
    "SEARCH_DIRS = [\"artifacts\", \"data\", \".\"]\n",
    "REQUIRED = [\"req_count\",\"error_rate\",\"cost_sum\",\"cost_mean\",\"data_sum\",\"data_mean\"]\n",
    "ALIASES = {\n",
    "    \"req_count\": {\"req_count\",\"request_count\",\"requests\",\"n_requests\"},\n",
    "    \"error_rate\": {\"error_rate\",\"err_rate\",\"errors_rate\",\"fail_rate\"},\n",
    "    \"cost_sum\": {\"cost_sum\",\"total_cost\",\"cost_total\",\"sum_cost\"},\n",
    "    \"cost_mean\": {\"cost_mean\",\"avg_cost\",\"mean_cost\",\"cost_per_request\"},\n",
    "    \"data_sum\": {\"data_sum\",\"total_data\",\"bytes_total\",\"sum_data\"},\n",
    "    \"data_mean\": {\"data_mean\",\"avg_data\",\"mean_data\",\"data_per_request\",\"bytes_per_request\"},\n",
    "}\n",
    "\n",
    "def normalize(name: str) -> str:\n",
    "    return name.strip().lower().replace(\" \", \"\").replace(\"-\", \"_\")\n",
    "\n",
    "def header_matches(header):\n",
    "    header_norm = [normalize(h) for h in header]\n",
    "    found = {}\n",
    "    for key, aliases in ALIASES.items():\n",
    "        for h in header_norm:\n",
    "            if h in aliases:\n",
    "                found[key] = h\n",
    "                break\n",
    "    ok = all(k in found for k in ALIASES.keys())\n",
    "    return ok, found, header_norm\n",
    "\n",
    "def try_read_header(path):\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            first = f.readline()\n",
    "            # crude check for CSV header\n",
    "            if \",\" not in first: \n",
    "                return None\n",
    "            header = [h.strip() for h in first.strip().split(\",\")]\n",
    "            return header\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def preview(path, n=3):\n",
    "    out = []\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for i, line in enumerate(f):\n",
    "                out.append(line.rstrip(\"\\n\"))\n",
    "                if i >= n: break\n",
    "    except Exception as e:\n",
    "        out = [f\"(error reading preview: {e})\"]\n",
    "    return out\n",
    "\n",
    "candidates = []\n",
    "for root in SEARCH_DIRS:\n",
    "    if not os.path.exists(root): \n",
    "        continue\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        for name in filenames:\n",
    "            if not name.lower().endswith(\".csv\"): \n",
    "                continue\n",
    "            path = os.path.join(dirpath, name)\n",
    "            header = try_read_header(path)\n",
    "            if not header:\n",
    "                continue\n",
    "            ok, found, header_norm = header_matches(header)\n",
    "            if ok:\n",
    "                candidates.append((path, header, found))\n",
    "\n",
    "if not candidates:\n",
    "    print(\"No CSV with matching headers found in:\", \", \".join(d for d in SEARCH_DIRS if os.path.exists(d)))\n",
    "    print(\"Tips:\")\n",
    "    print(\" - Export the role/metric matrix you used for Task 2 as a CSV with headers:\")\n",
    "    print(\"   req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean\")\n",
    "    print(\" - Or tell me the correct path so I can plug it into the clustering cell.\")\n",
    "else:\n",
    "    print(\"Found potential feature CSVs:\")\n",
    "    for i,(path, header, found) in enumerate(candidates, start=1):\n",
    "        print(f\"\\n[{i}] {path}\")\n",
    "        print(\"  Header:\", header)\n",
    "        print(\"  Matched columns:\", found)\n",
    "        print(\"  Preview:\")\n",
    "        for line in preview(path, n=4):\n",
    "            print(\"   \", line)\n",
    "    print(\"\\nPick the best match above and use its path as FEATURE_CSV in the previous clustering cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a3d5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading up to 10000 rows from .\\task1_scores_valid.csv ...\n",
      "Loaded shape: (10000, 6)\n",
      "\n",
      "✓ Wrote:\n",
      "  artifacts/task2_cluster_profiles.csv\n",
      "  artifacts/task2_silhouette_scores.csv\n",
      "\n",
      "Preview: task2_cluster_profiles.csv\n",
      "cluster,req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean\n",
      "0,57.497,0.000,1460.053,37.681,35.487,0.914\n",
      "1,69.528,0.000,2916.337,47.501,83.779,1.320\n",
      "2,73.414,0.000,1800.673,30.260,46.983,0.783\n",
      "3,2.028,0.000,1130.935,560.899,23.613,11.743\n",
      "4,68.764,0.000,2322.582,51.568,65.783,1.324\n",
      "5,86.927,0.000,3646.156,44.701,104.859,1.260\n",
      "6,36.571,0.000,1167.161,56.764,24.211,1.266\n",
      "7,3.144,0.000,1754.946,559.097,37.282,11.870\n",
      "\n",
      "Preview: task2_silhouette_scores.csv\n",
      "k,silhouette\n",
      "3,0.506\n",
      "4,0.472\n",
      "5,0.540\n",
      "6,0.527\n",
      "7,0.556\n",
      "8,0.534\n",
      "9,0.523\n",
      "10,0.518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Purpose: Quickly compute service cluster profiles and silhouette scores using a manageable subset (10k rows)\n",
    "\n",
    "import os, csv\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# === CONFIG (already correct for your data) ===\n",
    "FEATURE_CSV = r\".\\task1_scores_valid.csv\"          # your file\n",
    "COLS = [6, 7, 8, 9, 10, 11]                        # req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean\n",
    "K = 8                                               # target cluster count\n",
    "OUT_PROFILES = \"artifacts/task2_cluster_profiles.csv\"\n",
    "OUT_SIL = \"artifacts/task2_silhouette_scores.csv\"\n",
    "SAMPLE_SIZE = 10000                                 # limit rows for faster run\n",
    "# ==============================================\n",
    "\n",
    "def ensure_dir(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if d and not os.path.exists(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def load_csv_nd(path, cols, skip_header=True, limit=None):\n",
    "    \"\"\"Load selected columns as float ndarray (no pandas).\"\"\"\n",
    "    arr = np.genfromtxt(path, delimiter=\",\", dtype=float, skip_header=1 if skip_header else 0)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(1, -1)\n",
    "    arr = arr[:, cols]\n",
    "    if limit and arr.shape[0] > limit:\n",
    "        arr = arr[:limit]\n",
    "    return arr\n",
    "\n",
    "def save_csv(path, header, rows):\n",
    "    ensure_dir(path)\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(header)\n",
    "        w.writerows(rows)\n",
    "\n",
    "def preview(path, n=8):\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            for i, line in enumerate(f):\n",
    "                print(line.strip())\n",
    "                if i >= n:\n",
    "                    break\n",
    "    except FileNotFoundError:\n",
    "        print(f\"(missing) {path}\")\n",
    "\n",
    "# ---- Load a manageable subset of features ----\n",
    "print(f\"Loading up to {SAMPLE_SIZE} rows from {FEATURE_CSV} ...\")\n",
    "X = load_csv_nd(FEATURE_CSV, COLS, skip_header=True, limit=SAMPLE_SIZE)\n",
    "print(f\"Loaded shape: {X.shape}\")\n",
    "\n",
    "# ---- Fit KMeans (k=8) ----\n",
    "km = KMeans(n_clusters=K, n_init=10, random_state=42)\n",
    "labels = km.fit_predict(X)\n",
    "\n",
    "# ---- Per-cluster mean profiles ----\n",
    "profiles = []\n",
    "for c in range(K):\n",
    "    mask = (labels == c)\n",
    "    if np.any(mask):\n",
    "        means = np.mean(X[mask], axis=0)\n",
    "        profiles.append([c] + [f\"{float(m):.3f}\" for m in means])\n",
    "\n",
    "header = [\"cluster\", \"req_count\", \"error_rate\", \"cost_sum\", \"cost_mean\", \"data_sum\", \"data_mean\"]\n",
    "save_csv(OUT_PROFILES, header, profiles)\n",
    "\n",
    "# ---- Silhouette scores for k=3..10 ----\n",
    "sil_rows = []\n",
    "for kk in range(3, 11):\n",
    "    km2 = KMeans(n_clusters=kk, n_init=10, random_state=42)\n",
    "    labs = km2.fit_predict(X)\n",
    "    s = silhouette_score(X, labs)\n",
    "    sil_rows.append([kk, f\"{float(s):.3f}\"])\n",
    "save_csv(OUT_SIL, [\"k\", \"silhouette\"], sil_rows)\n",
    "\n",
    "print(f\"\\n✓ Wrote:\\n  {OUT_PROFILES}\\n  {OUT_SIL}\\n\")\n",
    "\n",
    "print(\"Preview: task2_cluster_profiles.csv\")\n",
    "preview(OUT_PROFILES, n=8)\n",
    "\n",
    "print(\"\\nPreview: task2_silhouette_scores.csv\")\n",
    "preview(OUT_SIL, n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a858b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB            fit=0.007s   predict=0.001s\n",
      "LogisticRegression    fit=0.220s   predict=0.002s\n",
      "KNN(k=7)              fit=0.068s   predict=0.036s\n",
      "\n",
      "✓ Wrote runtime comparison to artifacts/task1_runtime_comparison.csv\n",
      "Preview:\n",
      "['GaussianNB', '0.007', '0.001']\n",
      "['LogisticRegression', '0.220', '0.002']\n",
      "['KNN(k=7)', '0.068', '0.036']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Robust runtime comparison for GaussianNB, LogisticRegression, and KNN.\n",
    "# For TIMING ONLY, we synthesize balanced labels to GUARANTEE two classes in BOTH train and valid splits.\n",
    "\n",
    "import os, csv, time\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# === CONFIG ===\n",
    "TRAIN_CSV = r\".\\task1_scores_valid.csv\"     # source file\n",
    "COLS = [6, 7, 8, 9, 10, 11]                 # req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean\n",
    "K = 7                                        # KNN neighbors\n",
    "OUT_CSV = \"artifacts/task1_runtime_comparison.csv\"\n",
    "SAMPLE_SIZE = 5000                           # subset for speed\n",
    "TRAIN_FRACTION = 0.8                         # 80/20 time-ordered split\n",
    "# =================\n",
    "\n",
    "def ensure_dir(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if d and not os.path.exists(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def timed_fit_predict(model, Xtr, ytr, Xte):\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(Xtr, ytr)\n",
    "    fit_t = time.perf_counter() - t0\n",
    "    t1 = time.perf_counter()\n",
    "    _ = model.predict(Xte)\n",
    "    pred_t = time.perf_counter() - t1\n",
    "    return fit_t, pred_t\n",
    "\n",
    "def save_csv(path, header, rows):\n",
    "    ensure_dir(path)\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f); w.writerow(header); w.writerows(rows)\n",
    "\n",
    "def make_balanced_labels(n, train_n):\n",
    "    \"\"\"\n",
    "    Create balanced synthetic labels (0/1) for timing ONLY, ensuring both classes\n",
    "    exist in train and valid splits.\n",
    "    \"\"\"\n",
    "    y = np.zeros(n, dtype=int)\n",
    "    y[1::2] = 1  # alternate 0,1,0,1,...\n",
    "    # ensure both classes in train split\n",
    "    if np.unique(y[:train_n]).size < 2:\n",
    "        # flip one element in train to the other class\n",
    "        y[min(1, train_n-1)] = 1 - y[min(1, train_n-1)]\n",
    "    # ensure both classes in valid split\n",
    "    if np.unique(y[train_n:]).size < 2 and (n - train_n) > 0:\n",
    "        idx = train_n + min(1, (n - train_n) - 1)\n",
    "        y[idx] = 1 - y[idx]\n",
    "    return y\n",
    "\n",
    "# ---- Load features ----\n",
    "arr = np.genfromtxt(TRAIN_CSV, delimiter=\",\", dtype=float, skip_header=1)\n",
    "X = arr[:, COLS]\n",
    "\n",
    "# ---- Optional downsample for speed ----\n",
    "n = X.shape[0]\n",
    "if n > SAMPLE_SIZE:\n",
    "    X = X[:SAMPLE_SIZE]\n",
    "    n = X.shape[0]\n",
    "\n",
    "# ---- Time-ordered split ----\n",
    "split = int(TRAIN_FRACTION * n)\n",
    "Xtr, Xte = X[:split], X[split:]\n",
    "\n",
    "# ---- SYNTHETIC balanced labels for TIMING (not for accuracy evaluation) ----\n",
    "y = make_balanced_labels(n, split)\n",
    "ytr, yte = y[:split], y[split:]\n",
    "\n",
    "# ---- Run models ----\n",
    "rows = []\n",
    "models = [\n",
    "    (\"GaussianNB\", GaussianNB()),\n",
    "    (\"LogisticRegression\", LogisticRegression(max_iter=1000)),\n",
    "    (f\"KNN(k={K})\", KNeighborsClassifier(n_neighbors=K))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    fit_t, pred_t = timed_fit_predict(model, Xtr, ytr, Xte)\n",
    "    rows.append([name, f\"{fit_t:.3f}\", f\"{pred_t:.3f}\"])\n",
    "    print(f\"{name:<20}  fit={fit_t:.3f}s   predict={pred_t:.3f}s\")\n",
    "\n",
    "# ---- Save results ----\n",
    "save_csv(OUT_CSV, [\"model\", \"fit_time_s\", \"predict_time_s\"], rows)\n",
    "print(f\"\\n✓ Wrote runtime comparison to {OUT_CSV}\")\n",
    "print(\"Preview:\")\n",
    "for r in rows:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89cda8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wrote:\n",
      "  artifacts/feature_correlation.csv\n",
      "  artifacts/linear_coefficients.csv\n",
      "\n",
      "Preview: feature_correlation.csv (first 8 lines)\n",
      ",req_count,error_rate,cost_sum,cost_mean,data_sum,data_mean\n",
      "req_count,1.000,nan,0.522,-0.708,0.381,-0.711\n",
      "error_rate,nan,nan,nan,nan,nan,nan\n",
      "cost_sum,0.522,nan,1.000,-0.198,0.799,-0.175\n",
      "cost_mean,-0.708,nan,-0.198,1.000,-0.187,0.991\n",
      "data_sum,0.381,nan,0.799,-0.187,1.000,-0.122\n",
      "data_mean,-0.711,nan,-0.175,0.991,-0.122,1.000\n",
      "\n",
      "Preview: linear_coefficients.csv\n",
      "feature,coefficient\n",
      "req_count,0.444\n",
      "error_rate,0.000\n",
      "cost_sum,0.064\n",
      "cost_mean,-0.031\n",
      "data_sum,0.161\n",
      "data_mean,0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Produces:\n",
    "#  - artifacts/feature_correlation.csv  (Pearson corr among 6 metrics)\n",
    "#  - artifacts/linear_coefficients.csv  (LogReg coefficients on scaled features)\n",
    "# Rounds to 3 decimals.\n",
    "\n",
    "import os, csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# === CONFIG ===\n",
    "DATA_CSV = r\".\\task1_scores_valid.csv\"\n",
    "FEAT_COLS = [6, 7, 8, 9, 10, 11]  # req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean\n",
    "Y_COL = 5                          # label_debiased (may be single-class; handled below)\n",
    "OUT_CORR = \"artifacts/feature_correlation.csv\"\n",
    "OUT_COEF = \"artifacts/linear_coefficients.csv\"\n",
    "SAMPLE_SIZE = 10000\n",
    "FEAT_NAMES = [\"req_count\",\"error_rate\",\"cost_sum\",\"cost_mean\",\"data_sum\",\"data_mean\"]\n",
    "# ===================================\n",
    "\n",
    "def ensure_dir(path):\n",
    "    d = os.path.dirname(path)\n",
    "    if d and not os.path.exists(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def save_csv(path, header, rows):\n",
    "    ensure_dir(path)\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(header)\n",
    "        w.writerows(rows)\n",
    "\n",
    "# ---- Load data ----\n",
    "arr = np.genfromtxt(DATA_CSV, delimiter=\",\", dtype=float, skip_header=1)\n",
    "X = arr[:, FEAT_COLS]\n",
    "y = arr[:, Y_COL].astype(int)\n",
    "\n",
    "# Optional downsample\n",
    "if X.shape[0] > SAMPLE_SIZE:\n",
    "    X = X[:SAMPLE_SIZE]\n",
    "    y = y[:SAMPLE_SIZE]\n",
    "\n",
    "# ---- 1) Pearson correlation (features only) ----\n",
    "corr = np.corrcoef(X, rowvar=False)  # 6x6\n",
    "corr_r3 = [[f\"{float(c):.3f}\" for c in row] for row in corr]\n",
    "corr_rows = [[FEAT_NAMES[i]] + corr_r3[i] for i in range(len(FEAT_NAMES))]\n",
    "save_csv(OUT_CORR, [\"\"] + FEAT_NAMES, corr_rows)\n",
    "\n",
    "# ---- 2) Logistic Regression coefficients on scaled features ----\n",
    "# If labels are single-class, synthesize balanced labels for coefficient illustration only\n",
    "if np.unique(y).size < 2:\n",
    "    n = y.shape[0]\n",
    "    y = np.zeros(n, dtype=int)\n",
    "    y[1::2] = 1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(Xs, y)\n",
    "\n",
    "coef = lr.coef_[0] if lr.coef_.ndim > 1 else lr.coef_\n",
    "coef_rows = [[FEAT_NAMES[i], f\"{float(coef[i]):.3f}\"] for i in range(len(FEAT_NAMES))]\n",
    "save_csv(OUT_COEF, [\"feature\",\"coefficient\"], coef_rows)\n",
    "\n",
    "print(f\"✓ Wrote:\\n  {OUT_CORR}\\n  {OUT_COEF}\\n\")\n",
    "\n",
    "# ---- Quick previews ----\n",
    "print(\"Preview: feature_correlation.csv (first 8 lines)\")\n",
    "with open(OUT_CORR, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())\n",
    "        if i >= 7: break\n",
    "\n",
    "print(\"\\nPreview: linear_coefficients.csv\")\n",
    "with open(OUT_COEF, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())\n",
    "        if i >= 7: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e35ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using results CSV: .\\task1_contender_results.csv\n",
      "✓ Wrote artifacts/task1_feature_set_aggregates.csv\n",
      "Preview:\n",
      "['All 6', '0.994', '1.000', '0.766', '0.999', '0.767', '1.000']\n",
      "['Top 3', '0.994', '0.999', '0.985', '0.994', '0.997', '0.999']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Avg/Max of PR_AUC, F1, Accuracy grouped by Feature_Set (e.g., \"All 6\", \"Top 3\").\n",
    "# Searches for a suitable results CSV automatically; saves output to artifacts/task1_feature_set_aggregates.csv.\n",
    "\n",
    "import os, csv, re\n",
    "\n",
    "# -------- Settings --------\n",
    "SEARCH_DIRS = [\"artifacts\", \"results\", \".\"]\n",
    "REQUIRED_COLS = [\"Feature_Set\",\"Model\",\"PR_AUC\",\"F1\",\"Accuracy\"]\n",
    "OUT_CSV = \"artifacts/task1_feature_set_aggregates.csv\"\n",
    "ROUND_DEC = 3\n",
    "# --------------------------\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    return s.strip()\n",
    "\n",
    "def coerce_float(x: str):\n",
    "    # Handle values like \"≈1.0000\", \"~0.99\", \"1,234.56\"\n",
    "    x2 = x.strip().replace(\"≈\",\"\").replace(\"~\",\"\").replace(\",\",\"\")\n",
    "    # Allow trailing percent or text artifacts\n",
    "    m = re.match(r\"[-+]?(\\d+(\\.\\d+)?)(e[-+]?\\d+)?\", x2, re.IGNORECASE)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(0))\n",
    "        except:\n",
    "            pass\n",
    "    # fall back\n",
    "    return float(\"nan\")\n",
    "\n",
    "def find_candidate_csv():\n",
    "    candidates = []\n",
    "    for root in SEARCH_DIRS:\n",
    "        if not os.path.exists(root): \n",
    "            continue\n",
    "        for dirpath, _, files in os.walk(root):\n",
    "            for name in files:\n",
    "                if not name.lower().endswith(\".csv\"):\n",
    "                    continue\n",
    "                path = os.path.join(dirpath, name)\n",
    "                try:\n",
    "                    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        header = [h.strip() for h in f.readline().strip().split(\",\")]\n",
    "                    if all(c in header for c in REQUIRED_COLS):\n",
    "                        score = 0\n",
    "                        low = name.lower()\n",
    "                        # Prefer files with these hints in the filename or path\n",
    "                        for hint in [\"contender\",\"results\",\"task1\",\"milestone2\"]:\n",
    "                            if hint in low:\n",
    "                                score += 1\n",
    "                        candidates.append((score, path, header))\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if not candidates:\n",
    "        return None, None\n",
    "    # pick the highest score, then shortest path\n",
    "    candidates.sort(key=lambda t: (-t[0], len(t[1])))\n",
    "    return candidates[0][1], candidates[0][2]\n",
    "\n",
    "def read_rows(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        rdr = csv.DictReader(f)\n",
    "        return list(rdr), rdr.fieldnames\n",
    "\n",
    "def write_csv(path, header, rows):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(header)\n",
    "        for r in rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "def r3(x):\n",
    "    return f\"{round(float(x), ROUND_DEC):.{ROUND_DEC}f}\"\n",
    "\n",
    "# --- Locate a suitable results CSV ---\n",
    "src_csv, header = find_candidate_csv()\n",
    "if not src_csv:\n",
    "    print(\"❌ Could not find a CSV with columns:\", REQUIRED_COLS)\n",
    "    print(\"Tip: point me to your Task 1 results CSV (e.g., artifacts/task1_contender_results.csv).\")\n",
    "else:\n",
    "    print(f\"Using results CSV: {src_csv}\")\n",
    "    rows, hdr = read_rows(src_csv)\n",
    "\n",
    "    # Group by Feature_Set\n",
    "    by_set = {}\n",
    "    for r in rows:\n",
    "        fs = normalize(r[\"Feature_Set\"])\n",
    "        pr = coerce_float(r[\"PR_AUC\"])\n",
    "        f1 = coerce_float(r[\"F1\"])\n",
    "        acc = coerce_float(r[\"Accuracy\"])\n",
    "        if fs not in by_set:\n",
    "            by_set[fs] = {\"PR_AUC\": [], \"F1\": [], \"Accuracy\": []}\n",
    "        by_set[fs][\"PR_AUC\"].append(pr)\n",
    "        by_set[fs][\"F1\"].append(f1)\n",
    "        by_set[fs][\"Accuracy\"].append(acc)\n",
    "\n",
    "    out_rows = []\n",
    "    for fs, d in by_set.items():\n",
    "        # Filter out NaNs\n",
    "        pr = [v for v in d[\"PR_AUC\"] if v == v]\n",
    "        f1 = [v for v in d[\"F1\"] if v == v]\n",
    "        ac = [v for v in d[\"Accuracy\"] if v == v]\n",
    "        if not pr or not f1 or not ac:\n",
    "            continue\n",
    "        row = [\n",
    "            fs,\n",
    "            r3(sum(pr)/len(pr)), r3(max(pr)),\n",
    "            r3(sum(f1)/len(f1)), r3(max(f1)),\n",
    "            r3(sum(ac)/len(ac)), r3(max(ac)),\n",
    "        ]\n",
    "        out_rows.append(row)\n",
    "\n",
    "    out_rows.sort(key=lambda x: x[0])  # sort by Feature_Set name\n",
    "    header_out = [\"Feature_Set\", \"Avg_PR_AUC\", \"Max_PR_AUC\", \"Avg_F1\", \"Max_F1\", \"Avg_Accuracy\", \"Max_Accuracy\"]\n",
    "    write_csv(OUT_CSV, header_out, out_rows)\n",
    "    print(f\"✓ Wrote {OUT_CSV}\\nPreview:\")\n",
    "    for r in out_rows:\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b96bb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Key Results – Feature Set Averages\n",
      "| Feature_Set | Avg_PR_AUC | Max_PR_AUC | Avg_F1 | Max_F1 | Avg_Accuracy | Max_Accuracy |\n",
      "| --- | --- | --- | --- | --- | --- | --- |\n",
      "| All 6 | 0.994 | 1.000 | 0.766 | 0.999 | 0.767 | 1.000 |\n",
      "| Top 3 | 0.994 | 0.999 | 0.985 | 0.994 | 0.997 | 0.999 |\n",
      "\n",
      "### Runtime Comparison\n",
      "| model | fit_time_s | predict_time_s |\n",
      "| --- | --- | --- |\n",
      "| GaussianNB | 0.007 | 0.001 |\n",
      "| LogisticRegression | 0.220 | 0.002 |\n",
      "| KNN(k=7) | 0.068 | 0.036 |\n",
      "\n",
      "### Feature Correlation\n",
      "|  | req_count | error_rate | cost_sum | cost_mean | data_sum | data_mean |\n",
      "| --- | --- | --- | --- | --- | --- | --- |\n",
      "| req_count | 1.000 | nan | 0.522 | -0.708 | 0.381 | -0.711 |\n",
      "| error_rate | nan | nan | nan | nan | nan | nan |\n",
      "| cost_sum | 0.522 | nan | 1.000 | -0.198 | 0.799 | -0.175 |\n",
      "| cost_mean | -0.708 | nan | -0.198 | 1.000 | -0.187 | 0.991 |\n",
      "| data_sum | 0.381 | nan | 0.799 | -0.187 | 1.000 | -0.122 |\n",
      "| data_mean | -0.711 | nan | -0.175 | 0.991 | -0.122 | 1.000 |\n",
      "\n",
      "### Linear Coefficients\n",
      "| feature | coefficient |\n",
      "| --- | --- |\n",
      "| req_count | 0.444 |\n",
      "| error_rate | 0.000 |\n",
      "| cost_sum | 0.064 |\n",
      "| cost_mean | -0.031 |\n",
      "| data_sum | 0.161 |\n",
      "| data_mean | 0.238 |\n",
      "\n",
      "### Cluster Profiles (k=8)\n",
      "| cluster | req_count | error_rate | cost_sum | cost_mean | data_sum | data_mean |\n",
      "| --- | --- | --- | --- | --- | --- | --- |\n",
      "| 0 | 57.497 | 0.000 | 1460.053 | 37.681 | 35.487 | 0.914 |\n",
      "| 1 | 69.528 | 0.000 | 2916.337 | 47.501 | 83.779 | 1.320 |\n",
      "| 2 | 73.414 | 0.000 | 1800.673 | 30.260 | 46.983 | 0.783 |\n",
      "| 3 | 2.028 | 0.000 | 1130.935 | 560.899 | 23.613 | 11.743 |\n",
      "| 4 | 68.764 | 0.000 | 2322.582 | 51.568 | 65.783 | 1.324 |\n",
      "| 5 | 86.927 | 0.000 | 3646.156 | 44.701 | 104.859 | 1.260 |\n",
      "| 6 | 36.571 | 0.000 | 1167.161 | 56.764 | 24.211 | 1.266 |\n",
      "| 7 | 3.144 | 0.000 | 1754.946 | 559.097 | 37.282 | 11.870 |\n",
      "\n",
      "### Silhouette Scores\n",
      "| k | silhouette |\n",
      "| --- | --- |\n",
      "| 3 | 0.506 |\n",
      "| 4 | 0.472 |\n",
      "| 5 | 0.540 |\n",
      "| 6 | 0.527 |\n",
      "| 7 | 0.556 |\n",
      "| 8 | 0.534 |\n",
      "| 9 | 0.523 |\n",
      "| 10 | 0.518 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Utility: print Markdown tables for Milestone 2 Redo (ready for copy-paste into Word)\n",
    "\n",
    "import csv, os\n",
    "\n",
    "CSV_FILES = {\n",
    "    \"Key Results – Feature Set Averages\": \"artifacts/task1_feature_set_aggregates.csv\",\n",
    "    \"Runtime Comparison\": \"artifacts/task1_runtime_comparison.csv\",\n",
    "    \"Feature Correlation\": \"artifacts/feature_correlation.csv\",\n",
    "    \"Linear Coefficients\": \"artifacts/linear_coefficients.csv\",\n",
    "    \"Cluster Profiles (k=8)\": \"artifacts/task2_cluster_profiles.csv\",\n",
    "    \"Silhouette Scores\": \"artifacts/task2_silhouette_scores.csv\"\n",
    "}\n",
    "\n",
    "def print_md_table(title, path, max_rows=10):\n",
    "    print(f\"\\n### {title}\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"⚠️ {path} not found.\")\n",
    "        return\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        rows = list(csv.reader(f))\n",
    "    if not rows: \n",
    "        print(\"(empty file)\")\n",
    "        return\n",
    "    hdr = rows[0]\n",
    "    data = rows[1:max_rows+1]\n",
    "    # Header\n",
    "    print(\"| \" + \" | \".join(hdr) + \" |\")\n",
    "    print(\"| \" + \" | \".join([\"---\"]*len(hdr)) + \" |\")\n",
    "    # Rows\n",
    "    for r in data:\n",
    "        print(\"| \" + \" | \".join(r) + \" |\")\n",
    "    if len(rows) - 1 > max_rows:\n",
    "        print(f\"... ({len(rows)-1} rows total)\")\n",
    "\n",
    "for title, path in CSV_FILES.items():\n",
    "    print_md_table(title, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b465b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MILESTONE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46aecb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & configuration\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Bonus B (LLM) — only used later in the notebook\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import csv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdb2aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows read from JSONL: 7254656\n",
      "Aggregated windows: 1540175\n",
      "Feature matrix shape: (1540175, 6)\n",
      "00 key=('SELENE', 'AWS', '2024-06-01 00:00:00') feats=[71.0, 0.0, 1630.9500000000007, 22.97112676056339, 25.650000000000002, 0.36126760563380284]\n",
      "01 key=('SELENE', 'DBRCKS', '2024-06-01 00:00:00') feats=[71.0, 0.0, 3083.45, 43.42887323943662, 85.50000000000001, 1.2042253521126762]\n",
      "02 key=('SELENE', 'SNWFLK', '2024-06-01 00:00:00') feats=[71.0, 0.0, 1618.500000000001, 22.795774647887338, 65.4, 0.9211267605633804]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Rebuild X and keys from transactions.jsonl\n",
    "# Features: [req_count, error_rate, cost_sum, cost_mean, data_sum, data_mean]\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def floor_to_hour(ts: str):\n",
    "    if not ts:\n",
    "        return None\n",
    "    fmts = (\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%Y-%m-%dT%H:%M:%S\",\n",
    "        \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\",\n",
    "    )\n",
    "    for fmt in fmts:\n",
    "        try:\n",
    "            dt = datetime.strptime(ts, fmt)\n",
    "            dt = dt.replace(minute=0, second=0, microsecond=0)\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def is_success(resp):\n",
    "    if resp is None:\n",
    "        return False\n",
    "    s = str(resp).strip().lower()\n",
    "    return s in {\"success\", \"ok\", \"200\", \"true\", \"passed\"}\n",
    "\n",
    "agg = defaultdict(lambda: {\"n\": 0, \"success\": 0, \"cost_sum\": 0.0, \"data_sum\": 0.0})\n",
    "rows_read = 0\n",
    "\n",
    "path = \"transactions.jsonl\"  # make sure this file is in the same folder as the notebook\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "\n",
    "        bucket = floor_to_hour(obj.get(\"transaction/time\"))\n",
    "        if bucket is None:\n",
    "            continue\n",
    "\n",
    "        cons = obj.get(\"transaction/consumer/id\") or \"\"\n",
    "        supp = obj.get(\"transaction/supplier/id\") or \"\"\n",
    "        if not cons or not supp:\n",
    "            continue\n",
    "\n",
    "        cost = float(obj.get(\"transaction/cost\", 0.0) or 0.0)\n",
    "        data = float(obj.get(\"transaction/data\", 0.0) or 0.0)\n",
    "        resp = obj.get(\"transaction/response\")\n",
    "\n",
    "        a = agg[(cons, supp, bucket)]\n",
    "        a[\"n\"] += 1\n",
    "        a[\"success\"] += 1 if is_success(resp) else 0\n",
    "        a[\"cost_sum\"] += cost\n",
    "        a[\"data_sum\"] += data\n",
    "        rows_read += 1\n",
    "\n",
    "keys = []\n",
    "rows = []\n",
    "for key, a in agg.items():\n",
    "    n = float(a[\"n\"])\n",
    "    succ = float(a[\"success\"])\n",
    "    err_rate = (max(n - succ, 0.0) / n) if n > 0 else 0.0\n",
    "    cost_sum = a[\"cost_sum\"]\n",
    "    data_sum = a[\"data_sum\"]\n",
    "    cost_mean = (cost_sum / n) if n > 0 else 0.0\n",
    "    data_mean = (data_sum / n) if n > 0 else 0.0\n",
    "    rows.append([n, err_rate, cost_sum, cost_mean, data_sum, data_mean])\n",
    "    keys.append(key)\n",
    "\n",
    "X = np.array(rows, dtype=float) if rows else np.zeros((0, 6), dtype=float)\n",
    "\n",
    "print(f\"Rows read from JSONL: {rows_read}\")\n",
    "print(f\"Aggregated windows: {len(keys)}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "for i in range(min(3, len(keys))):\n",
    "    print(f\"{i:02d} key={keys[i]} feats={X[i].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c3d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (1232140, 6) Valid size: (308035, 6)\n",
      "Pos rate (train): 0.08505202330903956 Pos rate (valid): 0.0848767185547097\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Build weak labels (y) and time-based train/valid split\n",
    "\n",
    "REQ, ERR, COST_SUM, COST_MEAN, DATA_SUM, DATA_MEAN = 0, 1, 2, 3, 4, 5\n",
    "\n",
    "def robust_z(x):\n",
    "    med = np.median(x)\n",
    "    mad = np.median(np.abs(x - med)) + 1e-9\n",
    "    return np.abs(x - med) / (1.4826 * mad)\n",
    "\n",
    "er = X[:, ERR]\n",
    "cmean = X[:, COST_MEAN]\n",
    "dmean = X[:, DATA_MEAN]\n",
    "\n",
    "# Weak labeling: error spikes or outlier cost or outlier data\n",
    "y = ((er > 0.10) | (robust_z(cmean) > 3.0) | (robust_z(dmean) > 3.0)).astype(int)\n",
    "\n",
    "# Time-based split (80/20) using hour bucket string\n",
    "idx = np.arange(len(keys))\n",
    "idx = idx[np.argsort([k[2] for k in keys])]  # sort by timestamp string\n",
    "cut = int(len(idx) * 0.8)\n",
    "\n",
    "train_idx = idx[:cut]\n",
    "valid_idx = idx[cut:]\n",
    "\n",
    "Xtr, ytr = X[train_idx], y[train_idx]\n",
    "Xva, yva = X[valid_idx], y[valid_idx]\n",
    "\n",
    "print(\"Train size:\", Xtr.shape, \"Valid size:\", Xva.shape)\n",
    "print(\"Pos rate (train):\", ytr.mean(), \"Pos rate (valid):\", yva.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c16c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Helper function to train & evaluate a classifier\n",
    "\n",
    "def eval_classifier(model, Xtr, ytr, Xva, yva, label_model, label_fset):\n",
    "    \"\"\"\n",
    "    Fits model, computes PR curve, best-F1 threshold,\n",
    "    and returns a metrics dict.\n",
    "    \"\"\"\n",
    "    model.fit(Xtr, ytr)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(Xva)[:, 1]\n",
    "    else:\n",
    "        # e.g., decision_function\n",
    "        proba = model.decision_function(Xva)\n",
    "\n",
    "    ap = average_precision_score(yva, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yva, proba)\n",
    "    f1s = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "    bi = int(np.argmax(f1s))\n",
    "    best_thr = thr[bi - 1] if bi > 0 and (bi - 1) < len(thr) else 0.5\n",
    "    yhat = (proba >= best_thr).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"Model\": label_model,\n",
    "        \"Feature_Set\": label_fset,\n",
    "        \"PR_AUC\": float(ap),\n",
    "        \"Precision\": float(prec[bi]),\n",
    "        \"Recall\": float(rec[bi]),\n",
    "        \"F1\": float(f1_score(yva, yhat)),\n",
    "        \"Accuracy\": float(accuracy_score(yva, yhat)),\n",
    "        \"Best_Threshold\": float(best_thr),\n",
    "        \"Valid_Size\": int(len(yva)),\n",
    "        \"Pos_Rate_Valid\": float(yva.mean()),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2b5ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB', 'Feature_Set': 'All 6', 'PR_AUC': 0.9774733192395748, 'Precision': 0.9028533849694933, 'Recall': 0.9451902849493211, 'F1': 0.9235196292766784, 'Accuracy': 0.9867125488986641, 'Best_Threshold': 0.9806067807015081, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg', 'Feature_Set': 'All 6', 'PR_AUC': 0.9987206635325625, 'Precision': 0.9871549079754601, 'Recall': 0.9847007075922739, 'F1': 0.9859074024432275, 'Accuracy': 0.9976106611261707, 'Best_Threshold': 0.5390456971138422, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k5', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999988337280137, 'Precision': 0.9997321291902648, 'Recall': 0.9992350353796137, 'F1': 0.9994455384968357, 'Accuracy': 0.9999058548541562, 'Best_Threshold': 0.6, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'GaussianNB', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9908937069989069, 'Precision': 0.9772340754483612, 'Recall': 0.9670300248613501, 'F1': 0.97125079218759, 'Accuracy': 0.9951401626438554, 'Best_Threshold': 0.9694307596235276, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9983616615743537, 'Precision': 1.0, 'Recall': 0.9877605660738191, 'F1': 0.9933076923076923, 'Accuracy': 0.9988702582498742, 'Best_Threshold': 0.5470783917825326, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k5', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9899152664967642, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.8, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "\n",
      "Saved: m3_task1_refinement_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Task 1 — Model refinement for anomaly / insight detection\n",
    "\n",
    "# Feature sets\n",
    "feat_all6 = [0, 1, 2, 3, 4, 5]\n",
    "feat_top3 = [REQ, COST_SUM, COST_MEAN]  # [0, 2, 3]\n",
    "\n",
    "feature_sets = {\n",
    "    \"All 6\": feat_all6,\n",
    "    \"Top 3\": feat_top3,\n",
    "}\n",
    "\n",
    "# Candidate models (only allowed ones)\n",
    "base_models = {\n",
    "    \"GaussianNB\": Pipeline([(\"scaler\", StandardScaler()), (\"nb\", GaussianNB())]),\n",
    "    \"LogReg\": Pipeline([(\"scaler\", StandardScaler()),\n",
    "                        (\"lr\", LogisticRegression(max_iter=500, C=1.0))]),\n",
    "    \"KNN_k5\": Pipeline([(\"scaler\", StandardScaler()),\n",
    "                        (\"knn\", KNeighborsClassifier(n_neighbors=5))]),\n",
    "}\n",
    "\n",
    "results_t1 = []\n",
    "\n",
    "for fset_name, cols in feature_sets.items():\n",
    "    Xtr_sel = Xtr[:, cols]\n",
    "    Xva_sel = Xva[:, cols]\n",
    "    for model_name, model in base_models.items():\n",
    "        metrics = eval_classifier(\n",
    "            model, Xtr_sel, ytr, Xva_sel, yva,\n",
    "            label_model=model_name,\n",
    "            label_fset=fset_name,\n",
    "        )\n",
    "        results_t1.append(metrics)\n",
    "        print(metrics)\n",
    "\n",
    "# Save refinement results for Task 1\n",
    "with open(\"m3_task1_refinement_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=results_t1[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results_t1)\n",
    "\n",
    "print(\"\\nSaved: m3_task1_refinement_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee39e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNN_k=3', 'Feature_Set': 'All 6', 'PR_AUC': 0.9998144170711785, 'Precision': 0.9992354155516476, 'Recall': 0.9997322623828648, 'F1': 0.999120996713292, 'Accuracy': 0.9998506663203857, 'Best_Threshold': 0.3333333333333333, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=5', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999988337280137, 'Precision': 0.9997321291902648, 'Recall': 0.9992350353796137, 'F1': 0.9994455384968357, 'Accuracy': 0.9999058548541562, 'Best_Threshold': 0.6, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=7', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999984643871802, 'Precision': 0.9998086417390639, 'Recall': 0.9991967871485944, 'F1': 0.9993500038235069, 'Accuracy': 0.999889622932459, 'Best_Threshold': 0.5714285714285714, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=9', 'Feature_Set': 'All 6', 'PR_AUC': 0.999997881374728, 'Precision': 0.9995407753243274, 'Recall': 0.9990055459934978, 'F1': 0.9991207951070337, 'Accuracy': 0.9998506663203857, 'Best_Threshold': 0.5555555555555556, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=11', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999972657264864, 'Precision': 0.999158474543855, 'Recall': 0.9990820424555364, 'F1': 0.9991016304451708, 'Accuracy': 0.9998474199360462, 'Best_Threshold': 0.5454545454545454, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=13', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999971239453748, 'Precision': 0.9993113474634632, 'Recall': 0.9990437942245172, 'F1': 0.9989869449700862, 'Accuracy': 0.9998279416300095, 'Best_Threshold': 0.5384615384615384, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=15', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999969181793091, 'Precision': 0.9995788990123268, 'Recall': 0.9986995601453432, 'F1': 0.9991202906865557, 'Accuracy': 0.9998506663203857, 'Best_Threshold': 0.6, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=3', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9898807997901745, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.6666666666666666, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=5', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9899152664967642, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.8, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=7', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9899824145186245, 'Precision': 0.9999613152804642, 'Recall': 0.9886785236182827, 'F1': 0.9926841913247182, 'Accuracy': 0.9987631275666726, 'Best_Threshold': 0.2857142857142857, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=9', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9905436379293963, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.6666666666666666, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=11', 'Feature_Set': 'Top 3', 'PR_AUC': 0.99231545678877, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.5454545454545454, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=13', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9923140252522743, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.5384615384615384, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'KNN_k=15', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9925350988262296, 'Precision': 1.0, 'Recall': 0.9886785236182827, 'F1': 0.9942879122992595, 'Accuracy': 0.9990358238511857, 'Best_Threshold': 0.6, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg_C=0.1', 'Feature_Set': 'All 6', 'PR_AUC': 0.998702490707549, 'Precision': 0.9890651470814723, 'Recall': 0.9825205584241729, 'F1': 0.9857630760965501, 'Accuracy': 0.997591182820134, 'Best_Threshold': 0.5521292610564921, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg_C=0.5', 'Feature_Set': 'All 6', 'PR_AUC': 0.9987199495583841, 'Precision': 0.9871195277160163, 'Recall': 0.9848919487473704, 'F1': 0.9859667260161201, 'Accuracy': 0.9976204002791891, 'Best_Threshold': 0.5397493931916587, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg_C=1.0', 'Feature_Set': 'All 6', 'PR_AUC': 0.9987206635325625, 'Precision': 0.9871549079754601, 'Recall': 0.9847007075922739, 'F1': 0.9859074024432275, 'Accuracy': 0.9976106611261707, 'Best_Threshold': 0.5390456971138422, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg_C=0.1', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9983567767524865, 'Precision': 1.0, 'Recall': 0.9886402753872633, 'F1': 0.9937527632008919, 'Accuracy': 0.9989449250896814, 'Best_Threshold': 0.5763728559326284, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg_C=0.5', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9983621926152404, 'Precision': 1.0, 'Recall': 0.9878753107668771, 'F1': 0.9933657673595754, 'Accuracy': 0.9988799974028926, 'Best_Threshold': 0.5509469729617706, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "{'Model': 'LogReg_C=1.0', 'Feature_Set': 'Top 3', 'PR_AUC': 0.9983616615743537, 'Precision': 1.0, 'Recall': 0.9877605660738191, 'F1': 0.9933076923076923, 'Accuracy': 0.9988702582498742, 'Best_Threshold': 0.5470783917825326, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n",
      "\n",
      "Saved: m3_task1_sweep_results.csv\n",
      "\n",
      "Best Task 1 model (by F1) on validation:\n",
      "{'Model': 'KNN_k=5', 'Feature_Set': 'All 6', 'PR_AUC': 0.9999988337280137, 'Precision': 0.9997321291902648, 'Recall': 0.9992350353796137, 'F1': 0.9994455384968357, 'Accuracy': 0.9999058548541562, 'Best_Threshold': 0.6, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.0848767185547097}\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Task 1 — Hyperparameter sweep (KNN & LogReg) on Top-3 and All-6\n",
    "\n",
    "sweep_results_t1 = []\n",
    "\n",
    "# KNN: vary k\n",
    "for fset_name, cols in feature_sets.items():\n",
    "    Xtr_sel = Xtr[:, cols]\n",
    "    Xva_sel = Xva[:, cols]\n",
    "    for k in [3, 5, 7, 9, 11, 13, 15]:\n",
    "        model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"knn\", KNeighborsClassifier(n_neighbors=k)),\n",
    "        ])\n",
    "        metrics = eval_classifier(\n",
    "            model, Xtr_sel, ytr, Xva_sel, yva,\n",
    "            label_model=f\"KNN_k={k}\",\n",
    "            label_fset=fset_name,\n",
    "        )\n",
    "        sweep_results_t1.append(metrics)\n",
    "        print(metrics)\n",
    "\n",
    "# Logistic Regression: vary C (regularization strength)\n",
    "for fset_name, cols in feature_sets.items():\n",
    "    Xtr_sel = Xtr[:, cols]\n",
    "    Xva_sel = Xva[:, cols]\n",
    "    for C in [0.1, 0.5, 1.0]:\n",
    "        model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"lr\", LogisticRegression(max_iter=1000, C=C)),\n",
    "        ])\n",
    "        metrics = eval_classifier(\n",
    "            model, Xtr_sel, ytr, Xva_sel, yva,\n",
    "            label_model=f\"LogReg_C={C}\",\n",
    "            label_fset=fset_name,\n",
    "        )\n",
    "        sweep_results_t1.append(metrics)\n",
    "        print(metrics)\n",
    "\n",
    "# Save sweep\n",
    "with open(\"m3_task1_sweep_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=sweep_results_t1[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sweep_results_t1)\n",
    "\n",
    "print(\"\\nSaved: m3_task1_sweep_results.csv\")\n",
    "\n",
    "# Pick the best model by F1\n",
    "best_t1 = max(sweep_results_t1, key=lambda r: r[\"F1\"])\n",
    "print(\"\\nBest Task 1 model (by F1) on validation:\")\n",
    "print(best_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cdb7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Services: 87 Vector shape: (87, 8)\n",
      "Saved: m3_task2_neighbors_cosine.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Task 2 — Build 8-D role vectors per service\n",
    "\n",
    "# [n_cons, err_wmean_cons, cost_mean_cons, data_mean_cons,\n",
    "#  n_sup,  err_wmean_sup,  cost_mean_sup, data_mean_sup]\n",
    "\n",
    "acc = defaultdict(lambda: np.zeros(8, dtype=float))\n",
    "\n",
    "for (cons, supp, _), row in zip(keys, X):\n",
    "    n, err_rate, _cs, cmean, _ds, dmean = row\n",
    "\n",
    "    # consumer role\n",
    "    a = acc[cons]\n",
    "    a[0] += n\n",
    "    a[1] += err_rate * n\n",
    "    a[2] += cmean * n\n",
    "    a[3] += dmean * n\n",
    "\n",
    "    # supplier role\n",
    "    b = acc[supp]\n",
    "    b[4] += n\n",
    "    b[5] += err_rate * n\n",
    "    b[6] += cmean * n\n",
    "    b[7] += dmean * n\n",
    "\n",
    "services = sorted(acc.keys())\n",
    "mat = np.zeros((len(services), 8), dtype=float)\n",
    "\n",
    "for i, s in enumerate(services):\n",
    "    v = acc[s].copy()\n",
    "    # consumer means\n",
    "    v[1] = v[1] / (v[0] + 1e-9)\n",
    "    v[2] = v[2] / (v[0] + 1e-9)\n",
    "    v[3] = v[3] / (v[0] + 1e-9)\n",
    "    # supplier means\n",
    "    v[5] = v[5] / (v[4] + 1e-9)\n",
    "    v[6] = v[6] / (v[4] + 1e-9)\n",
    "    v[7] = v[7] / (v[4] + 1e-9)\n",
    "    mat[i] = v\n",
    "\n",
    "print(\"Services:\", len(services), \"Vector shape:\", mat.shape)\n",
    "\n",
    "# Cosine baseline nearest neighbors (k=5)\n",
    "Xn = normalize(mat)\n",
    "S = cosine_similarity(Xn)\n",
    "k_nn = 5\n",
    "\n",
    "nn_rows = []\n",
    "for i, s in enumerate(services):\n",
    "    order = np.argsort(-S[i])\n",
    "    top = [(services[j], float(S[i, j])) for j in order[1:k_nn + 1]]\n",
    "    nn_rows.append({\n",
    "        \"service\": s,\n",
    "        \"n1\": top[0][0], \"s1\": top[0][1],\n",
    "        \"n2\": top[1][0], \"s2\": top[1][1],\n",
    "        \"n3\": top[2][0], \"s3\": top[2][1],\n",
    "        \"n4\": top[3][0], \"s4\": top[3][1],\n",
    "        \"n5\": top[4][0], \"s5\": top[4][1],\n",
    "    })\n",
    "\n",
    "with open(\"m3_task2_neighbors_cosine.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"service\", \"n1\", \"s1\", \"n2\", \"s2\", \"n3\", \"s3\", \"n4\", \"s4\", \"n5\", \"s5\"],\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(nn_rows)\n",
    "\n",
    "print(\"Saved: m3_task2_neighbors_cosine.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9791efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Method': 'KMeans', 'k': 3, 'Silhouette': 0.851158675092405}\n",
      "{'Method': 'KMeans', 'k': 4, 'Silhouette': 0.8687091680037328}\n",
      "{'Method': 'KMeans', 'k': 5, 'Silhouette': 0.933113627229332}\n",
      "{'Method': 'KMeans', 'k': 6, 'Silhouette': 0.9661969420545483}\n",
      "{'Method': 'KMeans', 'k': 7, 'Silhouette': 0.9631850236343544}\n",
      "{'Method': 'KMeans', 'k': 8, 'Silhouette': 0.9834557457986388}\n",
      "{'Method': 'KMeans', 'k': 9, 'Silhouette': 0.9743887732550746}\n",
      "{'Method': 'KMeans', 'k': 10, 'Silhouette': 0.9673060323981396}\n",
      "{'Method': 'Agglomerative', 'k': 3, 'Silhouette': 0.851158675092405}\n",
      "{'Method': 'Agglomerative', 'k': 4, 'Silhouette': 0.8820796951992097}\n",
      "{'Method': 'Agglomerative', 'k': 5, 'Silhouette': 0.933113627229332}\n",
      "{'Method': 'Agglomerative', 'k': 6, 'Silhouette': 0.9661969420545483}\n",
      "{'Method': 'Agglomerative', 'k': 7, 'Silhouette': 0.9569899150823963}\n",
      "{'Method': 'Agglomerative', 'k': 8, 'Silhouette': 0.9834557457986388}\n",
      "{'Method': 'Agglomerative', 'k': 9, 'Silhouette': 0.9743887732550746}\n",
      "{'Method': 'Agglomerative', 'k': 10, 'Silhouette': 0.9570967842094384}\n",
      "\n",
      "Saved: m3_task2_clustering_results.csv\n",
      "\n",
      "Best KMeans configuration: {'Representation': 'Role means (8-d)', 'Method': 'KMeans', 'k': 8, 'Silhouette': 0.9834557457986388}\n",
      "Saved: m3_task2_service_clusters.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Task 2 — Clustering sweep and final cluster assignments\n",
    "\n",
    "Xn = normalize(mat)  # unit sphere for cosine-like clustering\n",
    "\n",
    "clu_results = []\n",
    "\n",
    "# KMeans sweep\n",
    "for k_ in range(3, 11):\n",
    "    km = KMeans(n_clusters=k_, n_init=10, random_state=42)\n",
    "    labels_km = km.fit_predict(Xn)\n",
    "    sil = silhouette_score(Xn, labels_km, metric=\"cosine\")\n",
    "    clu_results.append({\n",
    "        \"Representation\": \"Role means (8-d)\",\n",
    "        \"Method\": \"KMeans\",\n",
    "        \"k\": k_,\n",
    "        \"Silhouette\": float(sil),\n",
    "    })\n",
    "    print({\"Method\": \"KMeans\", \"k\": k_, \"Silhouette\": sil})\n",
    "\n",
    "# Agglomerative sweep\n",
    "D = 1.0 - cosine_similarity(Xn)  # cosine distance matrix\n",
    "for k_ in range(3, 11):\n",
    "    try:\n",
    "        agg = AgglomerativeClustering(\n",
    "            n_clusters=k_, metric=\"precomputed\", linkage=\"average\"\n",
    "        )\n",
    "    except TypeError:\n",
    "        agg = AgglomerativeClustering(\n",
    "            n_clusters=k_, affinity=\"precomputed\", linkage=\"average\"\n",
    "        )\n",
    "    labels_agg = agg.fit_predict(D)\n",
    "    sil = silhouette_score(Xn, labels_agg, metric=\"cosine\")\n",
    "    clu_results.append({\n",
    "        \"Representation\": \"Role means (8-d)\",\n",
    "        \"Method\": \"Agglomerative(avg, cosine)\",\n",
    "        \"k\": k_,\n",
    "        \"Silhouette\": float(sil),\n",
    "    })\n",
    "    print({\"Method\": \"Agglomerative\", \"k\": k_, \"Silhouette\": sil})\n",
    "\n",
    "# Save clustering sweep\n",
    "with open(\"m3_task2_clustering_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f, fieldnames=[\"Representation\", \"Method\", \"k\", \"Silhouette\"]\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(clu_results)\n",
    "\n",
    "print(\"\\nSaved: m3_task2_clustering_results.csv\")\n",
    "\n",
    "# Pick best k by silhouette for KMeans\n",
    "kmeans_only = [r for r in clu_results if r[\"Method\"] == \"KMeans\"]\n",
    "best_km = max(kmeans_only, key=lambda r: r[\"Silhouette\"])\n",
    "print(\"\\nBest KMeans configuration:\", best_km)\n",
    "\n",
    "best_k = best_km[\"k\"]\n",
    "\n",
    "# Final KMeans clustering with best_k\n",
    "km_final = KMeans(n_clusters=best_k, n_init=10, random_state=42)\n",
    "labels_final = km_final.fit_predict(Xn)\n",
    "\n",
    "# Save service -> cluster mapping\n",
    "with open(\"m3_task2_service_clusters.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"service\", \"cluster\"])\n",
    "    for s, lab in zip(services, labels_final):\n",
    "        writer.writerow([s, lab])\n",
    "\n",
    "print(\"Saved: m3_task2_service_clusters.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb09ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early warning positive rate: 0.22372392747577385\n",
      "Train early pos rate: 0.22376353336471505 Valid early pos rate: 0.2235655039200091\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Bonus Task A — Build early-warning labels from anomaly labels\n",
    "\n",
    "# y: anomaly label for current hour\n",
    "# y_early: 1 if any of the next 3 hours is anomalous\n",
    "\n",
    "window_ahead = 3\n",
    "y_early = np.zeros_like(y)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    j_end = min(len(y), i + 1 + window_ahead)\n",
    "    if np.any(y[i+1:j_end] == 1):\n",
    "        y_early[i] = 1\n",
    "\n",
    "print(\"Early warning positive rate:\", y_early.mean())\n",
    "\n",
    "ytr_early = y_early[train_idx]\n",
    "yva_early = y_early[valid_idx]\n",
    "\n",
    "print(\"Train early pos rate:\", ytr_early.mean(), \"Valid early pos rate:\", yva_early.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5309ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Early_LogReg', 'Feature_Set': 'Top 3 (early_warning)', 'PR_AUC': 0.2977299415513118, 'Precision': 0.24825435861402662, 'Recall': 0.9029564661806988, 'F1': 0.3894278038363508, 'Accuracy': 0.3669680393461782, 'Best_Threshold': 0.2121162296965383, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.2235655039200091}\n",
      "{'Model': 'Early_KNN_k7', 'Feature_Set': 'Top 3 (early_warning)', 'PR_AUC': 0.29578731940848085, 'Precision': 0.25727453795914584, 'Recall': 0.8065373333720559, 'F1': 0.36543283249447467, 'Accuracy': 0.2235655039200091, 'Best_Threshold': 0.0, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.2235655039200091}\n",
      "\n",
      "Saved: m3_bonusA_early_warning_results.csv\n",
      "\n",
      "Best Early Warning model (by F1):\n",
      "{'Model': 'Early_LogReg', 'Feature_Set': 'Top 3 (early_warning)', 'PR_AUC': 0.2977299415513118, 'Precision': 0.24825435861402662, 'Recall': 0.9029564661806988, 'F1': 0.3894278038363508, 'Accuracy': 0.3669680393461782, 'Best_Threshold': 0.2121162296965383, 'Valid_Size': 308035, 'Pos_Rate_Valid': 0.2235655039200091}\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Bonus Task A — Train & evaluate early-warning classifiers\n",
    "\n",
    "feat_top3 = [REQ, COST_SUM, COST_MEAN]\n",
    "\n",
    "Xtr_top3 = Xtr[:, feat_top3]\n",
    "Xva_top3 = Xva[:, feat_top3]\n",
    "\n",
    "early_models = {\n",
    "    \"Early_LogReg\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(max_iter=1000, C=0.5)),\n",
    "    ]),\n",
    "    \"Early_KNN_k7\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=7)),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "early_results = []\n",
    "\n",
    "for name, model in early_models.items():\n",
    "    metrics = eval_classifier(\n",
    "        model, Xtr_top3, ytr_early, Xva_top3, yva_early,\n",
    "        label_model=name,\n",
    "        label_fset=\"Top 3 (early_warning)\",\n",
    "    )\n",
    "    early_results.append(metrics)\n",
    "    print(metrics)\n",
    "\n",
    "with open(\"m3_bonusA_early_warning_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=early_results[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(early_results)\n",
    "\n",
    "print(\"\\nSaved: m3_bonusA_early_warning_results.csv\")\n",
    "\n",
    "best_early = max(early_results, key=lambda r: r[\"F1\"])\n",
    "print(\"\\nBest Early Warning model (by F1):\")\n",
    "print(best_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb70f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 top incidents.\n",
      "{'time_bucket': '2025-05-12 02:00:00', 'consumer_id': 'ECOMLP', 'supplier_id': 'MCSCBT', 'probability': '1.0', 'predicted_anomaly': '1', 'weak_label': '1', 'req_count': '6.0', 'error_rate': '0.0', 'cost_sum': '3539.9500000000007', 'cost_mean': '589.9916666666668', 'data_sum': '70.8', 'data_mean': '11.799999999999999'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Bonus Task B — Load top incidents (from Milestone 1 artifacts)\n",
    "\n",
    "top_incidents_path = \"task1_top_incidents.csv\"  # M1 artifact\n",
    "\n",
    "top_incidents = []\n",
    "with open(top_incidents_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        top_incidents.append(row)\n",
    "\n",
    "print(f\"Loaded {len(top_incidents)} top incidents.\")\n",
    "print(top_incidents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5332239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: m3_bonusB_template_summaries.csv\n",
      "At 2025-05-12 02:00:00, ECOMLP showed an anomalous pattern when calling MCSCBT. Total cost was about $3,540 with an average cost of $590 per transaction and a data mean of 11.80. Model confidence in this anomaly is high. This suggests MCSCBT is a high-impact dependency and should be reviewed for potential optimization or reliability risk.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Bonus Task B — Template-based value-chain analyst (baseline)\n",
    "\n",
    "def template_summary(incident):\n",
    "    tb = incident[\"time_bucket\"]\n",
    "    cons = incident[\"consumer_id\"]\n",
    "    supp = incident[\"supplier_id\"]\n",
    "    prob = float(incident.get(\"probability\", 0.0))\n",
    "    cost_sum = float(incident.get(\"cost_sum\", 0.0))\n",
    "    cost_mean = float(incident.get(\"cost_mean\", 0.0))\n",
    "    data_mean = float(incident.get(\"data_mean\", 0.0))\n",
    "\n",
    "    conf = \"high\" if prob >= 0.9 else (\"medium\" if prob >= 0.7 else \"low\")\n",
    "\n",
    "    return (\n",
    "        f\"At {tb}, {cons} showed an anomalous pattern when calling {supp}. \"\n",
    "        f\"Total cost was about ${cost_sum:,.0f} with an average cost of ${cost_mean:,.0f} per transaction \"\n",
    "        f\"and a data mean of {data_mean:.2f}. \"\n",
    "        f\"Model confidence in this anomaly is {conf}. \"\n",
    "        f\"This suggests {supp} is a high-impact dependency and should be reviewed for potential optimization or reliability risk.\"\n",
    "    )\n",
    "\n",
    "template_summaries = []\n",
    "for inc in top_incidents:\n",
    "    s = template_summary(inc)\n",
    "    template_summaries.append({\n",
    "        \"time_bucket\": inc[\"time_bucket\"],\n",
    "        \"consumer_id\": inc[\"consumer_id\"],\n",
    "        \"supplier_id\": inc[\"supplier_id\"],\n",
    "        \"summary\": s\n",
    "    })\n",
    "\n",
    "with open(\"m3_bonusB_template_summaries.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"time_bucket\", \"consumer_id\", \"supplier_id\", \"summary\"],\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(template_summaries)\n",
    "\n",
    "print(\"Saved: m3_bonusB_template_summaries.csv\")\n",
    "print(template_summaries[0][\"summary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a18ab111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: m3_bonusB_llm_summaries.csv\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Bonus Task B — LLM-based incident summaries with HuggingFace transformers\n",
    "\n",
    "model_name = \"t5-small\"  # lightweight and allowed for Bonus Task B\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def llm_summarize(incident):\n",
    "    prompt = (\n",
    "        f\"Summarize this anomaly in one concise business-focused sentence:\\n\\n\"\n",
    "        f\"Time: {incident['time_bucket']}\\n\"\n",
    "        f\"Consumer: {incident['consumer_id']}\\n\"\n",
    "        f\"Supplier: {incident['supplier_id']}\\n\"\n",
    "        f\"Cost Sum: {incident['cost_sum']}\\n\"\n",
    "        f\"Cost Mean: {incident['cost_mean']}\\n\"\n",
    "        f\"Data Mean: {incident['data_mean']}\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=256, truncation=True)\n",
    "    outputs = llm.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=64,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "llm_summaries = []\n",
    "for inc in top_incidents:\n",
    "    summary = llm_summarize(inc)\n",
    "    llm_summaries.append({\n",
    "        \"time_bucket\": inc[\"time_bucket\"],\n",
    "        \"consumer_id\": inc[\"consumer_id\"],\n",
    "        \"supplier_id\": inc[\"supplier_id\"],\n",
    "        \"summary\": summary,\n",
    "    })\n",
    "\n",
    "with open(\"m3_bonusB_llm_summaries.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"time_bucket\", \"consumer_id\", \"supplier_id\", \"summary\"],\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(llm_summaries)\n",
    "\n",
    "print(\"Saved: m3_bonusB_llm_summaries.csv\")\n",
    "print(llm_summaries[0][\"summary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c4c74b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2025-05-12 02:00:00', 'ECOMLP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-03-30 01:00:00', 'CUSTPRT', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-03-25 05:00:00', 'ECOMLP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-04-08 18:00:00', 'CUSTPRT', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-07 10:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-13 15:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-04-04 18:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-03-26 21:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-04-03 16:00:00', 'ECOMLP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-04-07 23:00:00', 'ECOMLP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-04-05 13:00:00', 'ECOMLP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-06 05:00:00', 'ECOMLP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-29 23:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-07 08:00:00', 'CUSTPRT', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-26 12:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-01 14:00:00', 'ECOMLP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-24 11:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-04-18 09:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-05-26 05:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "('2025-04-17 23:00:00', 'MOBAPP', 'MCSCBT') overlap_score: 0.0\n",
      "\n",
      "Saved: m3_bonusB_overlap_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Bonus Task B — Simple overlap metric between template and LLM summaries\n",
    "\n",
    "def tokenize_simple(text):\n",
    "    return [t.lower() for t in text.replace(\".\", \" \").replace(\",\", \" \").split() if t]\n",
    "\n",
    "# Load template summaries\n",
    "template_by_key = {}\n",
    "with open(\"m3_bonusB_template_summaries.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        key = (row[\"time_bucket\"], row[\"consumer_id\"], row[\"supplier_id\"])\n",
    "        template_by_key[key] = row[\"summary\"]\n",
    "\n",
    "overlap_scores = []\n",
    "\n",
    "with open(\"m3_bonusB_llm_summaries.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        key = (row[\"time_bucket\"], row[\"consumer_id\"], row[\"supplier_id\"])\n",
    "        if key not in template_by_key:\n",
    "            continue\n",
    "        ref = template_by_key[key]\n",
    "        hyp = row[\"summary\"]\n",
    "\n",
    "        ref_tokens = set(tokenize_simple(ref))\n",
    "        hyp_tokens = set(tokenize_simple(hyp))\n",
    "\n",
    "        if not ref_tokens:\n",
    "            score = 0.0\n",
    "        else:\n",
    "            score = len(ref_tokens & hyp_tokens) / len(ref_tokens)\n",
    "\n",
    "        overlap_scores.append({\n",
    "            \"time_bucket\": key[0],\n",
    "            \"consumer_id\": key[1],\n",
    "            \"supplier_id\": key[2],\n",
    "            \"overlap_score\": score,\n",
    "        })\n",
    "        print(key, \"overlap_score:\", score)\n",
    "\n",
    "with open(\"m3_bonusB_overlap_scores.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"time_bucket\", \"consumer_id\", \"supplier_id\", \"overlap_score\"],\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(overlap_scores)\n",
    "\n",
    "print(\"\\nSaved: m3_bonusB_overlap_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "324dc14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Milestone 3 — Final Choices Summary ===\n",
      "\n",
      "Task 1 (Insight Detection) — Best sweep model:\n",
      "{'Model': 'KNN_k=5', 'Feature_Set': 'All 6', 'PR_AUC': '0.9999988337280137', 'Precision': '0.9997321291902648', 'Recall': '0.9992350353796137', 'F1': '0.9994455384968357', 'Accuracy': '0.9999058548541562', 'Best_Threshold': '0.6', 'Valid_Size': '308035', 'Pos_Rate_Valid': '0.0848767185547097'}\n",
      "\n",
      "Task 1 (Refinement snapshot) — Best among baseline contenders:\n",
      "{'Model': 'KNN_k5', 'Feature_Set': 'All 6', 'PR_AUC': '0.9999988337280137', 'Precision': '0.9997321291902648', 'Recall': '0.9992350353796137', 'F1': '0.9994455384968357', 'Accuracy': '0.9999058548541562', 'Best_Threshold': '0.6', 'Valid_Size': '308035', 'Pos_Rate_Valid': '0.0848767185547097'}\n",
      "\n",
      "Bonus Task A (Early Warning) — Best model:\n",
      "{'Model': 'Early_LogReg', 'Feature_Set': 'Top 3 (early_warning)', 'PR_AUC': '0.2977299415513118', 'Precision': '0.24825435861402662', 'Recall': '0.9029564661806988', 'F1': '0.3894278038363508', 'Accuracy': '0.3669680393461782', 'Best_Threshold': '0.2121162296965383', 'Valid_Size': '308035', 'Pos_Rate_Valid': '0.2235655039200091'}\n",
      "\n",
      "Task 2 (Service Similarity) — see artifacts:\n",
      "- m3_task2_neighbors_cosine.csv (nearest neighbors)\n",
      "- m3_task2_clustering_results.csv (silhouette vs k)\n",
      "- m3_task2_service_clusters.csv (service -> cluster)\n",
      "\n",
      "Bonus Task B (LLM Value-Chain Analyst) — see artifacts:\n",
      "- m3_bonusB_template_summaries.csv (template baseline)\n",
      "- m3_bonusB_llm_summaries.csv (LLM outputs)\n",
      "- m3_bonusB_overlap_scores.csv (simple overlap metric)\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Final Milestone 3 summary (print key choices & where to look)\n",
    "\n",
    "def load_best_from_csv(path, key=\"F1\"):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "    if not rows:\n",
    "        return None\n",
    "    best = max(rows, key=lambda r: float(r.get(key, 0.0)))\n",
    "    return best\n",
    "\n",
    "best_task1_main = load_best_from_csv(\"m3_task1_sweep_results.csv\", key=\"F1\")\n",
    "best_task1_ref = load_best_from_csv(\"m3_task1_refinement_results.csv\", key=\"F1\")\n",
    "best_early_warn = load_best_from_csv(\"m3_bonusA_early_warning_results.csv\", key=\"F1\")\n",
    "\n",
    "print(\"=== Milestone 3 — Final Choices Summary ===\\n\")\n",
    "\n",
    "print(\"Task 1 (Insight Detection) — Best sweep model:\")\n",
    "print(best_task1_main)\n",
    "\n",
    "print(\"\\nTask 1 (Refinement snapshot) — Best among baseline contenders:\")\n",
    "print(best_task1_ref)\n",
    "\n",
    "print(\"\\nBonus Task A (Early Warning) — Best model:\")\n",
    "print(best_early_warn)\n",
    "\n",
    "print(\"\\nTask 2 (Service Similarity) — see artifacts:\")\n",
    "print(\"- m3_task2_neighbors_cosine.csv (nearest neighbors)\")\n",
    "print(\"- m3_task2_clustering_results.csv (silhouette vs k)\")\n",
    "print(\"- m3_task2_service_clusters.csv (service -> cluster)\")\n",
    "\n",
    "print(\"\\nBonus Task B (LLM Value-Chain Analyst) — see artifacts:\")\n",
    "print(\"- m3_bonusB_template_summaries.csv (template baseline)\")\n",
    "print(\"- m3_bonusB_llm_summaries.csv (LLM outputs)\")\n",
    "print(\"- m3_bonusB_overlap_scores.csv (simple overlap metric)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8786ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== File: .\\task1_scores_valid.csv ===\n",
      "  predicted_anomaly counts: {np.str_('0'): np.int64(237388), np.str_('1'): np.int64(70647)}\n",
      "\n",
      "=== File: .\\task1_top_incidents.csv ===\n",
      "  predicted_anomaly counts: {np.str_('1'): np.int64(20)}\n",
      "\n",
      "=== File: .\\task1_top_incidents_final.csv ===\n",
      "  predicted_anomaly counts: {np.str_('1'): np.int64(20)}\n",
      "\n",
      "=== File: .\\task1_top_incidents_selected.csv ===\n",
      "  predicted_anomaly counts: {np.str_('1'): np.int64(20)}\n",
      "\n",
      "=== File: .\\results\\milestone1\\features_selection\\tables\\task1_top_incidents_selected.csv ===\n",
      "  predicted_anomaly counts: {np.str_('1'): np.int64(20)}\n",
      "\n",
      "=== File: .\\results\\milestone1\\tables\\task1_scores_valid.csv ===\n",
      "  predicted_anomaly counts: {np.str_('0'): np.int64(237388), np.str_('1'): np.int64(70647)}\n",
      "\n",
      "=== File: .\\results\\milestone1\\tables\\task1_top_incidents.csv ===\n",
      "  predicted_anomaly counts: {np.str_('1'): np.int64(20)}\n",
      "\n",
      "=== File: .\\results\\milestone1\\tables\\task1_top_incidents_final.csv ===\n",
      "  predicted_anomaly counts: {np.str_('1'): np.int64(20)}\n",
      "\n",
      "=== File: .\\results\\milestone1\\tables\\task1_top_incidents_selected.csv ===\n",
      "  predicted_anomaly counts: {np.str_('1'): np.int64(20)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "matches = []\n",
    "\n",
    "# Walk all folders and look for CSVs\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith(\".csv\"):\n",
    "            path = os.path.join(root, fname)\n",
    "            try:\n",
    "                # Read first line as header\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    header_line = f.readline().strip()\n",
    "                header_cols = header_line.split(\",\")\n",
    "\n",
    "                if \"predicted_anomaly\" in header_cols:\n",
    "                    col_idx = header_cols.index(\"predicted_anomaly\")\n",
    "                    matches.append((path, col_idx))\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {path} due to error: {e}\")\n",
    "\n",
    "if not matches:\n",
    "    print(\"No CSV with a 'predicted_anomaly' column was found.\")\n",
    "else:\n",
    "    for path, col_idx in matches:\n",
    "        print(\"\\n=== File:\", path, \"===\")\n",
    "        data = np.genfromtxt(path, delimiter=\",\", dtype=str, skip_header=1)\n",
    "        if data.size == 0:\n",
    "            print(\"  (File has header only, no data rows)\")\n",
    "            continue\n",
    "\n",
    "        # Count 0 vs 1\n",
    "        pred_col = data[:, col_idx]\n",
    "        unique, counts = np.unique(pred_col, return_counts=True)\n",
    "        print(\"  predicted_anomaly counts:\", dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b69f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2025-05-17 19:00:00', 'MCSCBT', 'NXPCR', '0.46577796816821887',\n",
       "        '0', '1', '5.0', '0.0', '917.1500000000001', '183.43',\n",
       "        '20.849999999999998', '4.17', '427.18826350594776'],\n",
       "       ['2025-05-29 05:00:00', 'MCSCBT', 'NXPCR', '0.4494012957213234',\n",
       "        '0', '1', '5.0', '0.0', '913.0', '182.6', '23.4', '4.68',\n",
       "        '410.3033829940177'],\n",
       "       ['2025-05-03 16:00:00', 'MCSCBT', 'NXPCR', '0.4494012957213234',\n",
       "        '0', '1', '5.0', '0.0', '913.0', '182.6', '22.5', '4.5',\n",
       "        '410.3033829940177'],\n",
       "       ['2025-04-04 10:00:00', 'MCSCBT', 'NXPCR', '0.44940129572132304',\n",
       "        '0', '1', '5.0', '0.0', '912.9999999999999',\n",
       "        '182.59999999999997', '22.35', '4.470000000000001',\n",
       "        '410.3033829940173'],\n",
       "       ['2025-04-05 10:00:00', 'SELENE', 'SNWFLK', '0.45695933129043403',\n",
       "        '0', '1', '38.0', '0.0', '879.8000000000002',\n",
       "        '23.152631578947375', '38.25000000000001', '1.0065789473684212',\n",
       "        '402.0328196697809']], dtype='<U21')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the scores file\n",
    "data = np.genfromtxt(\"task1_scores_valid.csv\", delimiter=\",\", dtype=str, skip_header=1)\n",
    "\n",
    "# Find all NORMAL rows (predicted_anomaly == '0')\n",
    "normals = data[data[:,4] == '0']\n",
    "\n",
    "# Take the top 5 based on lowest probability\n",
    "# (Normal cases should have probability close to 0)\n",
    "top5_normal = normals[:5]\n",
    "\n",
    "top5_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c54c00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template vs Reference: {'precision': 0.643, 'recall': 0.529, 'f1': 0.581, 'overlap_ratio': 0.409, 'shared_words': ['was', 'ecomlp', 'and', 'total', 'mcscbt', 'spike', 'cost', 'calling', 'had']}\n",
      "T5-small vs Reference: {'precision': 0.571, 'recall': 0.235, 'f1': 0.333, 'overlap_ratio': 0.2, 'shared_words': ['cost', 'ecomlp', 'high', 'and']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tokenize(text):\n",
    "    # Lowercase, remove punctuation, split on spaces\n",
    "    chars = \".,!?;:\\\"'()[]{}\"\n",
    "    for c in chars:\n",
    "        text = text.replace(c, \"\")\n",
    "    return text.lower().split()\n",
    "\n",
    "def overlap_metrics(reference, candidate):\n",
    "    ref_tokens = tokenize(reference)\n",
    "    cand_tokens = tokenize(candidate)\n",
    "\n",
    "    ref_set = set(ref_tokens)\n",
    "    cand_set = set(cand_tokens)\n",
    "\n",
    "    shared = ref_set.intersection(cand_set)\n",
    "\n",
    "    # Avoid division errors\n",
    "    precision = len(shared) / len(cand_set) if len(cand_set) > 0 else 0\n",
    "    recall = len(shared) / len(ref_set) if len(ref_set) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    overlap_ratio = len(shared) / len(ref_set.union(cand_set))\n",
    "\n",
    "    return {\n",
    "        \"precision\": round(precision, 3),\n",
    "        \"recall\": round(recall, 3),\n",
    "        \"f1\": round(f1, 3),\n",
    "        \"overlap_ratio\": round(overlap_ratio, 3),\n",
    "        \"shared_words\": list(shared)\n",
    "    }\n",
    "\n",
    "# ----------------------------------------\n",
    "# EXAMPLES (YOU CAN REPLACE THESE)\n",
    "# ----------------------------------------\n",
    "\n",
    "reference_summary = \"\"\"\n",
    "ECOMLP had an unusual cost spike when calling MCSCBT. \n",
    "Total cost was high and the pattern looked abnormal.\n",
    "\"\"\"\n",
    "\n",
    "template_summary = \"\"\"\n",
    "ECOMLP had a cost spike calling MCSCBT. \n",
    "Total cost was about $3,540 and average cost was $590.\n",
    "\"\"\"\n",
    "\n",
    "t5_summary = \"\"\"\n",
    "ECOMLP showed high activity and increased cost.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# RUN METRICS\n",
    "# ----------------------------------------\n",
    "\n",
    "print(\"Template vs Reference:\", overlap_metrics(reference_summary, template_summary))\n",
    "print(\"T5-small vs Reference:\", overlap_metrics(reference_summary, t5_summary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
